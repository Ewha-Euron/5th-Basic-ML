{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmTwPiVnB0WW"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UiPUuhW-B0Wd"
      },
      "outputs": [],
      "source": [
        "list1 = [1,2,3]\n",
        "print(type(list1))\n",
        "array1 = np.array(list1)\n",
        "print(type(array1))\n",
        "print(array1, array1.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fTX_AuMB0We"
      },
      "outputs": [],
      "source": [
        "list2 = [1, 2, 'test']\n",
        "array2 = np.array(list2)\n",
        "print(array2, array2.dtype)\n",
        "\n",
        "list3 = [1, 2, 3.0]\n",
        "array3 = np.array(list3)\n",
        "print(array3, array3.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4L_xWPgQB0Wf"
      },
      "outputs": [],
      "source": [
        "array_int = np.array([1, 2, 3])\n",
        "array_float = array_int.astype('float64')\n",
        "print(array_float, array_float.dtype)\n",
        "\n",
        "array_int1= array_float.astype('int32')\n",
        "print(array_int1, array_int1.dtype)\n",
        "\n",
        "array_float1 = np.array([1.1, 2.1, 3.1])\n",
        "array_int2= array_float1.astype('int32')\n",
        "print(array_int2, array_int2.dtype)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0vaheCW_B0Wh"
      },
      "outputs": [],
      "source": [
        "sequence_array = np.arange(10)\n",
        "print(sequence_array)\n",
        "print(sequence_array.dtype, sequence_array.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bnZZ07WwB0Wi"
      },
      "outputs": [],
      "source": [
        "zero_array = np.zeros((3,2),dtype='int32')\n",
        "print(zero_array)\n",
        "print(zero_array.dtype, zero_array.shape)\n",
        "\n",
        "one_array = np.ones((3,2))\n",
        "print(one_array)\n",
        "print(one_array.dtype, one_array.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4j5NnTH0B0Wk"
      },
      "source": [
        "### reshape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0b5x8a6B0Wk"
      },
      "outputs": [],
      "source": [
        "array1 = np.arange(10)\n",
        "print('array1:\\n', array1)\n",
        "\n",
        "array2 = array1.reshape(2,5)\n",
        "print('array2:\\n',array2)\n",
        "\n",
        "array3 = array1.reshape(5,2)\n",
        "print('array3:\\n',array3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZBXotdTB0Wl"
      },
      "outputs": [],
      "source": [
        "array1.reshape(4,3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cakrpswNB0Wl"
      },
      "outputs": [],
      "source": [
        "array1 = np.arange(10)\n",
        "print(array1)\n",
        "\n",
        "array2 = array1.reshape(-1,5)\n",
        "print('array2 shape:',array2.shape)\n",
        "\n",
        "array3 = array1.reshape(5,-1)\n",
        "print('array3 shape:',array3.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gEfG0-VfB0Wm"
      },
      "outputs": [],
      "source": [
        "array1 = np.arange(10)\n",
        "array4 = array1.reshape(-1,4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pd3MXeNQB0Wm"
      },
      "outputs": [],
      "source": [
        "array1 = np.arange(8)\n",
        "array3d = array1.reshape((2,2,2))\n",
        "print('array3d:\\n',array3d.tolist())\n",
        "\n",
        "# 3차원 ndarray를 2차원 ndarray로 변환\n",
        "array5 = array3d.reshape(-1,1)\n",
        "print('array5:\\n',array5.tolist())\n",
        "print('array5 shape:',array5.shape)\n",
        "\n",
        "# 1차원 ndarray를 2차원 ndarray로 변환\n",
        "array6 = array1.reshape(-1,1)\n",
        "print('array6:\\n',array6.tolist())\n",
        "print('array6 shape:',array6.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4cGGzvmEB0Wo"
      },
      "outputs": [],
      "source": [
        "print('맨 뒤의 값:',array1[-1], ', 맨 뒤에서 두번째 값:',array1[-2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KkB9EVhVB0Wo"
      },
      "outputs": [],
      "source": [
        "array1[0] = 9\n",
        "array1[8] = 0\n",
        "print('array1:',array1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61fdHwAIB0Wo"
      },
      "outputs": [],
      "source": [
        "array1d = np.arange(start=1, stop=10)\n",
        "array2d = array1d.reshape(3,3)\n",
        "print(array2d)\n",
        "\n",
        "print('(row=0,col=0) index 가리키는 값:', array2d[0,0] )\n",
        "print('(row=0,col=1) index 가리키는 값:', array2d[0,1] )\n",
        "print('(row=1,col=0) index 가리키는 값:', array2d[1,0] )\n",
        "print('(row=2,col=2) index 가리키는 값:', array2d[2,2] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDPpNNt2B0Wo"
      },
      "outputs": [],
      "source": [
        "array1 = np.arange(start=1, stop=10)\n",
        "array3 = array1[0:3]\n",
        "print(array3)\n",
        "print(type(array3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYqht31bB0Wp"
      },
      "outputs": [],
      "source": [
        "array1 = np.arange(start=1, stop=10)\n",
        "array4 = array1[:3]\n",
        "print(array4)\n",
        "\n",
        "array5 = array1[3:]\n",
        "print(array5)\n",
        "\n",
        "array6 = array1[:]\n",
        "print(array6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DH3dP9eB0Wp"
      },
      "outputs": [],
      "source": [
        "array1d = np.arange(start=1, stop=10)\n",
        "array2d = array1d.reshape(3,3)\n",
        "print('array2d:\\n',array2d)\n",
        "\n",
        "print('array2d[0:2, 0:2] \\n', array2d[0:2, 0:2])\n",
        "print('array2d[1:3, 0:3] \\n', array2d[1:3, 0:3])\n",
        "print('array2d[1:3, :] \\n', array2d[1:3, :])\n",
        "print('array2d[:, :] \\n', array2d[:, :])\n",
        "print('array2d[:2, 1:] \\n', array2d[:2, 1:])\n",
        "print('array2d[:2, 0] \\n', array2d[:2, 0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLOqT7R9B0Wp"
      },
      "outputs": [],
      "source": [
        "print(array2d[0])\n",
        "print(array2d[1])\n",
        "print('array2d[0] shape:', array2d[0].shape, 'array2d[1] shape:', array2d[1].shape )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQ2YG30oB0Wq"
      },
      "outputs": [],
      "source": [
        "array1d = np.arange(start=1, stop=10)\n",
        "array2d = array1d.reshape(3,3)\n",
        "\n",
        "array3 = array2d[[0,1], 2]\n",
        "print('array2d[[0,1], 2] => ',array3.tolist())\n",
        "\n",
        "array4 = array2d[[0,1], 0:2]\n",
        "print('array2d[[0,1], 0:2] => ',array4.tolist())\n",
        "\n",
        "array5 = array2d[[0,1]]\n",
        "print('array2d[[0,1]] => ',array5.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NgrWk372C9WN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zc-cfhMTB0Wq"
      },
      "outputs": [],
      "source": [
        "array1d = np.arange(start=1, stop=10)\n",
        "# [ ] 안에 array1d > 5 Boolean indexing을 적용\n",
        "array3 = array1d[array1d > 5]\n",
        "print('array1d > 5 불린 인덱싱 결과 값 :', array3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xNWZ33cdB0Wq"
      },
      "outputs": [],
      "source": [
        "array1d > 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2p6BHCc7B0Wr"
      },
      "outputs": [],
      "source": [
        "boolean_indexes = np.array([False, False, False, False, False,  True,  True,  True,  True])\n",
        "array3 = array1d[boolean_indexes]\n",
        "print('불린 인덱스로 필터링 결과 :', array3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7IGC8L_gB0Wr"
      },
      "outputs": [],
      "source": [
        "indexes = np.array([5,6,7,8])\n",
        "array4 = array1d[ indexes ]\n",
        "print('일반 인덱스로 필터링 결과 :',array4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXymP2nEB0Wr"
      },
      "outputs": [],
      "source": [
        "org_array = np.array([ 3, 1, 9, 5])\n",
        "print('원본 행렬:', org_array)\n",
        "# np.sort( )로 정렬\n",
        "sort_array1 = np.sort(org_array)\n",
        "print ('np.sort( ) 호출 후 반환된 정렬 행렬:', sort_array1)\n",
        "print('np.sort( ) 호출 후 원본 행렬:', org_array)\n",
        "# ndarray.sort( )로 정렬\n",
        "sort_array2 = org_array.sort()\n",
        "print('org_array.sort( ) 호출 후 반환된 행렬:', sort_array2)\n",
        "print('org_array.sort( ) 호출 후 원본 행렬:', org_array)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUzxIDHyB0Ws"
      },
      "outputs": [],
      "source": [
        "sort_array1_desc = np.sort(org_array)[::-1]\n",
        "print ('내림차순으로 정렬:', sort_array1_desc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Lm7UHPkB0Ws"
      },
      "outputs": [],
      "source": [
        "array2d = np.array([[8, 12],\n",
        "                   [7, 1 ]])\n",
        "\n",
        "sort_array2d_axis0 = np.sort(array2d, axis=0)\n",
        "print('로우 방향으로 정렬:\\n', sort_array2d_axis0)\n",
        "\n",
        "sort_array2d_axis1 = np.sort(array2d, axis=1)\n",
        "print('컬럼 방향으로 정렬:\\n', sort_array2d_axis1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEcyXqPBB0Wu"
      },
      "outputs": [],
      "source": [
        "org_array = np.array([ 3, 1, 9, 5])\n",
        "sort_indices = np.argsort(org_array)\n",
        "print(type(sort_indices))\n",
        "print('행렬 정렬 시 원본 행렬의 인덱스:', sort_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEVYfhcaB0Wv"
      },
      "outputs": [],
      "source": [
        "org_array = np.array([ 3, 1, 9, 5])\n",
        "sort_indices_desc = np.argsort(org_array)[::-1]\n",
        "print('행렬 내림차순 정렬 시 원본 행렬의 인덱스:', sort_indices_desc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QFRaoF8wB0Wv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "name_array = np.array(['John', 'Mike', 'Sarah', 'Kate', 'Samuel'])\n",
        "score_array= np.array([78, 95, 84, 98, 88])\n",
        "\n",
        "sort_indices_asc = np.argsort(score_array)\n",
        "print('성적 오름차순 정렬 시 score_array의 인덱스:', sort_indices_asc)\n",
        "print('성적 오름차순으로 name_array의 이름 출력:', name_array[sort_indices_asc])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpEp9j2uB0Ww"
      },
      "outputs": [],
      "source": [
        "A = np.array([[1, 2, 3],\n",
        "              [4, 5, 6]])\n",
        "B = np.array([[7, 8],\n",
        "              [9, 10],\n",
        "              [11, 12]])\n",
        "\n",
        "dot_product = np.dot(A, B)\n",
        "print('행렬 내적 결과:\\n', dot_product)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjC5bKeQB0Wx"
      },
      "outputs": [],
      "source": [
        "A = np.array([[1, 2],\n",
        "              [3, 4]])\n",
        "transpose_mat = np.transpose(A)\n",
        "print('A의 전치 행렬:\\n', transpose_mat)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BO1_eO0eE79q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhEVt2duDjMr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6uFIh6N8DjMs"
      },
      "outputs": [],
      "source": [
        "titanic_df = pd.read_csv('titanic_train.csv')\n",
        "print('titanic 변수 type:',type(titanic_df))\n",
        "titanic_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4oqEwdq2DjMs"
      },
      "outputs": [],
      "source": [
        "titanic_df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICHOdOzeDjMs"
      },
      "outputs": [],
      "source": [
        "print('DataFrame 크기: ', titanic_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lghrS1BLDjMt"
      },
      "outputs": [],
      "source": [
        "titanic_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EsbtQ9jODjMt"
      },
      "outputs": [],
      "source": [
        "titanic_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmOvh_mxDjMt"
      },
      "outputs": [],
      "source": [
        "value_counts = titanic_df['Pclass'].value_counts()\n",
        "print(value_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2YAaSDTDjMt"
      },
      "outputs": [],
      "source": [
        "titanic_pclass = titanic_df['Pclass']\n",
        "print(type(titanic_pclass))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xu2I7FY-DjMt"
      },
      "outputs": [],
      "source": [
        "titanic_pclass.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xew_gSKHDjMu"
      },
      "outputs": [],
      "source": [
        "value_counts = titanic_df['Pclass'].value_counts()\n",
        "print(type(value_counts))\n",
        "print(value_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6e29YIrDjMu"
      },
      "outputs": [],
      "source": [
        "print('titanic_df 데이터 건수:', titanic_df.shape[0])\n",
        "print('기본 설정인 dropna=True로 value_counts()')\n",
        "# value_counts()는 디폴트로 dropna=True이므로 value_counts(dropna=True)와 동일.\n",
        "print(titanic_df['Embarked'].value_counts())\n",
        "print(titanic_df['Embarked'].value_counts(dropna=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5NHZxqzFI1d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eIBxrWBSFI1e"
      },
      "outputs": [],
      "source": [
        "titanic_df = pd.read_csv('titanic_train.csv')\n",
        "print('titanic 변수 type:',type(titanic_df))\n",
        "titanic_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ExSIlxIFI1e"
      },
      "outputs": [],
      "source": [
        "titanic_df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8-T1hJwFI1e"
      },
      "outputs": [],
      "source": [
        "print('DataFrame 크기: ', titanic_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dv0Ez3JSFI1e"
      },
      "outputs": [],
      "source": [
        "titanic_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEn3lpW1FI1e"
      },
      "outputs": [],
      "source": [
        "titanic_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aY2N54ZPFI1e"
      },
      "outputs": [],
      "source": [
        "value_counts = titanic_df['Pclass'].value_counts()\n",
        "print(value_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ONiRx0LmFI1e"
      },
      "outputs": [],
      "source": [
        "titanic_pclass = titanic_df['Pclass']\n",
        "print(type(titanic_pclass))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDWLuFQvFI1e"
      },
      "outputs": [],
      "source": [
        "titanic_pclass.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-KkKENOLFI1e"
      },
      "outputs": [],
      "source": [
        "value_counts = titanic_df['Pclass'].value_counts()\n",
        "print(type(value_counts))\n",
        "print(value_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8-JlCGVFI1e"
      },
      "outputs": [],
      "source": [
        "print('titanic_df 데이터 건수:', titanic_df.shape[0])\n",
        "print('기본 설정인 dropna=True로 value_counts()')\n",
        "# value_counts()는 디폴트로 dropna=True이므로 value_counts(dropna=True)와 동일.\n",
        "print(titanic_df['Embarked'].value_counts())\n",
        "print(titanic_df['Embarked'].value_counts(dropna=False))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bmsWoUZdFSqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "NQGd7RWTDjMu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "col_name1=['col1']\n",
        "list1 = [1, 2, 3]\n",
        "array1 = np.array(list1)\n",
        "print('array1 shape:', array1.shape )\n",
        "# 리스트를 이용해 DataFrame 생성.\n",
        "df_list1 = pd.DataFrame(list1, columns=col_name1)\n",
        "print('1차원 리스트로 만든 DataFrame:\\n', df_list1)\n",
        "# 넘파이 ndarray를 이용해 DataFrame 생성.\n",
        "df_array1 = pd.DataFrame(array1, columns=col_name1)\n",
        "print('1차원 ndarray로 만든 DataFrame:\\n', df_array1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LDxmVikBHgoX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCcdTz4PDjMu"
      },
      "outputs": [],
      "source": [
        "# 3개의 칼럼명이 필요함.\n",
        "col_name2=['col1', 'col2', 'col3']\n",
        "\n",
        "# 2행x3열 형태의 리스트와 ndarray 생성한 뒤 이를 DataFrame으로 변환.\n",
        "list2 = [[1, 2, 3],\n",
        "         [11, 12, 13]]\n",
        "array2 = np.array(list2)\n",
        "print('array2 shape:', array2.shape )\n",
        "df_list2 = pd.DataFrame(list2, columns=col_name2)\n",
        "print('2차원 리스트로 만든 DataFrame:\\n', df_list2)\n",
        "df_array2 = pd.DataFrame(array2, columns=col_name2)\n",
        "print('2차원 ndarray로 만든 DataFrame:\\n', df_array2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "AfCKz7k_DjMv"
      },
      "outputs": [],
      "source": [
        "# Key는 컬럼명으로 매핑, Value는 리스트 형(또는 ndarray)\n",
        "dict = {'col1':[1, 11], 'col2':[2, 22], 'col3':[3, 33]}\n",
        "df_dict = pd.DataFrame(dict)\n",
        "print('딕셔너리로 만든 DataFrame:\\n', df_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cjnc8xhjDjMv"
      },
      "outputs": [],
      "source": [
        "# DataFrame을 ndarray로 변환\n",
        "array3 = df_dict.values\n",
        "print('df_dict.values 타입:', type(array3), 'df_dict.values shape:', array3.shape)\n",
        "print(array3)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lT8-XN5-DjMv"
      },
      "outputs": [],
      "source": [
        "# DataFrame을 리스트로 변환\n",
        "list3 = df_dict.values.tolist()\n",
        "print('df_dict.values.tolist() 타입:', type(list3))\n",
        "print(list3)\n",
        "\n",
        "# DataFrame을 딕셔너리로 변환\n",
        "dict3 = df_dict.to_dict('list')\n",
        "print('\\n df_dict.to_dict() 타입:', type(dict3))\n",
        "print(dict3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4B9jhB2UFVk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hY2kH3NSDjMv"
      },
      "outputs": [],
      "source": [
        "titanic_df['Age_0']=0\n",
        "titanic_df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5WZVdBMDjMv"
      },
      "outputs": [],
      "source": [
        "titanic_df['Age_by_10'] = titanic_df['Age']*10\n",
        "titanic_df['Family_No'] = titanic_df['SibSp'] + titanic_df['Parch']+1\n",
        "titanic_df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4dyc-OhQDjMv"
      },
      "outputs": [],
      "source": [
        "titanic_df['Age_by_10'] = titanic_df['Age_by_10'] + 100\n",
        "titanic_df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "po6e5vNRGdys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhBBhePhDjMw"
      },
      "outputs": [],
      "source": [
        "# 원본 파일 재 로딩\n",
        "titanic_df = pd.read_csv('titanic_train.csv')\n",
        "# Index 객체 추출\n",
        "indexes = titanic_df.index\n",
        "print(indexes)\n",
        "# Index 객체를 실제 값 arrray로 변환\n",
        "print('Index 객체 array값:\\n',indexes.values)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MV5fDxfSDjMw"
      },
      "outputs": [],
      "source": [
        "print(type(indexes.values))\n",
        "print(indexes.values.shape)\n",
        "print(indexes[:5].values)\n",
        "print(indexes.values[:5])\n",
        "print(indexes[6])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTNPARWMDjMw"
      },
      "outputs": [],
      "source": [
        "indexes[0] = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tlxw-TDwDjMw"
      },
      "outputs": [],
      "source": [
        "series_fair = titanic_df['Fare']\n",
        "print('Fair Series max 값:', series_fair.max())\n",
        "print('Fair Series sum 값:', series_fair.sum())\n",
        "print('sum() Fair Series:', sum(series_fair))\n",
        "print('Fair Series + 3:\\n',(series_fair + 3).head(3) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K62uHIC4DjMw"
      },
      "outputs": [],
      "source": [
        "titanic_reset_df = titanic_df.reset_index(inplace=False)\n",
        "titanic_reset_df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1JPYWkmDjMw"
      },
      "outputs": [],
      "source": [
        "print('### before reset_index ###')\n",
        "value_counts = titanic_df['Pclass'].value_counts()\n",
        "print(value_counts)\n",
        "print('value_counts 객체 변수 타입:',type(value_counts))\n",
        "\n",
        "new_value_counts = value_counts.reset_index(inplace=False)\n",
        "print('### After reset_index ###')\n",
        "print(new_value_counts)\n",
        "print('new_value_counts 객체 변수 타입:',type(new_value_counts))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_Ou3HodDjMx"
      },
      "outputs": [],
      "source": [
        "print('단일 컬럼 데이터 추출:\\n', titanic_df[ 'Pclass' ].head(3))\n",
        "print('\\n여러 컬럼들의 데이터 추출:\\n', titanic_df[ ['Survived', 'Pclass'] ].head(3))\n",
        "print('[ ] 안에 숫자 index는 KeyError 오류 발생:\\n', titanic_df[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hb_nlowsDjMx"
      },
      "outputs": [],
      "source": [
        "titanic_df[0:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5RYNqdDyDjMy"
      },
      "outputs": [],
      "source": [
        "titanic_df[ titanic_df['Pclass'] == 3].head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVxQ6xkxDjMy"
      },
      "outputs": [],
      "source": [
        "data = {'Name': ['Chulmin', 'Eunkyung','Jinwoong','Soobeom'],\n",
        "        'Year': [2011, 2016, 2015, 2015],\n",
        "        'Gender': ['Male', 'Female', 'Male', 'Male']\n",
        "       }\n",
        "data_df = pd.DataFrame(data, index=['one','two','three','four'])\n",
        "data_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HyrqC8sXDjMy"
      },
      "outputs": [],
      "source": [
        "data_df.iloc[0, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "OvOVjZb0DjMy"
      },
      "outputs": [],
      "source": [
        "# 아래 코드는 오류를 발생시킵니다.\n",
        "data_df.iloc[0, 'Name']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7d5TMjCDjMy"
      },
      "outputs": [],
      "source": [
        "# 아래 코드는 오류를 발생합니다.\n",
        "data_df.iloc['one', 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M70wmzNYDjMz"
      },
      "outputs": [],
      "source": [
        "print(\"\\n 맨 마지막 칼럼 데이터 [:, -1] \\n\", data_df.iloc[:, -1])\n",
        "print(\"\\n 맨 마지막 칼럼을 제외한 모든 데이터 [:, :-1] \\n\", data_df.iloc[: , :-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQEvOMHODjMz"
      },
      "outputs": [],
      "source": [
        "data_df.loc['one', 'Name']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R87Y_CFQDjMz"
      },
      "outputs": [],
      "source": [
        "# 아래 코드는 오류를 발생합니다.\n",
        "data_df_reset.loc[0, 'Name']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yl_3XaP7DjMz"
      },
      "outputs": [],
      "source": [
        "print('위치기반 iloc slicing\\n', data_df.iloc[0:1, 0],'\\n')\n",
        "print('명칭기반 loc slicing\\n', data_df.loc['one':'two', 'Name'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXWaQ1nPDjM0"
      },
      "outputs": [],
      "source": [
        "titanic_df = pd.read_csv('titanic_train.csv')\n",
        "titanic_boolean = titanic_df[titanic_df['Age'] > 60]\n",
        "print(type(titanic_boolean))\n",
        "titanic_boolean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "713WshvfDjM0"
      },
      "outputs": [],
      "source": [
        "titanic_df[titanic_df['Age'] > 60][['Name','Age']].head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yvilZKDqDjM0"
      },
      "outputs": [],
      "source": [
        "titanic_df.loc[titanic_df['Age'] > 60, ['Name','Age']].head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kuOEeFmEDjM0"
      },
      "outputs": [],
      "source": [
        "titanic_df[ (titanic_df['Age'] > 60) & (titanic_df['Pclass']==1) & (titanic_df['Sex']=='female')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aq3hcwCXDjM1"
      },
      "outputs": [],
      "source": [
        "cond1 = titanic_df['Age'] > 60\n",
        "cond2 = titanic_df['Pclass']==1\n",
        "cond3 = titanic_df['Sex']=='female'\n",
        "titanic_df[ cond1 & cond2 & cond3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qau6UixFDjM1"
      },
      "outputs": [],
      "source": [
        "titanic_sorted = titanic_df.sort_values(by=['Name'])\n",
        "titanic_sorted.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KoGI0cO1DjM1"
      },
      "outputs": [],
      "source": [
        "titanic_sorted = titanic_df.sort_values(by=['Pclass', 'Name'], ascending=False)\n",
        "titanic_sorted.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7ZIsI29DjM1"
      },
      "outputs": [],
      "source": [
        "titanic_df.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2CEQNXmDDjM1"
      },
      "outputs": [],
      "source": [
        "titanic_df[['Age', 'Fare']].mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7pCrLiJ_DjM2"
      },
      "outputs": [],
      "source": [
        "titanic_groupby = titanic_df.groupby(by='Pclass')\n",
        "print(type(titanic_groupby))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0C2GUrOxDjM2"
      },
      "outputs": [],
      "source": [
        "titanic_groupby = titanic_df.groupby('Pclass').count()\n",
        "titanic_groupby"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMEAKqz5DjM2"
      },
      "outputs": [],
      "source": [
        "titanic_groupby = titanic_df.groupby('Pclass')[['PassengerId', 'Survived']].count()\n",
        "titanic_groupby"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGdnZLHkDjM2"
      },
      "outputs": [],
      "source": [
        "titanic_df.groupby('Pclass')['Age'].agg([max, min])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uK3nJsZyDjM2"
      },
      "outputs": [],
      "source": [
        "agg_format={'Age':'max', 'SibSp':'sum', 'Fare':'mean'}\n",
        "titanic_df.groupby('Pclass').agg(agg_format)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "psU09ya2G3F4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vkUw9smtDjM3"
      },
      "outputs": [],
      "source": [
        "def get_square(a):\n",
        "    return a**2\n",
        "\n",
        "print('3의 제곱은:',get_square(3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2rYUEfIDjM3"
      },
      "outputs": [],
      "source": [
        "lambda_square = lambda x : x ** 2\n",
        "print('3의 제곱은:',lambda_square(3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FdatalKGDjM3"
      },
      "outputs": [],
      "source": [
        "a=[1,2,3]\n",
        "squares = map(lambda x : x**2, a)\n",
        "list(squares)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0TJ6pvD8DjM3"
      },
      "outputs": [],
      "source": [
        "titanic_df['Name_len']= titanic_df['Name'].apply(lambda x : len(x))\n",
        "titanic_df[['Name','Name_len']].head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TWMTeYGQDjM3"
      },
      "outputs": [],
      "source": [
        "titanic_df['Child_Adult'] = titanic_df['Age'].apply(lambda x : 'Child' if x <=15 else 'Adult' )\n",
        "titanic_df[['Age','Child_Adult']].head(8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRj5Nnj6DjM4"
      },
      "outputs": [],
      "source": [
        "titanic_df['Age_cat'] = titanic_df['Age'].apply(lambda x : 'Child' if x<=15 else ('Adult' if x <= 60 else\n",
        "                                                                                  'Elderly'))\n",
        "titanic_df['Age_cat'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6T8PPQosDjM4"
      },
      "outputs": [],
      "source": [
        "# 나이에 따라 세분화된 분류를 수행하는 함수 생성.\n",
        "def get_category(age):\n",
        "    cat = ''\n",
        "    if age <= 5: cat = 'Baby'\n",
        "    elif age <= 12: cat = 'Child'\n",
        "    elif age <= 18: cat = 'Teenager'\n",
        "    elif age <= 25: cat = 'Student'\n",
        "    elif age <= 35: cat = 'Young Adult'\n",
        "    elif age <= 60: cat = 'Adult'\n",
        "    else : cat = 'Elderly'\n",
        "\n",
        "    return cat\n",
        "\n",
        "# lambda 식에 위에서 생성한 get_category( ) 함수를 반환값으로 지정.\n",
        "# get_category(X)는 입력값으로 ‘Age’ 컬럼 값을 받아서 해당하는 cat 반환\n",
        "titanic_df['Age_cat'] = titanic_df['Age'].apply(lambda x : get_category(x))\n",
        "titanic_df[['Age','Age_cat']].head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zj-SqFquDjM4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "여기서부터 2장 입니다!! 불꽃 데이터 품종 예측하기>>>::"
      ],
      "metadata": {
        "id": "dDBWIOn3HjJA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1mDZ9Xm4Ht2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVT69AgaHgZ3"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CmzYmk-UHgZ4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "iris = load_iris()\n",
        "\n",
        "# iris.data는 Iris 데이터 세트에서 피처(feature)만으로 된 데이터를 numpy로 가지고 있습니다.\n",
        "iris_data = iris.data\n",
        "\n",
        "# iris.target은 붓꽃 데이터 세트에서 레이블(결정 값) 데이터를 numpy로 가지고 있습니다.\n",
        "iris_label = iris.target\n",
        "print('iris target값:', iris_label)\n",
        "print('iris target명:', iris.target_names)\n",
        "\n",
        "# 붓꽃 데이터 세트를 자세히 보기 위해 DataFrame으로 변환합니다.\n",
        "iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)\n",
        "iris_df['label'] = iris.target\n",
        "iris_df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gs2LpXv-HgZ5"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(iris_data, iris_label,\n",
        "                                                    test_size=0.2, random_state=11)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qxnq8qTjHgZ5"
      },
      "outputs": [],
      "source": [
        "dt_clf = DecisionTreeClassifier(random_state=11)\n",
        "\n",
        "# 학습 수행\n",
        "dt_clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygVOJOEpHgZ5"
      },
      "outputs": [],
      "source": [
        "pred = dt_clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9ftXrRuHgZ6"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print('예측 정확도: {0:.4f}'.format(accuracy_score(y_test,pred)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfUuL_yKJ5Su"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "dt_clf = DecisionTreeClassifier()\n",
        "train_data = iris.data\n",
        "train_label = iris.target\n",
        "dt_clf.fit(train_data, train_label)\n",
        "\n",
        "# 학습 데이터 셋으로 예측 수행\n",
        "pred = dt_clf.predict(train_data)\n",
        "print('예측 정확도:',accuracy_score(train_label,pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LIU-6w9ZJ5Sw"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "dt_clf = DecisionTreeClassifier( )\n",
        "iris_data = load_iris()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target,\n",
        "                                                    test_size=0.3, random_state=121)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9bwNatCCJ5Sx"
      },
      "outputs": [],
      "source": [
        "dt_clf.fit(X_train, y_train)\n",
        "pred = dt_clf.predict(X_test)\n",
        "print('예측 정확도: {0:.4f}'.format(accuracy_score(y_test,pred)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oF5yHeJMJ5Sy"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "\n",
        "iris = load_iris()\n",
        "features = iris.data\n",
        "label = iris.target\n",
        "dt_clf = DecisionTreeClassifier(random_state=156)\n",
        "\n",
        "# 5개의 폴드 세트로 분리하는 KFold 객체와 폴드 세트별 정확도를 담을 리스트 객체 생성.\n",
        "kfold = KFold(n_splits=5)\n",
        "cv_accuracy = []\n",
        "print('붓꽃 데이터 세트 크기:',features.shape[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVwkti1qJ5Sy"
      },
      "outputs": [],
      "source": [
        "n_iter = 0\n",
        "\n",
        "# KFold객체의 split( ) 호출하면 폴드 별 학습용, 검증용 테스트의 로우 인덱스를 array로 반환\n",
        "for train_index, test_index  in kfold.split(features):\n",
        "    # kfold.split( )으로 반환된 인덱스를 이용하여 학습용, 검증용 테스트 데이터 추출\n",
        "    X_train, X_test = features[train_index], features[test_index]\n",
        "    y_train, y_test = label[train_index], label[test_index]\n",
        "    #학습 및 예측\n",
        "    dt_clf.fit(X_train , y_train)\n",
        "    pred = dt_clf.predict(X_test)\n",
        "    n_iter += 1\n",
        "    # 반복 시 마다 정확도 측정\n",
        "    accuracy = np.round(accuracy_score(y_test,pred), 4)\n",
        "    train_size = X_train.shape[0]\n",
        "    test_size = X_test.shape[0]\n",
        "    print('\\n#{0} 교차 검증 정확도 :{1}, 학습 데이터 크기: {2}, 검증 데이터 크기: {3}'\n",
        "          .format(n_iter, accuracy, train_size, test_size))\n",
        "    print('#{0} 검증 세트 인덱스:{1}'.format(n_iter,test_index))\n",
        "    cv_accuracy.append(accuracy)\n",
        "\n",
        "# 개별 iteration별 정확도를 합하여 평균 정확도 계산\n",
        "print('\\n## 평균 검증 정확도:', np.mean(cv_accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SL9Ssy1wJ5Sz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "iris = load_iris()\n",
        "\n",
        "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "iris_df['label']=iris.target\n",
        "iris_df['label'].value_counts()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0hpVKaRJ5S0"
      },
      "outputs": [],
      "source": [
        "kfold = KFold(n_splits=3)\n",
        "# kfold.split(X)는 폴드 세트를 3번 반복할 때마다 달라지는 학습/테스트 용 데이터 로우 인덱스 번호 반환.\n",
        "n_iter =0\n",
        "for train_index, test_index  in kfold.split(iris_df):\n",
        "    n_iter += 1\n",
        "    label_train= iris_df['label'].iloc[train_index]\n",
        "    label_test= iris_df['label'].iloc[test_index]\n",
        "    print('## 교차 검증: {0}'.format(n_iter))\n",
        "    print('학습 레이블 데이터 분포:\\n', label_train.value_counts())\n",
        "    print('검증 레이블 데이터 분포:\\n', label_test.value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lph0mnAgJ5S0"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "skf = StratifiedKFold(n_splits=3)\n",
        "n_iter=0\n",
        "\n",
        "for train_index, test_index in skf.split(iris_df, iris_df['label']):\n",
        "    n_iter += 1\n",
        "    label_train= iris_df['label'].iloc[train_index]\n",
        "    label_test= iris_df['label'].iloc[test_index]\n",
        "    print('## 교차 검증: {0}'.format(n_iter))\n",
        "    print('학습 레이블 데이터 분포:\\n', label_train.value_counts())\n",
        "    print('검증 레이블 데이터 분포:\\n', label_test.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8pmPkLe_J5S1"
      },
      "outputs": [],
      "source": [
        "dt_clf = DecisionTreeClassifier(random_state=156)\n",
        "\n",
        "skfold = StratifiedKFold(n_splits=3)\n",
        "n_iter=0\n",
        "cv_accuracy=[]\n",
        "\n",
        "for train_index, test_index  in skfold.split(features, label):\n",
        "       X_train, X_test = features[train_index], features[test_index]\n",
        "    y_train, y_test = label[train_index], label[test_index]\n",
        "    #학습 및 예측\n",
        "    dt_clf.fit(X_train , y_train)\n",
        "    pred = dt_clf.predict(X_test)\n",
        "\n",
        "    n_iter += 1\n",
        "    accuracy = np.round(accuracy_score(y_test,pred), 4)\n",
        "    train_size = X_train.shape[0]\n",
        "    test_size = X_test.shape[0]\n",
        "    print('\\n#{0} 교차 검증 정확도 :{1}, 학습 데이터 크기: {2}, 검증 데이터 크기: {3}'\n",
        "          .format(n_iter, accuracy, train_size, test_size))\n",
        "    print('#{0} 검증 세트 인덱스:{1}'.format(n_iter,test_index))\n",
        "    cv_accuracy.append(accuracy)\n",
        "\n",
        "# 교차 검증별 정확도 및 평균 정확도 계산\n",
        "print('\\n## 교차 검증별 정확도:', np.round(cv_accuracy, 4))\n",
        "print('## 평균 검증 정확도:', np.round(np.mean(cv_accuracy), 4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9WhvrGmpJ5S2"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_val_score , cross_validate\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris_data = load_iris()\n",
        "dt_clf = DecisionTreeClassifier(random_state=156)\n",
        "\n",
        "data = iris_data.data\n",
        "label = iris_data.target\n",
        "\n",
        "# 성능 지표는 정확도(accuracy) , 교차 검증 세트는 3개\n",
        "scores = cross_val_score(dt_clf , data , label , scoring='accuracy',cv=3)\n",
        "print('교차 검증별 정확도:',np.round(scores, 4))\n",
        "print('평균 검증 정확도:', np.round(np.mean(scores), 4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-isUdm3xJ5S3"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# 데이터를 로딩하고 학습데이타와 테스트 데이터 분리\n",
        "iris = load_iris()\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target,\n",
        "                                                    test_size=0.2, random_state=121)\n",
        "dtree = DecisionTreeClassifier()\n",
        "\n",
        "### parameter 들을 dictionary 형태로 설정\n",
        "parameters = {'max_depth':[1,2,3], 'min_samples_split':[2,3]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkvRCqaSJ5S3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# param_grid의 하이퍼 파라미터들을 3개의 train, test set fold 로 나누어서 테스트 수행 설정.\n",
        "### refit=True 가 default 임. True이면 가장 좋은 파라미터 설정으로 재 학습 시킴.\n",
        "grid_dtree = GridSearchCV(dtree, param_grid=parameters, cv=3, refit=True)\n",
        "\n",
        "# 붓꽃 Train 데이터로 param_grid의 하이퍼 파라미터들을 순차적으로 학습/평가 .\n",
        "grid_dtree.fit(X_train, y_train)\n",
        "\n",
        "# GridSearchCV 결과 추출하여 DataFrame으로 변환\n",
        "scores_df = pd.DataFrame(grid_dtree.cv_results_)\n",
        "scores_df[['params', 'mean_test_score', 'rank_test_score', \\\n",
        "           'split0_test_score', 'split1_test_score', 'split2_test_score']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_M1k4VbJ5S3"
      },
      "outputs": [],
      "source": [
        "print('GridSearchCV 최적 파라미터:', grid_dtree.best_params_)\n",
        "print('GridSearchCV 최고 정확도: {0:.4f}'.format(grid_dtree.best_score_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbP3XiinJ5S3"
      },
      "outputs": [],
      "source": [
        "# GridSearchCV의 refit으로 이미 학습이 된 estimator 반환\n",
        "estimator = grid_dtree.best_estimator_\n",
        "\n",
        "# GridSearchCV의 best_estimator_는 이미 최적 하이퍼 파라미터로 학습이 됨\n",
        "pred = estimator.predict(X_test)\n",
        "print('테스트 데이터 세트 정확도: {0:.4f}'.format(accuracy_score(y_test,pred)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7_7OM3gKe4X"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "items=['TV','냉장고','전자레인지','컴퓨터','선풍기','선풍기','믹서','믹서']\n",
        "\n",
        "# LabelEncoder를 객체로 생성한 후 , fit( ) 과 transform( ) 으로 label 인코딩 수행.\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(items)\n",
        "labels = encoder.transform(items)\n",
        "print('인코딩 변환값:',labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgNFBDztKe4Z"
      },
      "outputs": [],
      "source": [
        "print('인코딩 클래스:',encoder.classes_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9hiB6RPnKe4Z"
      },
      "outputs": [],
      "source": [
        "print('디코딩 원본 값:',encoder.inverse_transform([4, 5, 2, 0, 1, 1, 3, 3]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXgi5HzKKe4a"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np\n",
        "\n",
        "items=['TV','냉장고','전자레인지','컴퓨터','선풍기','선풍기','믹서','믹서']\n",
        "\n",
        "# 2차원 ndarray로 변환합니다.\n",
        "items = np.array(items).reshape(-1, 1)\n",
        "\n",
        "# 원-핫 인코딩을 적용합니다.\n",
        "oh_encoder = OneHotEncoder()\n",
        "oh_encoder.fit(items)\n",
        "oh_labels = oh_encoder.transform(items)\n",
        "\n",
        "# OneHotEncoder로 변환한 결과는 희소행렬이므로 toarray()를 이용해 밀집 행렬로 변환.\n",
        "print('원-핫 인코딩 데이터')\n",
        "print(oh_labels.toarray())\n",
        "print('원-핫 인코딩 데이터 차원')\n",
        "print(oh_labels.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a03XPEjKKe4a"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame({'item':['TV','냉장고','전자레인지','컴퓨터','선풍기','선풍기','믹서','믹서'] })\n",
        "pd.get_dummies(df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qo734yUaMDi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02modrPkKe4b"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "import pandas as pd\n",
        "# 붓꽃 데이터 셋을 로딩하고 DataFrame으로 변환합니다.\n",
        "iris = load_iris()\n",
        "iris_data = iris.data\n",
        "iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)\n",
        "\n",
        "print('feature 들의 평균 값')\n",
        "print(iris_df.mean())\n",
        "print('\\nfeature 들의 분산 값')\n",
        "print(iris_df.var())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1wHfU3fHKe4b"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# StandardScaler객체 생성\n",
        "scaler = StandardScaler()\n",
        "# StandardScaler 로 데이터 셋 변환. fit( ) 과 transform( ) 호출.\n",
        "scaler.fit(iris_df)\n",
        "iris_scaled = scaler.transform(iris_df)\n",
        "\n",
        "#transform( )시 scale 변환된 데이터 셋이 numpy ndarry로 반환되어 이를 DataFrame으로 변환\n",
        "iris_df_scaled = pd.DataFrame(data=iris_scaled, columns=iris.feature_names)\n",
        "print('feature 들의 평균 값')\n",
        "print(iris_df_scaled.mean())\n",
        "print('\\nfeature 들의 분산 값')\n",
        "print(iris_df_scaled.var())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pvqhSWNsKe4b"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# MinMaxScaler객체 생성\n",
        "scaler = MinMaxScaler()\n",
        "# MinMaxScaler 로 데이터 셋 변환. fit() 과 transform() 호출.\n",
        "scaler.fit(iris_df)\n",
        "iris_scaled = scaler.transform(iris_df)\n",
        "\n",
        "# transform()시 scale 변환된 데이터 셋이 numpy ndarry로 반환되어 이를 DataFrame으로 변환\n",
        "iris_df_scaled = pd.DataFrame(data=iris_scaled, columns=iris.feature_names)\n",
        "print('feature들의 최솟값')\n",
        "print(iris_df_scaled.min())\n",
        "print('\\nfeature들의 최댓값')\n",
        "print(iris_df_scaled.max())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhNCIHbiKe4c"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "\n",
        "train_array = np.arange(0, 11).reshape(-1, 1)\n",
        "test_array =  np.arange(0, 6).reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_GR2rgtLKe4c"
      },
      "outputs": [],
      "source": [
        "# MinMaxScaler 객체에 별도의 feature_range 파라미터 값을 지정하지 않으면 0~1 값으로 변환\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# fit()하게 되면 train_array 데이터의 최솟값이 0, 최댓값이 10으로 설정.\n",
        "scaler.fit(train_array)\n",
        "\n",
        "# 1/10 scale로 train_array 데이터 변환함. 원본 10-> 1로 변환됨.\n",
        "train_scaled = scaler.transform(train_array)\n",
        "\n",
        "print('원본 train_array 데이터:', np.round(train_array.reshape(-1), 2))\n",
        "print('Scale된 train_array 데이터:', np.round(train_scaled.reshape(-1), 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0cq2SZVKe4d"
      },
      "outputs": [],
      "source": [
        "# MinMaxScaler에 test_array를 fit()하게 되면 원본 데이터의 최솟값이 0, 최댓값이 5로 설정됨\n",
        "scaler.fit(test_array)\n",
        "\n",
        "# 1/5 scale로 test_array 데이터 변환함. 원본 5->1로 변환.\n",
        "test_scaled = scaler.transform(test_array)\n",
        "\n",
        "# test_array의 scale 변환 출력.\n",
        "print('원본 test_array 데이터:', np.round(test_array.reshape(-1), 2))\n",
        "print('Scale된 test_array 데이터:', np.round(test_scaled.reshape(-1), 2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTvDIT7zKe4d"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler()\n",
        "scaler.fit(train_array)\n",
        "train_scaled = scaler.transform(train_array)\n",
        "print('원본 train_array 데이터:', np.round(train_array.reshape(-1), 2))\n",
        "print('Scale된 train_array 데이터:', np.round(train_scaled.reshape(-1), 2))\n",
        "\n",
        "# test_array에 Scale 변환을 할 때는 반드시 fit()을 호출하지 않고 transform() 만으로 변환해야 함.\n",
        "test_scaled = scaler.transform(test_array)\n",
        "print('\\n원본 test_array 데이터:', np.round(test_array.reshape(-1), 2))\n",
        "print('Scale된 test_array 데이터:', np.round(test_scaled.reshape(-1), 2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "여기서부터 3장입니다!!"
      ],
      "metadata": {
        "id": "8ml6JT5-NP3k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBuOH8vbNe2M",
        "outputId": "6e30e914-66a8-4cc9-dd91-1a8fa9869376"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.0.2\n"
          ]
        }
      ],
      "source": [
        "import sklearn\n",
        "\n",
        "print(sklearn.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mpc23-jINe2O"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.base import BaseEstimator\n",
        "\n",
        "class MyDummyClassifier(BaseEstimator):\n",
        "    # fit( ) 메소드는 아무것도 학습하지 않음.\n",
        "    def fit(self, X , y=None):\n",
        "        pass\n",
        "\n",
        "    # predict( ) 메소드는 단순히 Sex feature가 1 이면 0 , 그렇지 않으면 1 로 예측함.\n",
        "    def predict(self, X):\n",
        "        pred = np.zeros( ( X.shape[0], 1 ))\n",
        "        for i in range (X.shape[0]) :\n",
        "            if X['Sex'].iloc[i] == 1:\n",
        "                pred[i] = 0\n",
        "            else :\n",
        "                pred[i] = 1\n",
        "\n",
        "        return pred\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVeLnxXUNe2O"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Null 처리 함수\n",
        "def fillna(df):\n",
        "    df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
        "    df['Cabin'].fillna('N', inplace=True)\n",
        "    df['Embarked'].fillna('N', inplace=True)\n",
        "    df['Fare'].fillna(0, inplace=True)\n",
        "    return df\n",
        "\n",
        "# 머신러닝 알고리즘에 불필요한 피처 제거\n",
        "def drop_features(df):\n",
        "    df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)\n",
        "    return df\n",
        "\n",
        "# 레이블 인코딩 수행.\n",
        "def format_features(df):\n",
        "    df['Cabin'] = df['Cabin'].str[:1]\n",
        "    features = ['Cabin', 'Sex', 'Embarked']\n",
        "    for feature in features:\n",
        "        le = LabelEncoder()\n",
        "        le = le.fit(df[feature])\n",
        "        df[feature] = le.transform(df[feature])\n",
        "    return df\n",
        "\n",
        "# 앞에서 설정한 데이터 전처리 함수 호출\n",
        "def transform_features(df):\n",
        "    df = fillna(df)\n",
        "    df = drop_features(df)\n",
        "    df = format_features(df)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dn-xemFeNe2O",
        "outputId": "1c2ba8a6-3977-499f-8594-326d4b4c83ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dummy Classifier의 정확도는: 0.7877\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 원본 데이터를 재로딩, 데이터 가공, 학습 데이터/테스트 데이터 분할.\n",
        "titanic_df = pd.read_csv('./titanic_train.csv')\n",
        "y_titanic_df = titanic_df['Survived']\n",
        "X_titanic_df= titanic_df.drop('Survived', axis=1)\n",
        "X_titanic_df = transform_features(X_titanic_df)\n",
        "X_train, X_test, y_train, y_test=train_test_split(X_titanic_df, y_titanic_df,\n",
        "                                                  test_size=0.2, random_state=0)\n",
        "\n",
        "# 위에서 생성한 Dummy Classifier를 이용해 학습/예측/평가 수행.\n",
        "myclf = MyDummyClassifier()\n",
        "myclf.fit(X_train, y_train)\n",
        "\n",
        "mypredictions = myclf.predict(X_test)\n",
        "print('Dummy Classifier의 정확도는: {0:.4f}'.format(accuracy_score(y_test, mypredictions)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ieX37rCANe2P",
        "outputId": "2a61968b-fdf3-4520-ae00-70747b0476e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 0.  0.  5. ...  0.  0.  0.]\n",
            " [ 0.  0.  0. ... 10.  0.  0.]\n",
            " [ 0.  0.  0. ... 16.  9.  0.]\n",
            " ...\n",
            " [ 0.  0.  1. ...  6.  0.  0.]\n",
            " [ 0.  0.  2. ... 12.  0.  0.]\n",
            " [ 0.  0. 10. ... 12.  1.  0.]]\n",
            "### digits.data.shape: (1797, 64)\n",
            "[0 1 2 ... 8 9 8]\n",
            "### digits.target.shape: (1797,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.base import BaseEstimator\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "class MyFakeClassifier(BaseEstimator):\n",
        "    def fit(self,X,y):\n",
        "        pass\n",
        "\n",
        "    # 입력값으로 들어오는 X 데이터 셋의 크기만큼 모두 0값으로 만들어서 반환\n",
        "    def predict(self,X):\n",
        "        return np.zeros( (len(X), 1) , dtype=bool)\n",
        "\n",
        "# 사이킷런의 내장 데이터 셋인 load_digits( )를 이용하여 MNIST 데이터 로딩\n",
        "digits = load_digits()\n",
        "\n",
        "print(digits.data)\n",
        "print(\"### digits.data.shape:\", digits.data.shape)\n",
        "print(digits.target)\n",
        "print(\"### digits.target.shape:\", digits.target.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PaETeYppNe2P",
        "outputId": "79856d66-1f67-4553-aecb-4565aa3ffe2c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([False, False, False, ..., False, False, False])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "digits.target == 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65RX6pQwNe2P"
      },
      "outputs": [],
      "source": [
        "# digits번호가 7번이면 True이고 이를 astype(int)로 1로 변환, 7번이 아니면 False이고 0으로 변환.\n",
        "y = (digits.target == 7).astype(int)\n",
        "X_train, X_test, y_train, y_test = train_test_split( digits.data, y, random_state=11)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwhNtLTCNe2P",
        "outputId": "b956ea62-5bfd-4980-d2ee-882e401759c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "레이블 테스트 세트 크기 : (450,)\n",
            "테스트 세트 레이블 0 과 1의 분포도\n",
            "0    405\n",
            "1     45\n",
            "dtype: int64\n",
            "모든 예측을 0으로 하여도 정확도는:0.900\n"
          ]
        }
      ],
      "source": [
        "# 불균형한 레이블 데이터 분포도 확인.\n",
        "print('레이블 테스트 세트 크기 :', y_test.shape)\n",
        "print('테스트 세트 레이블 0 과 1의 분포도')\n",
        "print(pd.Series(y_test).value_counts())\n",
        "\n",
        "# Dummy Classifier로 학습/예측/정확도 평가\n",
        "fakeclf = MyFakeClassifier()\n",
        "fakeclf.fit(X_train , y_train)\n",
        "fakepred = fakeclf.predict(X_test)\n",
        "print('모든 예측을 0으로 하여도 정확도는:{:.3f}'.format(accuracy_score(y_test , fakepred)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e4mT6e8HNnBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "io611fgpNe2T",
        "outputId": "bff3cdbb-b95f-4b2f-bbb2-6a041685361a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 스코어: 0.7966\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1 = f1_score(y_test , pred)\n",
        "print('F1 스코어: {0:.4f}'.format(f1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dAxPCg4dNe2T",
        "outputId": "884dd771-33a7-452b-e074-e74b3ac88a71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "임곗값: 0.4\n",
            "오차 행렬\n",
            "[[97 21]\n",
            " [11 50]]\n",
            "정확도: 0.8212, 정밀도: 0.7042, 재현율: 0.8197, F1:0.7576\n",
            "임곗값: 0.45\n",
            "오차 행렬\n",
            "[[105  13]\n",
            " [ 13  48]]\n",
            "정확도: 0.8547, 정밀도: 0.7869, 재현율: 0.7869, F1:0.7869\n",
            "임곗값: 0.5\n",
            "오차 행렬\n",
            "[[108  10]\n",
            " [ 14  47]]\n",
            "정확도: 0.8659, 정밀도: 0.8246, 재현율: 0.7705, F1:0.7966\n",
            "임곗값: 0.55\n",
            "오차 행렬\n",
            "[[111   7]\n",
            " [ 16  45]]\n",
            "정확도: 0.8715, 정밀도: 0.8654, 재현율: 0.7377, F1:0.7965\n",
            "임곗값: 0.6\n",
            "오차 행렬\n",
            "[[113   5]\n",
            " [ 17  44]]\n",
            "정확도: 0.8771, 정밀도: 0.8980, 재현율: 0.7213, F1:0.8000\n"
          ]
        }
      ],
      "source": [
        "def get_clf_eval(y_test , pred):\n",
        "    confusion = confusion_matrix( y_test, pred)\n",
        "    accuracy = accuracy_score(y_test , pred)\n",
        "    precision = precision_score(y_test , pred)\n",
        "    recall = recall_score(y_test , pred)\n",
        "    # F1 스코어 추가\n",
        "    f1 = f1_score(y_test,pred)\n",
        "    print('오차 행렬')\n",
        "    print(confusion)\n",
        "    # f1 score print 추가\n",
        "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}, F1:{3:.4f}'.format(accuracy, precision, recall, f1))\n",
        "\n",
        "thresholds = [0.4 , 0.45 , 0.50 , 0.55 , 0.60]\n",
        "pred_proba = lr_clf.predict_proba(X_test)\n",
        "get_eval_by_threshold(y_test, pred_proba[:,1].reshape(-1,1), thresholds)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4Ct6b1vNe2U",
        "outputId": "82404971-85c6-40ef-8a4d-445cffe3b2e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "샘플 추출을 위한 임곗값 배열의 index: [ 1  6 11 16 21 26 31 36 41 46]\n",
            "샘플 index로 추출한 임곗값:  [0.94 0.73 0.62 0.52 0.44 0.28 0.15 0.14 0.13 0.12]\n",
            "샘플 임곗값별 FPR:  [0.    0.008 0.025 0.076 0.127 0.254 0.576 0.61  0.746 0.847]\n",
            "샘플 임곗값별 TPR:  [0.016 0.492 0.705 0.738 0.803 0.885 0.902 0.951 0.967 1.   ]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "# 레이블 값이 1일때의 예측 확률을 추출\n",
        "pred_proba_class1 = lr_clf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "fprs , tprs , thresholds = roc_curve(y_test, pred_proba_class1)\n",
        "# 반환된 임곗값 배열에서 샘플로 데이터를 추출하되, 임곗값을 5 Step으로 추출.\n",
        "# thresholds[0]은 max(예측확률)+1로 임의 설정됨. 이를 제외하기 위해 np.arange는 1부터 시작\n",
        "thr_index = np.arange(1, thresholds.shape[0], 5)\n",
        "print('샘플 추출을 위한 임곗값 배열의 index:', thr_index)\n",
        "print('샘플 index로 추출한 임곗값: ', np.round(thresholds[thr_index], 2))\n",
        "\n",
        "# 5 step 단위로 추출된 임계값에 따른 FPR, TPR 값\n",
        "print('샘플 임곗값별 FPR: ', np.round(fprs[thr_index], 3))\n",
        "print('샘플 임곗값별 TPR: ', np.round(tprs[thr_index], 3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJbikG5RNe2U",
        "outputId": "270cf704-9a5d-4c7b-a6dd-9090839fa036"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC AUC 값: 0.8987\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "pred_proba = lr_clf.predict_proba(X_test)[:, 1]\n",
        "roc_score = roc_auc_score(y_test, pred_proba)\n",
        "print('ROC AUC 값: {0:.4f}'.format(roc_score))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlTB96pqNe2U"
      },
      "outputs": [],
      "source": [
        "def get_clf_eval(y_test, pred=None, pred_proba=None):\n",
        "    confusion = confusion_matrix( y_test, pred)\n",
        "    accuracy = accuracy_score(y_test , pred)\n",
        "    precision = precision_score(y_test , pred)\n",
        "    recall = recall_score(y_test , pred)\n",
        "    f1 = f1_score(y_test,pred)\n",
        "    # ROC-AUC 추가\n",
        "    roc_auc = roc_auc_score(y_test, pred_proba)\n",
        "    print('오차 행렬')\n",
        "    print(confusion)\n",
        "    # ROC-AUC print 추가\n",
        "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\\\n",
        "          F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSGIG5xeOFrq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
        "from sklearn.metrics import f1_score, confusion_matrix, precision_recall_curve, roc_curve\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "diabetes_data = pd.read_csv('diabetes.csv')\n",
        "print(diabetes_data['Outcome'].value_counts())\n",
        "diabetes_data.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpiIUA0JOFrt"
      },
      "outputs": [],
      "source": [
        "# 수정된 get_clf_eval() 함수\n",
        "def get_clf_eval(y_test, pred=None, pred_proba=None):\n",
        "    confusion = confusion_matrix( y_test, pred)\n",
        "    accuracy = accuracy_score(y_test , pred)\n",
        "    precision = precision_score(y_test , pred)\n",
        "    recall = recall_score(y_test , pred)\n",
        "    f1 = f1_score(y_test,pred)\n",
        "    # ROC-AUC 추가\n",
        "    roc_auc = roc_auc_score(y_test, pred_proba)\n",
        "    print('오차 행렬')\n",
        "    print(confusion)\n",
        "    # ROC-AUC print 추가\n",
        "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\\\n",
        "    F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y40eUZdvOFrt"
      },
      "outputs": [],
      "source": [
        "def precision_recall_curve_plot(y_test=None, pred_proba_c1=None):\n",
        "    # threshold ndarray와 이 threshold에 따른 정밀도, 재현율 ndarray 추출.\n",
        "    precisions, recalls, thresholds = precision_recall_curve( y_test, pred_proba_c1)\n",
        "\n",
        "    # X축을 threshold값으로, Y축은 정밀도, 재현율 값으로 각각 Plot 수행. 정밀도는 점선으로 표시\n",
        "    plt.figure(figsize=(8,6))\n",
        "    threshold_boundary = thresholds.shape[0]\n",
        "    plt.plot(thresholds, precisions[0:threshold_boundary], linestyle='--', label='precision')\n",
        "    plt.plot(thresholds, recalls[0:threshold_boundary],label='recall')\n",
        "\n",
        "    # threshold 값 X 축의 Scale을 0.1 단위로 변경\n",
        "    start, end = plt.xlim()\n",
        "    plt.xticks(np.round(np.arange(start, end, 0.1),2))\n",
        "\n",
        "    # x축, y축 label과 legend, 그리고 grid 설정\n",
        "    plt.xlabel('Threshold value'); plt.ylabel('Precision and Recall value')\n",
        "    plt.legend(); plt.grid()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNyF-1YNOFru"
      },
      "outputs": [],
      "source": [
        "# 피처 데이터 세트 X, 레이블 데이터 세트 y를 추출.\n",
        "# 맨 끝이 Outcome 컬럼으로 레이블 값임. 컬럼 위치 -1을 이용해 추출\n",
        "X = diabetes_data.iloc[:, :-1]\n",
        "y = diabetes_data.iloc[:, -1]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 156, stratify=y)\n",
        "\n",
        "# 로지스틱 회귀로 학습,예측 및 평가 수행.\n",
        "lr_clf = LogisticRegression(solver='liblinear')\n",
        "lr_clf.fit(X_train , y_train)\n",
        "pred = lr_clf.predict(X_test)\n",
        "pred_proba = lr_clf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "get_clf_eval(y_test , pred, pred_proba)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "BJaaWUxTOFrv"
      },
      "outputs": [],
      "source": [
        "X = diabetes_data.iloc[:, :-1]\n",
        "y = diabetes_data.iloc[:, -1]\n",
        "\n",
        "# StandardScaler 클래스를 이용해 피처 데이터 세트에 일괄적으로 스케일링 적용\n",
        "scaler = StandardScaler( )\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size = 0.2, random_state = 156, stratify=y)\n",
        "\n",
        "# 로지스틱 회귀로 학습, 예측 및 평가 수행.\n",
        "lr_clf = LogisticRegression()\n",
        "lr_clf.fit(X_train , y_train)\n",
        "pred = lr_clf.predict(X_test)\n",
        "pred_proba = lr_clf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "get_clf_eval(y_test , pred, pred_proba)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_f7zYRV8OFrv"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import Binarizer\n",
        "\n",
        "def get_eval_by_threshold(y_test , pred_proba_c1, thresholds):\n",
        "    # thresholds 리스트 객체내의 값을 차례로 iteration하면서 Evaluation 수행.\n",
        "    for custom_threshold in thresholds:\n",
        "        binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_c1)\n",
        "        custom_predict = binarizer.transform(pred_proba_c1)\n",
        "        print('임곗값:',custom_threshold)\n",
        "        get_clf_eval(y_test , custom_predict, pred_proba_c1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wui-uDn2OFrw"
      },
      "outputs": [],
      "source": [
        "# 임곗값를 0.48로 설정한 Binarizer 생성\n",
        "binarizer = Binarizer(threshold=0.48)\n",
        "\n",
        "# 위에서 구한 lr_clf의 predict_proba() 예측 확률 array에서 1에 해당하는 컬럼값을 Binarizer변환.\n",
        "pred_th_048 = binarizer.fit_transform(pred_proba[:, 1].reshape(-1,1))\n",
        "\n",
        "get_clf_eval(y_test , pred_th_048, pred_proba[:, 1])\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}