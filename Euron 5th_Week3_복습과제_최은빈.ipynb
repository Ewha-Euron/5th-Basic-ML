{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oW4LpW9lRj3n"
   },
   "source": [
    "# **1. GBM**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s3_1vAdpRxoo"
   },
   "source": [
    "## **1-a. `creditcard.csv`를 다운받은 후 실습을 진행해 주세요.**\n",
    "- 데이터 출처: [Credit Card Fraud Detection](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3vR5gQ4HYGAX"
   },
   "outputs": [],
   "source": [
    "## Colab - 구글 드라이브 마운트\n",
    "# Colab을 사용하시는 분들만 실행시켜 주시면 됩니다.\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "lkOKaEKZG2Yn"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"C:/Users/Flex/Documents/Euron/creditcard.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2_tC0W-5Ryje"
   },
   "source": [
    "## **1-b. GradientBoostingClassifier을 이용하여 훈련 데이터를 fit한 후, GBM 정확도와 수행시간을 구하세요.**\n",
    "(test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "7zBOFln9ZENb"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "967Hgk2YZXfa",
    "outputId": "aa8b3623-a718-43f5-d07d-87cd0ec29b85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM 정확도: 0.9989\n"
     ]
    }
   ],
   "source": [
    "## 데이터 분할: 훈련 데이터와 테스트 데이터\n",
    "\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "## GBM 모델링\n",
    "# 아래에 코드를 작성해 주세요.\n",
    "gb_clf = GradientBoostingClassifier(random_state = 42)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "gb_pred= gb_clf.predict(X_test)\n",
    "gb_accuracy = accuracy_score(y_test, gb_pred)\n",
    "\n",
    "print('GBM 정확도: {0:.4f}'.format(gb_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0_npf7xNR1BZ"
   },
   "source": [
    "## **1-b(2). GBM으로 학습하는 시간이 얼마나 걸리는지 수행 시간을 출력해 주세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FdMUSczWa8_A",
    "outputId": "c47927fd-a125-4cab-a190-761f256d0009"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM 수행 시간: 886.7 초\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "gb_clf = GradientBoostingClassifier(random_state = 42)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "print('GBM 수행 시간: {0:.1f} 초'.format(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xqzN9Hy8TaOk"
   },
   "source": [
    "## **1-c. ```subsample``` 파라미터를 설정하여 gbm 모델을 학습시키고 학습 시간을 비교해 보세요.**  \n",
    "(subsample = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "FxWwRW_7TbT0"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4HAD9Ebsgte4",
    "outputId": "78b3f503-efbf-44f5-d170-4a05d34651e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM (subsample = 0.8) 정확도: 0.9985\n",
      "GBM (subsample = 0.8) 정확도: 1695905827.3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "gbm_clf = GradientBoostingClassifier(subsample=0.8)\n",
    "gbm_clf.fit(X_train, y_train)\n",
    "gbm_pred = gbm_clf.predict(X_test)\n",
    "gbm_accuracy = accuracy_score(y_test, gbm_pred)\n",
    "gbm_start_time = time.time()\n",
    "\n",
    "print('GBM (subsample = 0.8) 정확도: {0:.4f}'.format(gbm_accuracy))\n",
    "print('GBM (subsample = 0.8) 수행 시간: {0:.1f}'.format(gbm_start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D52196vv7JoI"
   },
   "source": [
    "# **2. XGBoost**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "koZCKhp8HW4o"
   },
   "source": [
    "- 모델 : Python Wrapper XGBoost\n",
    "- 적용 데이터 : 위스콘신 유방암 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ECMkbXJ-7KT6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.3\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "\n",
    "print(xgboost.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5kFl0zeC7tQR"
   },
   "source": [
    "- 출력 : 1.7.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "fHDjuv_V7vAf"
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L11sPCSZ74oH"
   },
   "source": [
    "##**2-a. cancer_df의 shape을 프린트하고, 상위 5개 행을 확인해 주세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "4wBOlQxn72Te"
   },
   "outputs": [],
   "source": [
    "dataset = load_breast_cancer()\n",
    "X_features = dataset.data\n",
    "y_label = dataset.target\n",
    "\n",
    "cancer_df = pd.DataFrame(data = X_features, columns = dataset.feature_names)\n",
    "cancer_df['target'] = y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "cMfEC-nZ8HH-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 31)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "3          0.6638                  0.17300       0  \n",
       "4          0.2364                  0.07678       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(cancer_df.shape)\n",
    "cancer_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tOKlsQLD8HoD"
   },
   "source": [
    "## **2-b. 전체 데이터 중 80%는 학습용 데이터, 20%는 테스트용 데이터로 추출하고, 각각의 shape을 print해주세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "o6k1w2nf8SCm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455, 30) (114, 30)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y_label, test_size = 0.2, random_state = 156)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "9ZB87ux88a6w"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xgboost.core.DMatrix object at 0x000001E88C6B3850>\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(data = X_train, label = y_train)\n",
    "dtest = xgb.DMatrix(data = X_test, label = y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tzzNfY028f5b"
   },
   "source": [
    "##**2-c. 주어진 정보를 바탕으로 하이퍼 파라미터 목록을 완성해 주세요.**\n",
    "- 트리의 최대 깊이 : 3\n",
    "- 학습률 : 0.1\n",
    "- 반복 횟수 : 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "BZIEP5CS8jSs"
   },
   "outputs": [],
   "source": [
    "params = {'max_depth':3,\n",
    "          'eta':0.1,\n",
    "          'objective':'binary:logistic',\n",
    "          'eval_metric':'logloss'\n",
    "         }\n",
    "num_rounds = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "UInEOEh98t6z"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<xgboost.core.DMatrix at 0x1e88c6b3850>, 'train'),\n",
       " (<xgboost.core.DMatrix at 0x1e88c6b3d30>, 'eval')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_list = [(dtrain,'train'),(dtest,'eval')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mzl7NufX8utk"
   },
   "source": [
    "## **2-d. 하이퍼 파라미터를 `train( )` 함수의 파라미터로 전달해 주세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "5vgia5qw8vCa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.60969\teval-logloss:0.61352\n",
      "[1]\ttrain-logloss:0.54080\teval-logloss:0.54784\n",
      "[2]\ttrain-logloss:0.48375\teval-logloss:0.49425\n",
      "[3]\ttrain-logloss:0.43446\teval-logloss:0.44799\n",
      "[4]\ttrain-logloss:0.39055\teval-logloss:0.40911\n",
      "[5]\ttrain-logloss:0.35415\teval-logloss:0.37498\n",
      "[6]\ttrain-logloss:0.32122\teval-logloss:0.34571\n",
      "[7]\ttrain-logloss:0.29259\teval-logloss:0.32053\n",
      "[8]\ttrain-logloss:0.26747\teval-logloss:0.29721\n",
      "[9]\ttrain-logloss:0.24515\teval-logloss:0.27799\n",
      "[10]\ttrain-logloss:0.22569\teval-logloss:0.26030\n",
      "[11]\ttrain-logloss:0.20794\teval-logloss:0.24604\n",
      "[12]\ttrain-logloss:0.19218\teval-logloss:0.23156\n",
      "[13]\ttrain-logloss:0.17792\teval-logloss:0.22005\n",
      "[14]\ttrain-logloss:0.16522\teval-logloss:0.20857\n",
      "[15]\ttrain-logloss:0.15362\teval-logloss:0.19999\n",
      "[16]\ttrain-logloss:0.14333\teval-logloss:0.19012\n",
      "[17]\ttrain-logloss:0.13398\teval-logloss:0.18182\n",
      "[18]\ttrain-logloss:0.12560\teval-logloss:0.17473\n",
      "[19]\ttrain-logloss:0.11729\teval-logloss:0.16766\n",
      "[20]\ttrain-logloss:0.10969\teval-logloss:0.15820\n",
      "[21]\ttrain-logloss:0.10297\teval-logloss:0.15472\n",
      "[22]\ttrain-logloss:0.09707\teval-logloss:0.14895\n",
      "[23]\ttrain-logloss:0.09143\teval-logloss:0.14331\n",
      "[24]\ttrain-logloss:0.08634\teval-logloss:0.13634\n",
      "[25]\ttrain-logloss:0.08131\teval-logloss:0.13278\n",
      "[26]\ttrain-logloss:0.07686\teval-logloss:0.12791\n",
      "[27]\ttrain-logloss:0.07284\teval-logloss:0.12526\n",
      "[28]\ttrain-logloss:0.06925\teval-logloss:0.11998\n",
      "[29]\ttrain-logloss:0.06555\teval-logloss:0.11641\n",
      "[30]\ttrain-logloss:0.06241\teval-logloss:0.11450\n",
      "[31]\ttrain-logloss:0.05959\teval-logloss:0.11257\n",
      "[32]\ttrain-logloss:0.05710\teval-logloss:0.11154\n",
      "[33]\ttrain-logloss:0.05441\teval-logloss:0.10868\n",
      "[34]\ttrain-logloss:0.05204\teval-logloss:0.10668\n",
      "[35]\ttrain-logloss:0.04975\teval-logloss:0.10421\n",
      "[36]\ttrain-logloss:0.04775\teval-logloss:0.10296\n",
      "[37]\ttrain-logloss:0.04585\teval-logloss:0.10058\n",
      "[38]\ttrain-logloss:0.04401\teval-logloss:0.09868\n",
      "[39]\ttrain-logloss:0.04226\teval-logloss:0.09644\n",
      "[40]\ttrain-logloss:0.04065\teval-logloss:0.09587\n",
      "[41]\ttrain-logloss:0.03913\teval-logloss:0.09424\n",
      "[42]\ttrain-logloss:0.03738\teval-logloss:0.09471\n",
      "[43]\ttrain-logloss:0.03611\teval-logloss:0.09427\n",
      "[44]\ttrain-logloss:0.03494\teval-logloss:0.09389\n",
      "[45]\ttrain-logloss:0.03365\teval-logloss:0.09418\n",
      "[46]\ttrain-logloss:0.03253\teval-logloss:0.09402\n",
      "[47]\ttrain-logloss:0.03148\teval-logloss:0.09236\n",
      "[48]\ttrain-logloss:0.03039\teval-logloss:0.09301\n",
      "[49]\ttrain-logloss:0.02947\teval-logloss:0.09127\n",
      "[50]\ttrain-logloss:0.02854\teval-logloss:0.09005\n",
      "[51]\ttrain-logloss:0.02753\teval-logloss:0.08961\n",
      "[52]\ttrain-logloss:0.02656\teval-logloss:0.08958\n",
      "[53]\ttrain-logloss:0.02568\teval-logloss:0.09070\n",
      "[54]\ttrain-logloss:0.02500\teval-logloss:0.08958\n",
      "[55]\ttrain-logloss:0.02430\teval-logloss:0.09036\n",
      "[56]\ttrain-logloss:0.02357\teval-logloss:0.09159\n",
      "[57]\ttrain-logloss:0.02296\teval-logloss:0.09153\n",
      "[58]\ttrain-logloss:0.02249\teval-logloss:0.09199\n",
      "[59]\ttrain-logloss:0.02185\teval-logloss:0.09195\n",
      "[60]\ttrain-logloss:0.02132\teval-logloss:0.09194\n",
      "[61]\ttrain-logloss:0.02079\teval-logloss:0.09146\n",
      "[62]\ttrain-logloss:0.02022\teval-logloss:0.09031\n",
      "[63]\ttrain-logloss:0.01970\teval-logloss:0.08941\n",
      "[64]\ttrain-logloss:0.01918\teval-logloss:0.08972\n",
      "[65]\ttrain-logloss:0.01872\teval-logloss:0.08974\n",
      "[66]\ttrain-logloss:0.01833\teval-logloss:0.08962\n",
      "[67]\ttrain-logloss:0.01787\teval-logloss:0.08873\n",
      "[68]\ttrain-logloss:0.01760\teval-logloss:0.08862\n",
      "[69]\ttrain-logloss:0.01724\teval-logloss:0.08974\n",
      "[70]\ttrain-logloss:0.01688\teval-logloss:0.08998\n",
      "[71]\ttrain-logloss:0.01664\teval-logloss:0.08978\n",
      "[72]\ttrain-logloss:0.01629\teval-logloss:0.08958\n",
      "[73]\ttrain-logloss:0.01598\teval-logloss:0.08953\n",
      "[74]\ttrain-logloss:0.01566\teval-logloss:0.08875\n",
      "[75]\ttrain-logloss:0.01539\teval-logloss:0.08860\n",
      "[76]\ttrain-logloss:0.01515\teval-logloss:0.08812\n",
      "[77]\ttrain-logloss:0.01488\teval-logloss:0.08840\n",
      "[78]\ttrain-logloss:0.01464\teval-logloss:0.08874\n",
      "[79]\ttrain-logloss:0.01449\teval-logloss:0.08815\n",
      "[80]\ttrain-logloss:0.01418\teval-logloss:0.08758\n",
      "[81]\ttrain-logloss:0.01400\teval-logloss:0.08741\n",
      "[82]\ttrain-logloss:0.01377\teval-logloss:0.08849\n",
      "[83]\ttrain-logloss:0.01357\teval-logloss:0.08857\n",
      "[84]\ttrain-logloss:0.01341\teval-logloss:0.08807\n",
      "[85]\ttrain-logloss:0.01325\teval-logloss:0.08764\n",
      "[86]\ttrain-logloss:0.01311\teval-logloss:0.08742\n",
      "[87]\ttrain-logloss:0.01293\teval-logloss:0.08761\n",
      "[88]\ttrain-logloss:0.01271\teval-logloss:0.08707\n",
      "[89]\ttrain-logloss:0.01254\teval-logloss:0.08727\n",
      "[90]\ttrain-logloss:0.01235\teval-logloss:0.08716\n",
      "[91]\ttrain-logloss:0.01223\teval-logloss:0.08696\n",
      "[92]\ttrain-logloss:0.01206\teval-logloss:0.08717\n",
      "[93]\ttrain-logloss:0.01193\teval-logloss:0.08707\n",
      "[94]\ttrain-logloss:0.01182\teval-logloss:0.08659\n",
      "[95]\ttrain-logloss:0.01165\teval-logloss:0.08612\n",
      "[96]\ttrain-logloss:0.01148\teval-logloss:0.08714\n",
      "[97]\ttrain-logloss:0.01136\teval-logloss:0.08677\n",
      "[98]\ttrain-logloss:0.01124\teval-logloss:0.08669\n",
      "[99]\ttrain-logloss:0.01113\teval-logloss:0.08655\n",
      "[100]\ttrain-logloss:0.01100\teval-logloss:0.08650\n",
      "[101]\ttrain-logloss:0.01085\teval-logloss:0.08641\n",
      "[102]\ttrain-logloss:0.01075\teval-logloss:0.08629\n",
      "[103]\ttrain-logloss:0.01064\teval-logloss:0.08626\n",
      "[104]\ttrain-logloss:0.01050\teval-logloss:0.08683\n",
      "[105]\ttrain-logloss:0.01040\teval-logloss:0.08677\n",
      "[106]\ttrain-logloss:0.01030\teval-logloss:0.08732\n",
      "[107]\ttrain-logloss:0.01020\teval-logloss:0.08730\n",
      "[108]\ttrain-logloss:0.01007\teval-logloss:0.08728\n",
      "[109]\ttrain-logloss:0.01000\teval-logloss:0.08730\n",
      "[110]\ttrain-logloss:0.00991\teval-logloss:0.08729\n",
      "[111]\ttrain-logloss:0.00980\teval-logloss:0.08800\n",
      "[112]\ttrain-logloss:0.00971\teval-logloss:0.08794\n",
      "[113]\ttrain-logloss:0.00963\teval-logloss:0.08784\n",
      "[114]\ttrain-logloss:0.00956\teval-logloss:0.08807\n",
      "[115]\ttrain-logloss:0.00948\teval-logloss:0.08765\n",
      "[116]\ttrain-logloss:0.00942\teval-logloss:0.08730\n",
      "[117]\ttrain-logloss:0.00931\teval-logloss:0.08780\n",
      "[118]\ttrain-logloss:0.00923\teval-logloss:0.08775\n",
      "[119]\ttrain-logloss:0.00915\teval-logloss:0.08768\n",
      "[120]\ttrain-logloss:0.00912\teval-logloss:0.08763\n",
      "[121]\ttrain-logloss:0.00902\teval-logloss:0.08757\n",
      "[122]\ttrain-logloss:0.00897\teval-logloss:0.08755\n",
      "[123]\ttrain-logloss:0.00890\teval-logloss:0.08716\n",
      "[124]\ttrain-logloss:0.00884\teval-logloss:0.08767\n",
      "[125]\ttrain-logloss:0.00880\teval-logloss:0.08774\n",
      "[126]\ttrain-logloss:0.00871\teval-logloss:0.08827\n",
      "[127]\ttrain-logloss:0.00865\teval-logloss:0.08831\n",
      "[128]\ttrain-logloss:0.00861\teval-logloss:0.08827\n",
      "[129]\ttrain-logloss:0.00856\teval-logloss:0.08789\n",
      "[130]\ttrain-logloss:0.00846\teval-logloss:0.08886\n",
      "[131]\ttrain-logloss:0.00842\teval-logloss:0.08868\n",
      "[132]\ttrain-logloss:0.00839\teval-logloss:0.08874\n",
      "[133]\ttrain-logloss:0.00830\teval-logloss:0.08922\n",
      "[134]\ttrain-logloss:0.00827\teval-logloss:0.08918\n",
      "[135]\ttrain-logloss:0.00822\teval-logloss:0.08882\n",
      "[136]\ttrain-logloss:0.00816\teval-logloss:0.08851\n",
      "[137]\ttrain-logloss:0.00808\teval-logloss:0.08848\n",
      "[138]\ttrain-logloss:0.00805\teval-logloss:0.08839\n",
      "[139]\ttrain-logloss:0.00797\teval-logloss:0.08915\n",
      "[140]\ttrain-logloss:0.00795\teval-logloss:0.08911\n",
      "[141]\ttrain-logloss:0.00790\teval-logloss:0.08876\n",
      "[142]\ttrain-logloss:0.00787\teval-logloss:0.08868\n",
      "[143]\ttrain-logloss:0.00785\teval-logloss:0.08839\n",
      "[144]\ttrain-logloss:0.00778\teval-logloss:0.08927\n",
      "[145]\ttrain-logloss:0.00775\teval-logloss:0.08924\n",
      "[146]\ttrain-logloss:0.00773\teval-logloss:0.08914\n",
      "[147]\ttrain-logloss:0.00769\teval-logloss:0.08891\n",
      "[148]\ttrain-logloss:0.00762\teval-logloss:0.08942\n",
      "[149]\ttrain-logloss:0.00760\teval-logloss:0.08939\n",
      "[150]\ttrain-logloss:0.00757\teval-logloss:0.08911\n",
      "[151]\ttrain-logloss:0.00752\teval-logloss:0.08873\n",
      "[152]\ttrain-logloss:0.00750\teval-logloss:0.08872\n",
      "[153]\ttrain-logloss:0.00746\teval-logloss:0.08848\n",
      "[154]\ttrain-logloss:0.00741\teval-logloss:0.08847\n",
      "[155]\ttrain-logloss:0.00739\teval-logloss:0.08855\n",
      "[156]\ttrain-logloss:0.00737\teval-logloss:0.08852\n",
      "[157]\ttrain-logloss:0.00735\teval-logloss:0.08855\n",
      "[158]\ttrain-logloss:0.00732\teval-logloss:0.08827\n",
      "[159]\ttrain-logloss:0.00730\teval-logloss:0.08830\n",
      "[160]\ttrain-logloss:0.00728\teval-logloss:0.08828\n",
      "[161]\ttrain-logloss:0.00726\teval-logloss:0.08801\n",
      "[162]\ttrain-logloss:0.00724\teval-logloss:0.08776\n",
      "[163]\ttrain-logloss:0.00722\teval-logloss:0.08778\n",
      "[164]\ttrain-logloss:0.00720\teval-logloss:0.08778\n",
      "[165]\ttrain-logloss:0.00718\teval-logloss:0.08752\n",
      "[166]\ttrain-logloss:0.00716\teval-logloss:0.08754\n",
      "[167]\ttrain-logloss:0.00714\teval-logloss:0.08764\n",
      "[168]\ttrain-logloss:0.00712\teval-logloss:0.08739\n",
      "[169]\ttrain-logloss:0.00710\teval-logloss:0.08738\n",
      "[170]\ttrain-logloss:0.00708\teval-logloss:0.08730\n",
      "[171]\ttrain-logloss:0.00707\teval-logloss:0.08737\n",
      "[172]\ttrain-logloss:0.00705\teval-logloss:0.08740\n",
      "[173]\ttrain-logloss:0.00703\teval-logloss:0.08739\n",
      "[174]\ttrain-logloss:0.00701\teval-logloss:0.08713\n",
      "[175]\ttrain-logloss:0.00699\teval-logloss:0.08716\n",
      "[176]\ttrain-logloss:0.00697\teval-logloss:0.08695\n",
      "[177]\ttrain-logloss:0.00695\teval-logloss:0.08705\n",
      "[178]\ttrain-logloss:0.00694\teval-logloss:0.08697\n",
      "[179]\ttrain-logloss:0.00692\teval-logloss:0.08697\n",
      "[180]\ttrain-logloss:0.00690\teval-logloss:0.08704\n",
      "[181]\ttrain-logloss:0.00688\teval-logloss:0.08680\n",
      "[182]\ttrain-logloss:0.00687\teval-logloss:0.08683\n",
      "[183]\ttrain-logloss:0.00685\teval-logloss:0.08658\n",
      "[184]\ttrain-logloss:0.00683\teval-logloss:0.08659\n",
      "[185]\ttrain-logloss:0.00681\teval-logloss:0.08661\n",
      "[186]\ttrain-logloss:0.00680\teval-logloss:0.08637\n",
      "[187]\ttrain-logloss:0.00678\teval-logloss:0.08637\n",
      "[188]\ttrain-logloss:0.00676\teval-logloss:0.08630\n",
      "[189]\ttrain-logloss:0.00675\teval-logloss:0.08610\n",
      "[190]\ttrain-logloss:0.00673\teval-logloss:0.08602\n",
      "[191]\ttrain-logloss:0.00671\teval-logloss:0.08605\n",
      "[192]\ttrain-logloss:0.00670\teval-logloss:0.08615\n",
      "[193]\ttrain-logloss:0.00668\teval-logloss:0.08592\n",
      "[194]\ttrain-logloss:0.00667\teval-logloss:0.08591\n",
      "[195]\ttrain-logloss:0.00665\teval-logloss:0.08598\n",
      "[196]\ttrain-logloss:0.00663\teval-logloss:0.08601\n",
      "[197]\ttrain-logloss:0.00662\teval-logloss:0.08592\n",
      "[198]\ttrain-logloss:0.00660\teval-logloss:0.08585\n",
      "[199]\ttrain-logloss:0.00659\teval-logloss:0.08587\n",
      "[200]\ttrain-logloss:0.00657\teval-logloss:0.08589\n",
      "[201]\ttrain-logloss:0.00656\teval-logloss:0.08595\n",
      "[202]\ttrain-logloss:0.00654\teval-logloss:0.08573\n",
      "[203]\ttrain-logloss:0.00653\teval-logloss:0.08573\n",
      "[204]\ttrain-logloss:0.00651\teval-logloss:0.08575\n",
      "[205]\ttrain-logloss:0.00650\teval-logloss:0.08582\n",
      "[206]\ttrain-logloss:0.00648\teval-logloss:0.08584\n",
      "[207]\ttrain-logloss:0.00647\teval-logloss:0.08578\n",
      "[208]\ttrain-logloss:0.00645\teval-logloss:0.08569\n",
      "[209]\ttrain-logloss:0.00644\teval-logloss:0.08571\n",
      "[210]\ttrain-logloss:0.00643\teval-logloss:0.08581\n",
      "[211]\ttrain-logloss:0.00641\teval-logloss:0.08559\n",
      "[212]\ttrain-logloss:0.00640\teval-logloss:0.08580\n",
      "[213]\ttrain-logloss:0.00639\teval-logloss:0.08581\n",
      "[214]\ttrain-logloss:0.00637\teval-logloss:0.08574\n",
      "[215]\ttrain-logloss:0.00636\teval-logloss:0.08566\n",
      "[216]\ttrain-logloss:0.00635\teval-logloss:0.08584\n",
      "[217]\ttrain-logloss:0.00633\teval-logloss:0.08563\n",
      "[218]\ttrain-logloss:0.00632\teval-logloss:0.08573\n",
      "[219]\ttrain-logloss:0.00631\teval-logloss:0.08578\n",
      "[220]\ttrain-logloss:0.00629\teval-logloss:0.08579\n",
      "[221]\ttrain-logloss:0.00628\teval-logloss:0.08582\n",
      "[222]\ttrain-logloss:0.00627\teval-logloss:0.08576\n",
      "[223]\ttrain-logloss:0.00626\teval-logloss:0.08567\n",
      "[224]\ttrain-logloss:0.00624\teval-logloss:0.08586\n",
      "[225]\ttrain-logloss:0.00623\teval-logloss:0.08587\n",
      "[226]\ttrain-logloss:0.00622\teval-logloss:0.08593\n",
      "[227]\ttrain-logloss:0.00621\teval-logloss:0.08595\n",
      "[228]\ttrain-logloss:0.00619\teval-logloss:0.08587\n",
      "[229]\ttrain-logloss:0.00618\teval-logloss:0.08606\n",
      "[230]\ttrain-logloss:0.00617\teval-logloss:0.08600\n",
      "[231]\ttrain-logloss:0.00616\teval-logloss:0.08592\n",
      "[232]\ttrain-logloss:0.00615\teval-logloss:0.08610\n",
      "[233]\ttrain-logloss:0.00614\teval-logloss:0.08611\n",
      "[234]\ttrain-logloss:0.00612\teval-logloss:0.08617\n",
      "[235]\ttrain-logloss:0.00611\teval-logloss:0.08626\n",
      "[236]\ttrain-logloss:0.00610\teval-logloss:0.08629\n",
      "[237]\ttrain-logloss:0.00609\teval-logloss:0.08622\n",
      "[238]\ttrain-logloss:0.00608\teval-logloss:0.08639\n",
      "[239]\ttrain-logloss:0.00607\teval-logloss:0.08634\n",
      "[240]\ttrain-logloss:0.00606\teval-logloss:0.08618\n",
      "[241]\ttrain-logloss:0.00605\teval-logloss:0.08620\n",
      "[242]\ttrain-logloss:0.00604\teval-logloss:0.08625\n",
      "[243]\ttrain-logloss:0.00602\teval-logloss:0.08626\n",
      "[244]\ttrain-logloss:0.00601\teval-logloss:0.08629\n",
      "[245]\ttrain-logloss:0.00600\teval-logloss:0.08622\n",
      "[246]\ttrain-logloss:0.00599\teval-logloss:0.08640\n",
      "[247]\ttrain-logloss:0.00598\teval-logloss:0.08635\n",
      "[248]\ttrain-logloss:0.00597\teval-logloss:0.08628\n",
      "[249]\ttrain-logloss:0.00596\teval-logloss:0.08645\n",
      "[250]\ttrain-logloss:0.00595\teval-logloss:0.08629\n",
      "[251]\ttrain-logloss:0.00594\teval-logloss:0.08631\n",
      "[252]\ttrain-logloss:0.00593\teval-logloss:0.08636\n",
      "[253]\ttrain-logloss:0.00592\teval-logloss:0.08639\n",
      "[254]\ttrain-logloss:0.00591\teval-logloss:0.08649\n",
      "[255]\ttrain-logloss:0.00590\teval-logloss:0.08644\n",
      "[256]\ttrain-logloss:0.00589\teval-logloss:0.08629\n",
      "[257]\ttrain-logloss:0.00588\teval-logloss:0.08646\n",
      "[258]\ttrain-logloss:0.00587\teval-logloss:0.08639\n",
      "[259]\ttrain-logloss:0.00586\teval-logloss:0.08644\n",
      "[260]\ttrain-logloss:0.00585\teval-logloss:0.08646\n",
      "[261]\ttrain-logloss:0.00585\teval-logloss:0.08649\n",
      "[262]\ttrain-logloss:0.00584\teval-logloss:0.08645\n",
      "[263]\ttrain-logloss:0.00583\teval-logloss:0.08647\n",
      "[264]\ttrain-logloss:0.00582\teval-logloss:0.08632\n",
      "[265]\ttrain-logloss:0.00581\teval-logloss:0.08649\n",
      "[266]\ttrain-logloss:0.00580\teval-logloss:0.08654\n",
      "[267]\ttrain-logloss:0.00579\teval-logloss:0.08647\n",
      "[268]\ttrain-logloss:0.00578\teval-logloss:0.08650\n",
      "[269]\ttrain-logloss:0.00577\teval-logloss:0.08652\n",
      "[270]\ttrain-logloss:0.00576\teval-logloss:0.08669\n",
      "[271]\ttrain-logloss:0.00576\teval-logloss:0.08674\n",
      "[272]\ttrain-logloss:0.00575\teval-logloss:0.08683\n",
      "[273]\ttrain-logloss:0.00574\teval-logloss:0.08668\n",
      "[274]\ttrain-logloss:0.00573\teval-logloss:0.08664\n",
      "[275]\ttrain-logloss:0.00572\teval-logloss:0.08650\n",
      "[276]\ttrain-logloss:0.00571\teval-logloss:0.08635\n",
      "[277]\ttrain-logloss:0.00570\teval-logloss:0.08652\n",
      "[278]\ttrain-logloss:0.00570\teval-logloss:0.08657\n",
      "[279]\ttrain-logloss:0.00569\teval-logloss:0.08659\n",
      "[280]\ttrain-logloss:0.00568\teval-logloss:0.08668\n",
      "[281]\ttrain-logloss:0.00567\teval-logloss:0.08664\n",
      "[282]\ttrain-logloss:0.00566\teval-logloss:0.08650\n",
      "[283]\ttrain-logloss:0.00565\teval-logloss:0.08636\n",
      "[284]\ttrain-logloss:0.00565\teval-logloss:0.08640\n",
      "[285]\ttrain-logloss:0.00564\teval-logloss:0.08643\n",
      "[286]\ttrain-logloss:0.00563\teval-logloss:0.08646\n",
      "[287]\ttrain-logloss:0.00562\teval-logloss:0.08650\n",
      "[288]\ttrain-logloss:0.00562\teval-logloss:0.08637\n",
      "[289]\ttrain-logloss:0.00561\teval-logloss:0.08646\n",
      "[290]\ttrain-logloss:0.00560\teval-logloss:0.08645\n",
      "[291]\ttrain-logloss:0.00559\teval-logloss:0.08632\n",
      "[292]\ttrain-logloss:0.00558\teval-logloss:0.08628\n",
      "[293]\ttrain-logloss:0.00558\teval-logloss:0.08615\n",
      "[294]\ttrain-logloss:0.00557\teval-logloss:0.08620\n",
      "[295]\ttrain-logloss:0.00556\teval-logloss:0.08622\n",
      "[296]\ttrain-logloss:0.00556\teval-logloss:0.08631\n",
      "[297]\ttrain-logloss:0.00555\teval-logloss:0.08618\n",
      "[298]\ttrain-logloss:0.00554\teval-logloss:0.08626\n",
      "[299]\ttrain-logloss:0.00553\teval-logloss:0.08613\n",
      "[300]\ttrain-logloss:0.00553\teval-logloss:0.08618\n",
      "[301]\ttrain-logloss:0.00552\teval-logloss:0.08605\n",
      "[302]\ttrain-logloss:0.00551\teval-logloss:0.08602\n",
      "[303]\ttrain-logloss:0.00551\teval-logloss:0.08610\n",
      "[304]\ttrain-logloss:0.00550\teval-logloss:0.08598\n",
      "[305]\ttrain-logloss:0.00549\teval-logloss:0.08606\n",
      "[306]\ttrain-logloss:0.00548\teval-logloss:0.08597\n",
      "[307]\ttrain-logloss:0.00548\teval-logloss:0.08600\n",
      "[308]\ttrain-logloss:0.00547\teval-logloss:0.08600\n",
      "[309]\ttrain-logloss:0.00546\teval-logloss:0.08588\n",
      "[310]\ttrain-logloss:0.00546\teval-logloss:0.08592\n",
      "[311]\ttrain-logloss:0.00545\teval-logloss:0.08595\n"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.train(params = params, dtrain = dtrain, num_boost_round = num_rounds, \n",
    "                      early_stopping_rounds = 100, evals= eval_list)\n",
    "\n",
    "#311번 만에 조기종료"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "5UFWSwQp8yA8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict( ) 수행 결과값을 10개만 표시, 예측 확률 값으로 표시됨\n",
      "[0.934 0.003 0.91  0.094 0.993 1.    1.    0.999 0.997 0.   ]\n",
      "예측값 10개만 표시: [1, 0, 1, 0, 1, 1, 1, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "pred_probs = xgb_model.predict(dtest)\n",
    "print('predict( ) 수행 결과값을 10개만 표시, 예측 확률 값으로 표시됨')\n",
    "print(np.round(pred_probs[:10],3))\n",
    "\n",
    "# 예측 확률이 0.5 보다 크면 1 , 그렇지 않으면 0 으로 예측값 결정하여 List 객체인 preds에 저장\n",
    "preds = [ 1 if x > 0.5 else 0 for x in pred_probs ]\n",
    "print('예측값 10개만 표시:',preds[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mxk9DN5383sp"
   },
   "source": [
    "##**2-e. `get_eval_clf()` 을 통해 예측 평가를 진행해주세요**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "xS27kc1780cD"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "def get_clf_eval(y_test, pred=None, pred_proba=None):\n",
    "    confusion = confusion_matrix( y_test, pred)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    precision = precision_score(y_test , pred)\n",
    "    recall = recall_score(y_test , pred)\n",
    "    f1 = f1_score(y_test,pred)\n",
    "    # ROC-AUC 추가\n",
    "    roc_auc = roc_auc_score(y_test, pred_proba)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    # ROC-AUC print 추가\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\\\n",
    "    F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "v-foPK_M82hT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[35  2]\n",
      " [ 1 76]]\n",
      "정확도: 0.9737, 정밀도: 0.9744, 재현율: 0.9870,    F1: 0.9806, AUC:0.9951\n"
     ]
    }
   ],
   "source": [
    "get_clf_eval(y_test, preds, pred_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uvg4b6ap9lXg"
   },
   "source": [
    "# **3. LightGBM, HyperOpt**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f8SBYxBJ-vhb"
   },
   "source": [
    "## **3-1. LightGBM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SnRlTMVaIdU6"
   },
   "source": [
    "### **3-1-a. ```water_potability.csv```를 불러와 df에 저장해 주세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "3cg-dfFE-nOx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm==3.3.2 in c:\\users\\flex\\anaconda3\\lib\\site-packages (3.3.2)\n",
      "Requirement already satisfied: wheel in c:\\users\\flex\\anaconda3\\lib\\site-packages (from lightgbm==3.3.2) (0.37.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\flex\\anaconda3\\lib\\site-packages (from lightgbm==3.3.2) (1.21.5)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in c:\\users\\flex\\anaconda3\\lib\\site-packages (from lightgbm==3.3.2) (1.0.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\flex\\anaconda3\\lib\\site-packages (from lightgbm==3.3.2) (1.7.3)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\flex\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm==3.3.2) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\flex\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm==3.3.2) (2.2.0)\n",
      "3.3.2\n"
     ]
    }
   ],
   "source": [
    "# 3.3.2 버전으로 LightGBM을 설치합니다(일부 파라미터가 4.0.0에선 작동하지 않아서 넣었습니다.)\n",
    "\n",
    "!pip install lightgbm==3.3.2\n",
    "print(lightgbm.__version__) # 버전 확인용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ZcpuDJ8GIoBD"
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "z3XVGeXr-_kt"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ph</th>\n",
       "      <th>Hardness</th>\n",
       "      <th>Solids</th>\n",
       "      <th>Chloramines</th>\n",
       "      <th>Sulfate</th>\n",
       "      <th>Conductivity</th>\n",
       "      <th>Organic_carbon</th>\n",
       "      <th>Trihalomethanes</th>\n",
       "      <th>Turbidity</th>\n",
       "      <th>Potability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>204.890455</td>\n",
       "      <td>20791.318981</td>\n",
       "      <td>7.300212</td>\n",
       "      <td>368.516441</td>\n",
       "      <td>564.308654</td>\n",
       "      <td>10.379783</td>\n",
       "      <td>86.990970</td>\n",
       "      <td>2.963135</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.716080</td>\n",
       "      <td>129.422921</td>\n",
       "      <td>18630.057858</td>\n",
       "      <td>6.635246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>592.885359</td>\n",
       "      <td>15.180013</td>\n",
       "      <td>56.329076</td>\n",
       "      <td>4.500656</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.099124</td>\n",
       "      <td>224.236259</td>\n",
       "      <td>19909.541732</td>\n",
       "      <td>9.275884</td>\n",
       "      <td>NaN</td>\n",
       "      <td>418.606213</td>\n",
       "      <td>16.868637</td>\n",
       "      <td>66.420093</td>\n",
       "      <td>3.055934</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.316766</td>\n",
       "      <td>214.373394</td>\n",
       "      <td>22018.417441</td>\n",
       "      <td>8.059332</td>\n",
       "      <td>356.886136</td>\n",
       "      <td>363.266516</td>\n",
       "      <td>18.436524</td>\n",
       "      <td>100.341674</td>\n",
       "      <td>4.628771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.092223</td>\n",
       "      <td>181.101509</td>\n",
       "      <td>17978.986339</td>\n",
       "      <td>6.546600</td>\n",
       "      <td>310.135738</td>\n",
       "      <td>398.410813</td>\n",
       "      <td>11.558279</td>\n",
       "      <td>31.997993</td>\n",
       "      <td>4.075075</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ph    Hardness        Solids  Chloramines     Sulfate  Conductivity  \\\n",
       "0       NaN  204.890455  20791.318981     7.300212  368.516441    564.308654   \n",
       "1  3.716080  129.422921  18630.057858     6.635246         NaN    592.885359   \n",
       "2  8.099124  224.236259  19909.541732     9.275884         NaN    418.606213   \n",
       "3  8.316766  214.373394  22018.417441     8.059332  356.886136    363.266516   \n",
       "4  9.092223  181.101509  17978.986339     6.546600  310.135738    398.410813   \n",
       "\n",
       "   Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
       "0       10.379783        86.990970   2.963135           0  \n",
       "1       15.180013        56.329076   4.500656           0  \n",
       "2       16.868637        66.420093   3.055934           0  \n",
       "3       18.436524       100.341674   4.628771           0  \n",
       "4       11.558279        31.997993   4.075075           0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:/Users/Flex/Documents/Euron/water_potability.csv\")\n",
    "\n",
    "# 데이터 확인\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cXSVbYeI_DGz"
   },
   "source": [
    "### **3-1-b. 이럴수가! 결측값이 있는 것 같네요! 아래의 코드를 실행시켜 어느 변수에 결측값이 있는지 확인하고, 결측값들은 모두 해당하는 변수의 평균으로 바꿔주세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "r4nKg2mF_FHE"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ph                 491\n",
       "Hardness             0\n",
       "Solids               0\n",
       "Chloramines          0\n",
       "Sulfate            781\n",
       "Conductivity         0\n",
       "Organic_carbon       0\n",
       "Trihalomethanes    162\n",
       "Turbidity            0\n",
       "Potability           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "I3Iq_aHA_XUi"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ph</th>\n",
       "      <th>Hardness</th>\n",
       "      <th>Solids</th>\n",
       "      <th>Chloramines</th>\n",
       "      <th>Sulfate</th>\n",
       "      <th>Conductivity</th>\n",
       "      <th>Organic_carbon</th>\n",
       "      <th>Trihalomethanes</th>\n",
       "      <th>Turbidity</th>\n",
       "      <th>Potability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.080795</td>\n",
       "      <td>204.890455</td>\n",
       "      <td>20791.318981</td>\n",
       "      <td>7.300212</td>\n",
       "      <td>368.516441</td>\n",
       "      <td>564.308654</td>\n",
       "      <td>10.379783</td>\n",
       "      <td>86.990970</td>\n",
       "      <td>2.963135</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.716080</td>\n",
       "      <td>129.422921</td>\n",
       "      <td>18630.057858</td>\n",
       "      <td>6.635246</td>\n",
       "      <td>333.775777</td>\n",
       "      <td>592.885359</td>\n",
       "      <td>15.180013</td>\n",
       "      <td>56.329076</td>\n",
       "      <td>4.500656</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.099124</td>\n",
       "      <td>224.236259</td>\n",
       "      <td>19909.541732</td>\n",
       "      <td>9.275884</td>\n",
       "      <td>333.775777</td>\n",
       "      <td>418.606213</td>\n",
       "      <td>16.868637</td>\n",
       "      <td>66.420093</td>\n",
       "      <td>3.055934</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.316766</td>\n",
       "      <td>214.373394</td>\n",
       "      <td>22018.417441</td>\n",
       "      <td>8.059332</td>\n",
       "      <td>356.886136</td>\n",
       "      <td>363.266516</td>\n",
       "      <td>18.436524</td>\n",
       "      <td>100.341674</td>\n",
       "      <td>4.628771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.092223</td>\n",
       "      <td>181.101509</td>\n",
       "      <td>17978.986339</td>\n",
       "      <td>6.546600</td>\n",
       "      <td>310.135738</td>\n",
       "      <td>398.410813</td>\n",
       "      <td>11.558279</td>\n",
       "      <td>31.997993</td>\n",
       "      <td>4.075075</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ph    Hardness        Solids  Chloramines     Sulfate  Conductivity  \\\n",
       "0  7.080795  204.890455  20791.318981     7.300212  368.516441    564.308654   \n",
       "1  3.716080  129.422921  18630.057858     6.635246  333.775777    592.885359   \n",
       "2  8.099124  224.236259  19909.541732     9.275884  333.775777    418.606213   \n",
       "3  8.316766  214.373394  22018.417441     8.059332  356.886136    363.266516   \n",
       "4  9.092223  181.101509  17978.986339     6.546600  310.135738    398.410813   \n",
       "\n",
       "   Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
       "0       10.379783        86.990970   2.963135           0  \n",
       "1       15.180013        56.329076   4.500656           0  \n",
       "2       16.868637        66.420093   3.055934           0  \n",
       "3       18.436524       100.341674   4.628771           0  \n",
       "4       11.558279        31.997993   4.075075           0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 결측값을 해당 칼럼의 평균값으로 대체해 주세요.\n",
    "# 힌트: 파머완 138페이지\n",
    "\n",
    "df['ph'].fillna(df['ph'].mean(), inplace=True)\n",
    "df['Sulfate'].fillna(df['Sulfate'].mean(), inplace=True)\n",
    "df['Trihalomethanes'].fillna(df['Trihalomethanes'].mean(), inplace=True)\n",
    "\n",
    "\n",
    "# 데이터 확인\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OyXaOw0X_aXZ"
   },
   "source": [
    "### **3-1-c. df를 학습용 데이터와 테스트용 데이터로 분리해 주세요.**  \n",
    "(random_state = 42, 학습용 데이터가 전체의 **80%**를 차지하도록 설정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "oWbfGB4c_Znx"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hW1x8hQI_krM"
   },
   "source": [
    "### **3-1-d. 위에서 만든 X_train, y_train을 다시 나누어 90%는 학습용으로, 10%는 검증용 데이터로 분리해 주세요.**  \n",
    "(random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "QPuPw7bb_qF8"
   },
   "outputs": [],
   "source": [
    "X_tr, X_val, y_tr, y_val = train_test_split(X, y, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hEyCPkHZ_tYC"
   },
   "source": [
    "### **3-1-e. 다음 조건에 따라 LGBMClassifier을 생성한 후 ```lgbm_wrapper```에 저장해 주세요.**\n",
    "- 반복 수행할 트리 개수: 800개\n",
    "- 학습률: 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "4gPkmQo3_zlS"
   },
   "outputs": [],
   "source": [
    "lgbm_wrapper = LGBMClassifier(n_estimators = 800, learning_rate = 0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "unGn5aOi_2LG"
   },
   "source": [
    "### **3-1-f. `lgbm_wrapper`가 100번 학습을 반복해도 성능이 향상되지 않으면 수행을 멈추도록 설정해서 학습시키세요.**\n",
    "- 평가 지표: logloss  \n",
    "\n",
    "(❓❓❓❓❓로 표시된 빈칸을 채워주세요!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "89l5qcaB_6QV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[336]\ttraining's binary_logloss: 0.36864\tvalid_1's binary_logloss: 0.583198\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(learning_rate=0.02, n_estimators=800)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#위의 코드를 실행시켰으나 LGBM 3.3.2 가 실행되지 않는 관계로 callbacks 사용\n",
    "\n",
    "evals = [(X_tr, y_tr) , (X_val, y_val)]\n",
    "\n",
    "callbacks = [\n",
    "    lgb.early_stopping(100, verbose=True),  \n",
    "]\n",
    "\n",
    "lgbm_wrapper.fit(X_tr, y_tr, eval_metric='logloss', eval_set=evals, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z3YiAxdOAhqh"
   },
   "source": [
    "### **3-1-g. 위에서 학습시킨 `lgbm_wrapper`의 정확도를 출력하세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "yrG3MF-JAom3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgbm_wrapper 정확도:0.6829\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "preds= lgbm_wrapper.predict(X_val)\n",
    "lgbm_accuracy = accuracy_score(y_val, preds)\n",
    "\n",
    "print('lgbm_wrapper 정확도:{0:.4f}'.format(lgbm_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s5_joSurAjHs"
   },
   "source": [
    "### **3-1-i. 피처 중요도를 중요한 순서대로 시각화 해주세요.**\n",
    "(힌트: 파머완 252 페이지)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "5PG_98tJBfB9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Feature importance'}, xlabel='Feature importance', ylabel='Features'>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from lightgbm import plot_importance\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10,12))\n",
    "plot_importance(lgbm_wrapper, ax)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "egUn68R9AjSZ"
   },
   "source": [
    "## **3-2. HyperOpt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "YQfqj1GmGiYa"
   },
   "outputs": [],
   "source": [
    "from hyperopt import hp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dt90nZGGAjaO"
   },
   "source": [
    "### **3-2-a. 주어진 정보를 바탕으로 검색 공간을 설정해 주세요.**\n",
    "(힌트: `hp.uniform`)\n",
    "\n",
    "- max_depth: 5에서 20까지, 간격 = 1\n",
    "- min_child_weight: 1에서 2까지, 간격 = 1\n",
    "- colsample_bytree: 0.5, 1\n",
    "- learning_rate: 0.01에서 0.2 사이, 정규 분포된 값으로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "j9hI35hEBenL"
   },
   "outputs": [],
   "source": [
    "search_space = {'max_depth': hp.quniform('max_depth', 5, 20, 1), \n",
    "                'min_child_weight': hp.quniform('min_child_weight', 1,2,1),\n",
    "                'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1),\n",
    "                'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n",
    "               }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3cSRp1UDAji8"
   },
   "source": [
    "### **3-2-b. 검색 공간을 인자로 받아 목적함수를 완성해 주세요.**\n",
    "(n_estimators = 800)  \n",
    "(❓❓❓❓❓로 표시된 빈칸을 채워주세요!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "VIi05vIgHFKQ"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "from hyperopt import STATUS_OK\n",
    "\n",
    "\n",
    "def objective_func(search_space):\n",
    "    xgb_clf = XGBClassifier(n_estimators = 800,\n",
    "                            max_depth = int(search_space['max_depth']),    \n",
    "                            min_child_weight = int(search_space['min_child_weight']),\n",
    "                            learning_rate = search_space['learning_rate'],\n",
    "                            colsample_bytree = search_space['colsample_bytree'],\n",
    "                            eval_metric = 'logloss')\n",
    "    accuracy = cross_val_score(xgb_clf, X_train, y_train, scoring = 'accuracy', cv = 3)\n",
    "\n",
    "    return {'loss':-1 * np.mean(accuracy), 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dpFPo2bIBKYA"
   },
   "source": [
    "### **3-2-c. best에 `fmin()` 함수를 이용하여 최적 파라미터 값들을 저장해 주세요.**\n",
    "- fn, 검색공간: 위에서 구한 값\n",
    "- 최대 반복 횟수: 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "oagDclMCKKmS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 50/50 [08:27<00:00, 10.14s/trial, best loss: -0.6625980884279028]\n",
      "best: {'colsample_bytree': 0.7885873905384678, 'learning_rate': 0.011604457950492832, 'max_depth': 12.0, 'min_child_weight': 1.0}\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, Trials\n",
    "\n",
    "trial_val = Trials()\n",
    "best = fmin(fn = objective_func,\n",
    "            space = search_space,\n",
    "            algo = tpe.suggest,\n",
    "            max_evals = 50,\n",
    "            trials = trial_val,\n",
    "            rstate = np.random.default_rng(seed = 9))\n",
    "print('best:', best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X00SYdMqBKf-"
   },
   "source": [
    "### **3-2-d. 아래는 best에 포함된 최적 파라미터들을 할당한 분류기입니다. 해당 분류기의 정확도를 출력해 주세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "YWG7Vx8qLskd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Flex\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Flex\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb_wrapper 정확도:0.6860\n"
     ]
    }
   ],
   "source": [
    "xgb_wrapper = XGBClassifier(n_estimators = 400,\n",
    "                            learning_rate = round(best['learning_rate'], 5),\n",
    "                            max_depth = int(best['max_depth']),\n",
    "                            min_child_weight = int(best['min_child_weight']),\n",
    "                            colsample_bytree = round(best['colsample_bytree'], 5)\n",
    "                           )\n",
    "\n",
    "evals = [(X_tr, y_tr), (X_val, y_val)]\n",
    "xgb_wrapper.fit(X_tr, y_tr, early_stopping_rounds = 50, eval_metric = 'logloss',\n",
    "                eval_set = evals, verbose = 0)\n",
    "\n",
    "preds = xgb_wrapper.predict(X_val)\n",
    "xgb_accuracy = accuracy_score(y_val, preds)\n",
    "\n",
    "print('xgb_wrapper 정확도:{0:.4f}'.format(xgb_accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zi7nlAXnaIvx"
   },
   "source": [
    "# **4. 스태킹**\n",
    "- 4번 문제는 3번 문제에서 전처리 된 `water_potability.csv` 데이터를 계속 활용하시면 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zo-EqV9IaOHE"
   },
   "source": [
    "## **4-a. 기본 스태킹 기법을 적용해 봅시다.**\n",
    "- `SVM`, `KNN`, `로지스틱 회귀`, `결정 트리` 모델 객체를 생성해 주세요.\n",
    "- 최종 메타 모델은 `랜덤 포레스트`를 활용해주세요.\n",
    "- 파라미터 설정\n",
    "  - SVM: random_state = 0\n",
    "  - KNN: n_neighbors = 8\n",
    "  - RandomForest: n_estimators = 100, random_state = 0\n",
    "  - 나머지: 기본 파라미터(base model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "A8oVE61iW2rE"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "-g8nzDlXW_hD"
   },
   "outputs": [],
   "source": [
    "# SVM, KNN, 로지스틱 회귀, 결정 트리 개별 모델들을 생성해 주세요.\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "svm_clf = SVC(random_state = 0)\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=8)\n",
    "lr_clf = LogisticRegression()\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "\n",
    "# 최종 메타 모델로 랜덤 포레스트를 생성해 주세요.\n",
    "rf_final = RandomForestClassifier(n_estimators = 100, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_kiFDVuDZ92_"
   },
   "source": [
    "## **4-b. 개별 모델들을 학습시키고 예측을 수행합니다.**\n",
    "- 아래 코드를 완성시켜 봅시다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Vda9AE6ga1ne"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf.fit(X_tr, y_tr)\n",
    "knn_clf.fit(X_tr, y_tr)\n",
    "lr_clf.fit(X_tr, y_tr)\n",
    "dt_clf.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "bqQEJMSwbXfz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM 정확도: 0.6220\n",
      "KNN 정확도: 0.5793\n",
      "로지스틱 회귀 정확도: 0.6220\n",
      "결정 트리 정확도: 0.5701\n"
     ]
    }
   ],
   "source": [
    "## 학습된 개별 모델들이 반환하는 예측 데이터셋을 생성하세요.\n",
    "# 예측 시 들어가는 테스트 데이터셋 이름은 X_val 입니다.\n",
    "svm_pred = svm_clf.predict(X_val)\n",
    "knn_pred = knn_clf.predict(X_val)\n",
    "lr_pred = lr_clf.predict(X_val)\n",
    "dt_pred = dt_clf.predict(X_val)\n",
    "\n",
    "## 예측 정확도를 반환하세요. 테스트 레이블 데이터셋 이름은 y_val 입니다.\n",
    "# hint : accuracy_score()\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "svm_accuracy = accuracy_score(y_val, svm_pred)\n",
    "knn_accuracy = accuracy_score(y_val, knn_pred)\n",
    "lr_accuracy = accuracy_score(y_val,lr_pred)\n",
    "dt_accuracy = accuracy_score(y_val,dt_pred)\n",
    "\n",
    "print('SVM 정확도: {0:.4f}'.format(svm_accuracy))\n",
    "print('KNN 정확도: {0:.4f}'.format(knn_accuracy))\n",
    "print('로지스틱 회귀 정확도: {0:.4f}'.format(lr_accuracy))\n",
    "print('결정 트리 정확도: {0:.4f}'.format(dt_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AmQiW4i4c_9B"
   },
   "source": [
    "## **4-c. 반환된 예측 데이터셋을 행 형태로 묶어 pred 데이터셋에 저장합니다**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Od3yHZ3fc8Uf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 328)\n",
      "(328, 4)\n"
     ]
    }
   ],
   "source": [
    "pred = np.array([svm_pred, knn_pred, lr_pred, dt_pred])\n",
    "print(pred.shape)\n",
    "\n",
    "# 행과 열의 위치를 교환해 원본 데이터 값 하나 당 예측 데이터셋의 값이 1대1 매칭이 되도록 하세요.\n",
    "pred = np.transpose(pred)\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h8rhG78DdzpT"
   },
   "source": [
    "## **4-d. 완성된 최종 데이터셋을 최종 메타 모델에 학습시키고 예측시킵니다.**\n",
    "- 기본 스태킹 모델이므로 학습과 예측 모두 **동일한** 데이터셋을 사용합니다.\n",
    "- **정확도**도 함께 출력해 주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "eDf69kCPebqf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 메타 모델의 예측 정확도: 0.6220\n"
     ]
    }
   ],
   "source": [
    "rf_final.fit(pred, y_val)\n",
    "final = rf_final.predict(pred)\n",
    "\n",
    "print('최종 메타 모델의 예측 정확도: {0:.4f}'.format(accuracy_score(y_val , final)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bt9i77_NqqJp"
   },
   "source": [
    "# **5. CatBoost**\n",
    "- 책에서 다루지 않는 부분이기 때문에 간단한 실습만 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "bUp-KlCjr7nt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-3.3.0-py3-none-any.whl (404 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\flex\\anaconda3\\lib\\site-packages (from optuna) (21.3)\n",
      "Collecting colorlog\n",
      "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in c:\\users\\flex\\anaconda3\\lib\\site-packages (from optuna) (1.4.32)\n",
      "Requirement already satisfied: numpy in c:\\users\\flex\\anaconda3\\lib\\site-packages (from optuna) (1.21.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\flex\\anaconda3\\lib\\site-packages (from optuna) (4.64.0)\n",
      "Collecting alembic>=1.5.0\n",
      "  Downloading alembic-1.12.0-py3-none-any.whl (226 kB)\n",
      "Collecting cmaes>=0.10.0\n",
      "  Downloading cmaes-0.10.0-py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\flex\\anaconda3\\lib\\site-packages (from optuna) (6.0)\n",
      "Collecting Mako\n",
      "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\users\\flex\\anaconda3\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\flex\\anaconda3\\lib\\site-packages (from packaging>=20.0->optuna) (3.0.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\flex\\anaconda3\\lib\\site-packages (from sqlalchemy>=1.3.0->optuna) (1.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\flex\\anaconda3\\lib\\site-packages (from colorlog->optuna) (0.4.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\flex\\anaconda3\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (2.0.1)\n",
      "Installing collected packages: Mako, colorlog, cmaes, alembic, optuna\n",
      "Successfully installed Mako-1.2.4 alembic-1.12.0 cmaes-0.10.0 colorlog-6.7.0 optuna-3.3.0\n",
      "Collecting catboost\n",
      "  Downloading catboost-1.2.2-cp39-cp39-win_amd64.whl (101.0 MB)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\flex\\anaconda3\\lib\\site-packages (from catboost) (1.21.5)\n",
      "Requirement already satisfied: six in c:\\users\\flex\\anaconda3\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\flex\\anaconda3\\lib\\site-packages (from catboost) (1.7.3)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\flex\\anaconda3\\lib\\site-packages (from catboost) (1.4.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\flex\\anaconda3\\lib\\site-packages (from catboost) (3.5.1)\n",
      "Collecting graphviz\n",
      "  Downloading graphviz-0.20.1-py3-none-any.whl (47 kB)\n",
      "Requirement already satisfied: plotly in c:\\users\\flex\\anaconda3\\lib\\site-packages (from catboost) (5.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\flex\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\flex\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2021.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\flex\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\flex\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.3.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\flex\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (9.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\flex\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (3.0.4)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\flex\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\flex\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (21.3)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\flex\\anaconda3\\lib\\site-packages (from plotly->catboost) (8.0.1)\n",
      "Installing collected packages: graphviz, catboost\n",
      "Successfully installed catboost-1.2.2 graphviz-0.20.1\n"
     ]
    }
   ],
   "source": [
    "# catboost를 사용하기 위해 다음 코드를 실행합니다.\n",
    "\n",
    "!pip install optuna\n",
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "xbcYHmIsqycq"
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "cT3d6EKqsJRj"
   },
   "outputs": [],
   "source": [
    "df = datasets.load_iris()\n",
    "X = df.data\n",
    "y = df.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "8t-R1-Wfskfm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1eccaf28250>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CatBoostClassifier 객체를 생성하고 학습시켜 주세요.\n",
    "\n",
    "model_CBC = CatBoostClassifier()\n",
    "model_CBC.fit(X_train, y_train, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "7yfAnYNXs4LW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost의 예측 정확도: 0.9333\n"
     ]
    }
   ],
   "source": [
    "# pred에 X_test에 대한 예측 결과를 저장해 주세요.\n",
    "pred = model_CBC.predict(X_test)\n",
    "\n",
    "# 아래 코드를 완성해서 정확도를 출력하세요.\n",
    "print('CatBoost의 예측 정확도: {0:.4f}'.format(accuracy_score(y_test, pred)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
