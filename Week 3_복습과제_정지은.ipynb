{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oW4LpW9lRj3n"
   },
   "source": [
    "# **1. GBM**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s3_1vAdpRxoo"
   },
   "source": [
    "## **1-a. `creditcard.csv`를 다운받은 후 실습을 진행해 주세요.**\n",
    "- 데이터 출처: [Credit Card Fraud Detection](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3vR5gQ4HYGAX"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## Colab - 구글 드라이브 마운트\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Colab을 사용하시는 분들만 실행시켜 주시면 됩니다.\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      5\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "## Colab - 구글 드라이브 마운트\n",
    "# Colab을 사용하시는 분들만 실행시켜 주시면 됩니다.\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "lkOKaEKZG2Yn"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./creditcard.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2_tC0W-5Ryje"
   },
   "source": [
    "## **1-b. GradientBoostingClassifier을 이용하여 훈련 데이터를 fit한 후, GBM 정확도와 수행시간을 구하세요.**\n",
    "(test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "7zBOFln9ZENb"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "967Hgk2YZXfa",
    "outputId": "aa8b3623-a718-43f5-d07d-87cd0ec29b85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM 정확도: 0.9989\n"
     ]
    }
   ],
   "source": [
    "## 데이터 분할: 훈련 데이터와 테스트 데이터\n",
    "\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "## GBM 모델링\n",
    "# 아래에 코드를 작성해 주세요.\n",
    "gb_clf = GradientBoostingClassifier(random_state=42)\n",
    "start_time = time.time()\n",
    "gb_clf.fit(X_train, y_train)\n",
    "gb_pred = gb_clf.predict(X_test)\n",
    "gb_accuracy = accuracy_score(y_test, gb_pred)\n",
    "\n",
    "print('GBM 정확도: {0:.4f}'.format(gb_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0_npf7xNR1BZ"
   },
   "source": [
    "## **1-b(2). GBM으로 학습하는 시간이 얼마나 걸리는지 수행 시간을 출력해 주세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FdMUSczWa8_A",
    "outputId": "c47927fd-a125-4cab-a190-761f256d0009"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM 수행 시간: 202.1 초\n"
     ]
    }
   ],
   "source": [
    "print('GBM 수행 시간: {0:.1f} 초'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xqzN9Hy8TaOk"
   },
   "source": [
    "## **1-c. ```subsample``` 파라미터를 설정하여 gbm 모델을 학습시키고 학습 시간을 비교해 보세요.**  \n",
    "(subsample = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "FxWwRW_7TbT0"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4HAD9Ebsgte4",
    "outputId": "78b3f503-efbf-44f5-d170-4a05d34651e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM (subsample=0.8) 정확도: 0.9983\n",
      "GBM (subsample=0.8) 수행 시간: 154.5 초\n"
     ]
    }
   ],
   "source": [
    "gb_clf1 = GradientBoostingClassifier(random_state=42, subsample=0.8)\n",
    "start_time1 = time.time()\n",
    "gb_clf1.fit(X_train, y_train)\n",
    "gb_pred1 = gb_clf1.predict(X_test)\n",
    "gb_accuracy1 = accuracy_score(y_test, gb_pred1)\n",
    "\n",
    "print('GBM (subsample=0.8) 정확도: {0:.4f}'.format(gb_accuracy1))\n",
    "print('GBM (subsample=0.8) 수행 시간: {0:.1f} 초'.format(time.time() - start_time1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D52196vv7JoI"
   },
   "source": [
    "# **2. XGBoost**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "koZCKhp8HW4o"
   },
   "source": [
    "- 모델 : Python Wrapper XGBoost\n",
    "- 적용 데이터 : 위스콘신 유방암 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ECMkbXJ-7KT6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.3\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "\n",
    "print(xgboost.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5kFl0zeC7tQR"
   },
   "source": [
    "- 출력 : 1.7.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "fHDjuv_V7vAf"
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L11sPCSZ74oH"
   },
   "source": [
    "##**2-a. cancer_df의 shape을 프린트하고, 상위 5개 행을 확인해 주세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "4wBOlQxn72Te"
   },
   "outputs": [],
   "source": [
    "dataset = load_breast_cancer()\n",
    "X_features = dataset.data\n",
    "y_label = dataset.target\n",
    "\n",
    "cancer_df = pd.DataFrame(data = X_features, columns = dataset.feature_names)\n",
    "cancer_df['target'] = y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "cMfEC-nZ8HH-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cancer_df의 shape:  (569, 31)\n",
      "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
      "0        17.99         10.38          122.80     1001.0          0.11840   \n",
      "1        20.57         17.77          132.90     1326.0          0.08474   \n",
      "2        19.69         21.25          130.00     1203.0          0.10960   \n",
      "3        11.42         20.38           77.58      386.1          0.14250   \n",
      "4        20.29         14.34          135.10     1297.0          0.10030   \n",
      "\n",
      "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
      "0           0.27760          0.3001              0.14710         0.2419   \n",
      "1           0.07864          0.0869              0.07017         0.1812   \n",
      "2           0.15990          0.1974              0.12790         0.2069   \n",
      "3           0.28390          0.2414              0.10520         0.2597   \n",
      "4           0.13280          0.1980              0.10430         0.1809   \n",
      "\n",
      "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
      "0                 0.07871  ...          17.33           184.60      2019.0   \n",
      "1                 0.05667  ...          23.41           158.80      1956.0   \n",
      "2                 0.05999  ...          25.53           152.50      1709.0   \n",
      "3                 0.09744  ...          26.50            98.87       567.7   \n",
      "4                 0.05883  ...          16.67           152.20      1575.0   \n",
      "\n",
      "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
      "0            0.1622             0.6656           0.7119                0.2654   \n",
      "1            0.1238             0.1866           0.2416                0.1860   \n",
      "2            0.1444             0.4245           0.4504                0.2430   \n",
      "3            0.2098             0.8663           0.6869                0.2575   \n",
      "4            0.1374             0.2050           0.4000                0.1625   \n",
      "\n",
      "   worst symmetry  worst fractal dimension  target  \n",
      "0          0.4601                  0.11890       0  \n",
      "1          0.2750                  0.08902       0  \n",
      "2          0.3613                  0.08758       0  \n",
      "3          0.6638                  0.17300       0  \n",
      "4          0.2364                  0.07678       0  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"cancer_df의 shape: \", cancer_df.shape)\n",
    "\n",
    "print(cancer_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tOKlsQLD8HoD"
   },
   "source": [
    "## **2-b. 전체 데이터 중 80%는 학습용 데이터, 20%는 테스트용 데이터로 추출하고, 각각의 shape을 print해주세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "o6k1w2nf8SCm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455, 30) (114, 30)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test=train_test_split(X_features, y_label, test_size=0.2, random_state=156)\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "9ZB87ux88a6w"
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(data = X_train, label = y_train)\n",
    "dtest = xgb.DMatrix(data = X_test, label = y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tzzNfY028f5b"
   },
   "source": [
    "##**2-c. 주어진 정보를 바탕으로 하이퍼 파라미터 목록을 완성해 주세요.**\n",
    "- 트리의 최대 깊이 : 3\n",
    "- 학습률 : 0.1\n",
    "- 반복 횟수 : 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "BZIEP5CS8jSs"
   },
   "outputs": [],
   "source": [
    "params = {'max_depth':3,\n",
    "          'learning_rate' : 0.1,\n",
    "          'objective':'binary:logistic',\n",
    "          'eval_metric':'logloss'\n",
    "         }\n",
    "num_rounds = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "UInEOEh98t6z"
   },
   "outputs": [],
   "source": [
    "eval_list = [(dtrain,'train'),(dtest,'eval')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mzl7NufX8utk"
   },
   "source": [
    "## **2-d. 하이퍼 파라미터를 `train( )` 함수의 파라미터로 전달해 주세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "5vgia5qw8vCa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.60969\teval-logloss:0.61352\n",
      "[1]\ttrain-logloss:0.54080\teval-logloss:0.54784\n",
      "[2]\ttrain-logloss:0.48375\teval-logloss:0.49425\n",
      "[3]\ttrain-logloss:0.43446\teval-logloss:0.44799\n",
      "[4]\ttrain-logloss:0.39055\teval-logloss:0.40911\n",
      "[5]\ttrain-logloss:0.35415\teval-logloss:0.37498\n",
      "[6]\ttrain-logloss:0.32122\teval-logloss:0.34571\n",
      "[7]\ttrain-logloss:0.29259\teval-logloss:0.32053\n",
      "[8]\ttrain-logloss:0.26747\teval-logloss:0.29721\n",
      "[9]\ttrain-logloss:0.24515\teval-logloss:0.27799\n",
      "[10]\ttrain-logloss:0.22569\teval-logloss:0.26030\n",
      "[11]\ttrain-logloss:0.20794\teval-logloss:0.24604\n",
      "[12]\ttrain-logloss:0.19218\teval-logloss:0.23156\n",
      "[13]\ttrain-logloss:0.17792\teval-logloss:0.22005\n",
      "[14]\ttrain-logloss:0.16522\teval-logloss:0.20857\n",
      "[15]\ttrain-logloss:0.15362\teval-logloss:0.19999\n",
      "[16]\ttrain-logloss:0.14333\teval-logloss:0.19012\n",
      "[17]\ttrain-logloss:0.13398\teval-logloss:0.18182\n",
      "[18]\ttrain-logloss:0.12560\teval-logloss:0.17473\n",
      "[19]\ttrain-logloss:0.11729\teval-logloss:0.16766\n",
      "[20]\ttrain-logloss:0.10969\teval-logloss:0.15820\n",
      "[21]\ttrain-logloss:0.10297\teval-logloss:0.15472\n",
      "[22]\ttrain-logloss:0.09707\teval-logloss:0.14895\n",
      "[23]\ttrain-logloss:0.09143\teval-logloss:0.14331\n",
      "[24]\ttrain-logloss:0.08634\teval-logloss:0.13634\n",
      "[25]\ttrain-logloss:0.08131\teval-logloss:0.13278\n",
      "[26]\ttrain-logloss:0.07686\teval-logloss:0.12791\n",
      "[27]\ttrain-logloss:0.07284\teval-logloss:0.12526\n",
      "[28]\ttrain-logloss:0.06925\teval-logloss:0.11998\n",
      "[29]\ttrain-logloss:0.06555\teval-logloss:0.11641\n",
      "[30]\ttrain-logloss:0.06241\teval-logloss:0.11450\n",
      "[31]\ttrain-logloss:0.05959\teval-logloss:0.11257\n",
      "[32]\ttrain-logloss:0.05710\teval-logloss:0.11154\n",
      "[33]\ttrain-logloss:0.05441\teval-logloss:0.10868\n",
      "[34]\ttrain-logloss:0.05204\teval-logloss:0.10668\n",
      "[35]\ttrain-logloss:0.04975\teval-logloss:0.10421\n",
      "[36]\ttrain-logloss:0.04775\teval-logloss:0.10296\n",
      "[37]\ttrain-logloss:0.04585\teval-logloss:0.10058\n",
      "[38]\ttrain-logloss:0.04401\teval-logloss:0.09868\n",
      "[39]\ttrain-logloss:0.04226\teval-logloss:0.09644\n",
      "[40]\ttrain-logloss:0.04065\teval-logloss:0.09587\n",
      "[41]\ttrain-logloss:0.03913\teval-logloss:0.09424\n",
      "[42]\ttrain-logloss:0.03738\teval-logloss:0.09471\n",
      "[43]\ttrain-logloss:0.03611\teval-logloss:0.09427\n",
      "[44]\ttrain-logloss:0.03494\teval-logloss:0.09389\n",
      "[45]\ttrain-logloss:0.03365\teval-logloss:0.09418\n",
      "[46]\ttrain-logloss:0.03253\teval-logloss:0.09402\n",
      "[47]\ttrain-logloss:0.03148\teval-logloss:0.09236\n",
      "[48]\ttrain-logloss:0.03039\teval-logloss:0.09301\n",
      "[49]\ttrain-logloss:0.02947\teval-logloss:0.09127\n",
      "[50]\ttrain-logloss:0.02854\teval-logloss:0.09005\n",
      "[51]\ttrain-logloss:0.02753\teval-logloss:0.08961\n",
      "[52]\ttrain-logloss:0.02656\teval-logloss:0.08958\n",
      "[53]\ttrain-logloss:0.02568\teval-logloss:0.09070\n",
      "[54]\ttrain-logloss:0.02500\teval-logloss:0.08958\n",
      "[55]\ttrain-logloss:0.02430\teval-logloss:0.09036\n",
      "[56]\ttrain-logloss:0.02357\teval-logloss:0.09159\n",
      "[57]\ttrain-logloss:0.02296\teval-logloss:0.09153\n",
      "[58]\ttrain-logloss:0.02249\teval-logloss:0.09199\n",
      "[59]\ttrain-logloss:0.02185\teval-logloss:0.09195\n",
      "[60]\ttrain-logloss:0.02132\teval-logloss:0.09194\n",
      "[61]\ttrain-logloss:0.02079\teval-logloss:0.09146\n",
      "[62]\ttrain-logloss:0.02022\teval-logloss:0.09031\n",
      "[63]\ttrain-logloss:0.01970\teval-logloss:0.08941\n",
      "[64]\ttrain-logloss:0.01918\teval-logloss:0.08972\n",
      "[65]\ttrain-logloss:0.01872\teval-logloss:0.08974\n",
      "[66]\ttrain-logloss:0.01833\teval-logloss:0.08962\n",
      "[67]\ttrain-logloss:0.01787\teval-logloss:0.08873\n",
      "[68]\ttrain-logloss:0.01760\teval-logloss:0.08862\n",
      "[69]\ttrain-logloss:0.01724\teval-logloss:0.08974\n",
      "[70]\ttrain-logloss:0.01688\teval-logloss:0.08998\n",
      "[71]\ttrain-logloss:0.01664\teval-logloss:0.08978\n",
      "[72]\ttrain-logloss:0.01629\teval-logloss:0.08958\n",
      "[73]\ttrain-logloss:0.01598\teval-logloss:0.08953\n",
      "[74]\ttrain-logloss:0.01566\teval-logloss:0.08875\n",
      "[75]\ttrain-logloss:0.01539\teval-logloss:0.08860\n",
      "[76]\ttrain-logloss:0.01515\teval-logloss:0.08812\n",
      "[77]\ttrain-logloss:0.01488\teval-logloss:0.08840\n",
      "[78]\ttrain-logloss:0.01464\teval-logloss:0.08874\n",
      "[79]\ttrain-logloss:0.01449\teval-logloss:0.08815\n",
      "[80]\ttrain-logloss:0.01418\teval-logloss:0.08758\n",
      "[81]\ttrain-logloss:0.01400\teval-logloss:0.08741\n",
      "[82]\ttrain-logloss:0.01377\teval-logloss:0.08849\n",
      "[83]\ttrain-logloss:0.01357\teval-logloss:0.08857\n",
      "[84]\ttrain-logloss:0.01341\teval-logloss:0.08807\n",
      "[85]\ttrain-logloss:0.01325\teval-logloss:0.08764\n",
      "[86]\ttrain-logloss:0.01311\teval-logloss:0.08742\n",
      "[87]\ttrain-logloss:0.01293\teval-logloss:0.08761\n",
      "[88]\ttrain-logloss:0.01271\teval-logloss:0.08707\n",
      "[89]\ttrain-logloss:0.01254\teval-logloss:0.08727\n",
      "[90]\ttrain-logloss:0.01235\teval-logloss:0.08716\n",
      "[91]\ttrain-logloss:0.01223\teval-logloss:0.08696\n",
      "[92]\ttrain-logloss:0.01206\teval-logloss:0.08717\n",
      "[93]\ttrain-logloss:0.01193\teval-logloss:0.08707\n",
      "[94]\ttrain-logloss:0.01182\teval-logloss:0.08659\n",
      "[95]\ttrain-logloss:0.01165\teval-logloss:0.08612\n",
      "[96]\ttrain-logloss:0.01148\teval-logloss:0.08714\n",
      "[97]\ttrain-logloss:0.01136\teval-logloss:0.08677\n",
      "[98]\ttrain-logloss:0.01124\teval-logloss:0.08669\n",
      "[99]\ttrain-logloss:0.01113\teval-logloss:0.08655\n",
      "[100]\ttrain-logloss:0.01100\teval-logloss:0.08650\n",
      "[101]\ttrain-logloss:0.01085\teval-logloss:0.08641\n",
      "[102]\ttrain-logloss:0.01075\teval-logloss:0.08629\n",
      "[103]\ttrain-logloss:0.01064\teval-logloss:0.08626\n",
      "[104]\ttrain-logloss:0.01050\teval-logloss:0.08683\n",
      "[105]\ttrain-logloss:0.01040\teval-logloss:0.08677\n",
      "[106]\ttrain-logloss:0.01030\teval-logloss:0.08732\n",
      "[107]\ttrain-logloss:0.01020\teval-logloss:0.08730\n",
      "[108]\ttrain-logloss:0.01007\teval-logloss:0.08728\n",
      "[109]\ttrain-logloss:0.01000\teval-logloss:0.08730\n",
      "[110]\ttrain-logloss:0.00991\teval-logloss:0.08729\n",
      "[111]\ttrain-logloss:0.00980\teval-logloss:0.08800\n",
      "[112]\ttrain-logloss:0.00971\teval-logloss:0.08794\n",
      "[113]\ttrain-logloss:0.00963\teval-logloss:0.08784\n",
      "[114]\ttrain-logloss:0.00956\teval-logloss:0.08807\n",
      "[115]\ttrain-logloss:0.00948\teval-logloss:0.08765\n",
      "[116]\ttrain-logloss:0.00942\teval-logloss:0.08730\n",
      "[117]\ttrain-logloss:0.00931\teval-logloss:0.08780\n",
      "[118]\ttrain-logloss:0.00923\teval-logloss:0.08775\n",
      "[119]\ttrain-logloss:0.00915\teval-logloss:0.08768\n",
      "[120]\ttrain-logloss:0.00912\teval-logloss:0.08763\n",
      "[121]\ttrain-logloss:0.00902\teval-logloss:0.08757\n",
      "[122]\ttrain-logloss:0.00897\teval-logloss:0.08755\n",
      "[123]\ttrain-logloss:0.00890\teval-logloss:0.08716\n",
      "[124]\ttrain-logloss:0.00884\teval-logloss:0.08767\n",
      "[125]\ttrain-logloss:0.00880\teval-logloss:0.08774\n",
      "[126]\ttrain-logloss:0.00871\teval-logloss:0.08827\n",
      "[127]\ttrain-logloss:0.00865\teval-logloss:0.08831\n",
      "[128]\ttrain-logloss:0.00861\teval-logloss:0.08827\n",
      "[129]\ttrain-logloss:0.00856\teval-logloss:0.08789\n",
      "[130]\ttrain-logloss:0.00846\teval-logloss:0.08886\n",
      "[131]\ttrain-logloss:0.00842\teval-logloss:0.08868\n",
      "[132]\ttrain-logloss:0.00839\teval-logloss:0.08874\n",
      "[133]\ttrain-logloss:0.00830\teval-logloss:0.08922\n",
      "[134]\ttrain-logloss:0.00827\teval-logloss:0.08918\n",
      "[135]\ttrain-logloss:0.00822\teval-logloss:0.08882\n",
      "[136]\ttrain-logloss:0.00816\teval-logloss:0.08851\n",
      "[137]\ttrain-logloss:0.00808\teval-logloss:0.08848\n",
      "[138]\ttrain-logloss:0.00805\teval-logloss:0.08839\n",
      "[139]\ttrain-logloss:0.00797\teval-logloss:0.08915\n",
      "[140]\ttrain-logloss:0.00795\teval-logloss:0.08911\n",
      "[141]\ttrain-logloss:0.00790\teval-logloss:0.08876\n",
      "[142]\ttrain-logloss:0.00787\teval-logloss:0.08868\n",
      "[143]\ttrain-logloss:0.00785\teval-logloss:0.08839\n",
      "[144]\ttrain-logloss:0.00778\teval-logloss:0.08927\n",
      "[145]\ttrain-logloss:0.00775\teval-logloss:0.08924\n",
      "[146]\ttrain-logloss:0.00773\teval-logloss:0.08914\n",
      "[147]\ttrain-logloss:0.00769\teval-logloss:0.08891\n",
      "[148]\ttrain-logloss:0.00762\teval-logloss:0.08942\n",
      "[149]\ttrain-logloss:0.00760\teval-logloss:0.08939\n",
      "[150]\ttrain-logloss:0.00757\teval-logloss:0.08911\n",
      "[151]\ttrain-logloss:0.00752\teval-logloss:0.08873\n",
      "[152]\ttrain-logloss:0.00750\teval-logloss:0.08872\n",
      "[153]\ttrain-logloss:0.00746\teval-logloss:0.08848\n",
      "[154]\ttrain-logloss:0.00741\teval-logloss:0.08847\n",
      "[155]\ttrain-logloss:0.00739\teval-logloss:0.08855\n",
      "[156]\ttrain-logloss:0.00737\teval-logloss:0.08852\n",
      "[157]\ttrain-logloss:0.00735\teval-logloss:0.08855\n",
      "[158]\ttrain-logloss:0.00732\teval-logloss:0.08827\n",
      "[159]\ttrain-logloss:0.00730\teval-logloss:0.08830\n",
      "[160]\ttrain-logloss:0.00728\teval-logloss:0.08828\n",
      "[161]\ttrain-logloss:0.00726\teval-logloss:0.08801\n",
      "[162]\ttrain-logloss:0.00724\teval-logloss:0.08776\n",
      "[163]\ttrain-logloss:0.00722\teval-logloss:0.08778\n",
      "[164]\ttrain-logloss:0.00720\teval-logloss:0.08778\n",
      "[165]\ttrain-logloss:0.00718\teval-logloss:0.08752\n",
      "[166]\ttrain-logloss:0.00716\teval-logloss:0.08754\n",
      "[167]\ttrain-logloss:0.00714\teval-logloss:0.08764\n",
      "[168]\ttrain-logloss:0.00712\teval-logloss:0.08739\n",
      "[169]\ttrain-logloss:0.00710\teval-logloss:0.08738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[170]\ttrain-logloss:0.00708\teval-logloss:0.08730\n",
      "[171]\ttrain-logloss:0.00707\teval-logloss:0.08737\n",
      "[172]\ttrain-logloss:0.00705\teval-logloss:0.08740\n",
      "[173]\ttrain-logloss:0.00703\teval-logloss:0.08739\n",
      "[174]\ttrain-logloss:0.00701\teval-logloss:0.08713\n",
      "[175]\ttrain-logloss:0.00699\teval-logloss:0.08716\n",
      "[176]\ttrain-logloss:0.00697\teval-logloss:0.08695\n",
      "[177]\ttrain-logloss:0.00695\teval-logloss:0.08705\n",
      "[178]\ttrain-logloss:0.00694\teval-logloss:0.08697\n",
      "[179]\ttrain-logloss:0.00692\teval-logloss:0.08697\n",
      "[180]\ttrain-logloss:0.00690\teval-logloss:0.08704\n",
      "[181]\ttrain-logloss:0.00688\teval-logloss:0.08680\n",
      "[182]\ttrain-logloss:0.00687\teval-logloss:0.08683\n",
      "[183]\ttrain-logloss:0.00685\teval-logloss:0.08658\n",
      "[184]\ttrain-logloss:0.00683\teval-logloss:0.08659\n",
      "[185]\ttrain-logloss:0.00681\teval-logloss:0.08661\n",
      "[186]\ttrain-logloss:0.00680\teval-logloss:0.08637\n",
      "[187]\ttrain-logloss:0.00678\teval-logloss:0.08637\n",
      "[188]\ttrain-logloss:0.00676\teval-logloss:0.08630\n",
      "[189]\ttrain-logloss:0.00675\teval-logloss:0.08610\n",
      "[190]\ttrain-logloss:0.00673\teval-logloss:0.08602\n",
      "[191]\ttrain-logloss:0.00671\teval-logloss:0.08605\n",
      "[192]\ttrain-logloss:0.00670\teval-logloss:0.08615\n",
      "[193]\ttrain-logloss:0.00668\teval-logloss:0.08592\n",
      "[194]\ttrain-logloss:0.00667\teval-logloss:0.08591\n",
      "[195]\ttrain-logloss:0.00665\teval-logloss:0.08598\n",
      "[196]\ttrain-logloss:0.00663\teval-logloss:0.08601\n",
      "[197]\ttrain-logloss:0.00662\teval-logloss:0.08592\n",
      "[198]\ttrain-logloss:0.00660\teval-logloss:0.08585\n",
      "[199]\ttrain-logloss:0.00659\teval-logloss:0.08587\n",
      "[200]\ttrain-logloss:0.00657\teval-logloss:0.08589\n",
      "[201]\ttrain-logloss:0.00656\teval-logloss:0.08595\n",
      "[202]\ttrain-logloss:0.00654\teval-logloss:0.08573\n",
      "[203]\ttrain-logloss:0.00653\teval-logloss:0.08573\n",
      "[204]\ttrain-logloss:0.00651\teval-logloss:0.08575\n",
      "[205]\ttrain-logloss:0.00650\teval-logloss:0.08582\n",
      "[206]\ttrain-logloss:0.00648\teval-logloss:0.08584\n",
      "[207]\ttrain-logloss:0.00647\teval-logloss:0.08578\n",
      "[208]\ttrain-logloss:0.00645\teval-logloss:0.08569\n",
      "[209]\ttrain-logloss:0.00644\teval-logloss:0.08571\n",
      "[210]\ttrain-logloss:0.00643\teval-logloss:0.08581\n",
      "[211]\ttrain-logloss:0.00641\teval-logloss:0.08559\n",
      "[212]\ttrain-logloss:0.00640\teval-logloss:0.08580\n",
      "[213]\ttrain-logloss:0.00639\teval-logloss:0.08581\n",
      "[214]\ttrain-logloss:0.00637\teval-logloss:0.08574\n",
      "[215]\ttrain-logloss:0.00636\teval-logloss:0.08566\n",
      "[216]\ttrain-logloss:0.00635\teval-logloss:0.08584\n",
      "[217]\ttrain-logloss:0.00633\teval-logloss:0.08563\n",
      "[218]\ttrain-logloss:0.00632\teval-logloss:0.08573\n",
      "[219]\ttrain-logloss:0.00631\teval-logloss:0.08578\n",
      "[220]\ttrain-logloss:0.00629\teval-logloss:0.08579\n",
      "[221]\ttrain-logloss:0.00628\teval-logloss:0.08582\n",
      "[222]\ttrain-logloss:0.00627\teval-logloss:0.08576\n",
      "[223]\ttrain-logloss:0.00626\teval-logloss:0.08567\n",
      "[224]\ttrain-logloss:0.00624\teval-logloss:0.08586\n",
      "[225]\ttrain-logloss:0.00623\teval-logloss:0.08587\n",
      "[226]\ttrain-logloss:0.00622\teval-logloss:0.08593\n",
      "[227]\ttrain-logloss:0.00621\teval-logloss:0.08595\n",
      "[228]\ttrain-logloss:0.00619\teval-logloss:0.08587\n",
      "[229]\ttrain-logloss:0.00618\teval-logloss:0.08606\n",
      "[230]\ttrain-logloss:0.00617\teval-logloss:0.08600\n",
      "[231]\ttrain-logloss:0.00616\teval-logloss:0.08592\n",
      "[232]\ttrain-logloss:0.00615\teval-logloss:0.08610\n",
      "[233]\ttrain-logloss:0.00614\teval-logloss:0.08611\n",
      "[234]\ttrain-logloss:0.00612\teval-logloss:0.08617\n",
      "[235]\ttrain-logloss:0.00611\teval-logloss:0.08626\n",
      "[236]\ttrain-logloss:0.00610\teval-logloss:0.08629\n",
      "[237]\ttrain-logloss:0.00609\teval-logloss:0.08622\n",
      "[238]\ttrain-logloss:0.00608\teval-logloss:0.08639\n",
      "[239]\ttrain-logloss:0.00607\teval-logloss:0.08634\n",
      "[240]\ttrain-logloss:0.00606\teval-logloss:0.08618\n",
      "[241]\ttrain-logloss:0.00605\teval-logloss:0.08620\n",
      "[242]\ttrain-logloss:0.00604\teval-logloss:0.08625\n",
      "[243]\ttrain-logloss:0.00602\teval-logloss:0.08626\n",
      "[244]\ttrain-logloss:0.00601\teval-logloss:0.08629\n",
      "[245]\ttrain-logloss:0.00600\teval-logloss:0.08622\n",
      "[246]\ttrain-logloss:0.00599\teval-logloss:0.08640\n",
      "[247]\ttrain-logloss:0.00598\teval-logloss:0.08635\n",
      "[248]\ttrain-logloss:0.00597\teval-logloss:0.08628\n",
      "[249]\ttrain-logloss:0.00596\teval-logloss:0.08645\n",
      "[250]\ttrain-logloss:0.00595\teval-logloss:0.08629\n",
      "[251]\ttrain-logloss:0.00594\teval-logloss:0.08631\n",
      "[252]\ttrain-logloss:0.00593\teval-logloss:0.08636\n",
      "[253]\ttrain-logloss:0.00592\teval-logloss:0.08639\n",
      "[254]\ttrain-logloss:0.00591\teval-logloss:0.08649\n",
      "[255]\ttrain-logloss:0.00590\teval-logloss:0.08644\n",
      "[256]\ttrain-logloss:0.00589\teval-logloss:0.08629\n",
      "[257]\ttrain-logloss:0.00588\teval-logloss:0.08646\n",
      "[258]\ttrain-logloss:0.00587\teval-logloss:0.08639\n",
      "[259]\ttrain-logloss:0.00586\teval-logloss:0.08644\n",
      "[260]\ttrain-logloss:0.00585\teval-logloss:0.08646\n",
      "[261]\ttrain-logloss:0.00585\teval-logloss:0.08649\n",
      "[262]\ttrain-logloss:0.00584\teval-logloss:0.08645\n",
      "[263]\ttrain-logloss:0.00583\teval-logloss:0.08647\n",
      "[264]\ttrain-logloss:0.00582\teval-logloss:0.08632\n",
      "[265]\ttrain-logloss:0.00581\teval-logloss:0.08649\n",
      "[266]\ttrain-logloss:0.00580\teval-logloss:0.08654\n",
      "[267]\ttrain-logloss:0.00579\teval-logloss:0.08647\n",
      "[268]\ttrain-logloss:0.00578\teval-logloss:0.08650\n",
      "[269]\ttrain-logloss:0.00577\teval-logloss:0.08652\n",
      "[270]\ttrain-logloss:0.00576\teval-logloss:0.08669\n",
      "[271]\ttrain-logloss:0.00576\teval-logloss:0.08674\n",
      "[272]\ttrain-logloss:0.00575\teval-logloss:0.08683\n",
      "[273]\ttrain-logloss:0.00574\teval-logloss:0.08668\n",
      "[274]\ttrain-logloss:0.00573\teval-logloss:0.08664\n",
      "[275]\ttrain-logloss:0.00572\teval-logloss:0.08650\n",
      "[276]\ttrain-logloss:0.00571\teval-logloss:0.08635\n",
      "[277]\ttrain-logloss:0.00570\teval-logloss:0.08652\n",
      "[278]\ttrain-logloss:0.00570\teval-logloss:0.08657\n",
      "[279]\ttrain-logloss:0.00569\teval-logloss:0.08659\n",
      "[280]\ttrain-logloss:0.00568\teval-logloss:0.08668\n",
      "[281]\ttrain-logloss:0.00567\teval-logloss:0.08664\n",
      "[282]\ttrain-logloss:0.00566\teval-logloss:0.08650\n",
      "[283]\ttrain-logloss:0.00565\teval-logloss:0.08636\n",
      "[284]\ttrain-logloss:0.00565\teval-logloss:0.08640\n",
      "[285]\ttrain-logloss:0.00564\teval-logloss:0.08643\n",
      "[286]\ttrain-logloss:0.00563\teval-logloss:0.08646\n",
      "[287]\ttrain-logloss:0.00562\teval-logloss:0.08650\n",
      "[288]\ttrain-logloss:0.00562\teval-logloss:0.08637\n",
      "[289]\ttrain-logloss:0.00561\teval-logloss:0.08646\n",
      "[290]\ttrain-logloss:0.00560\teval-logloss:0.08645\n",
      "[291]\ttrain-logloss:0.00559\teval-logloss:0.08632\n",
      "[292]\ttrain-logloss:0.00558\teval-logloss:0.08628\n",
      "[293]\ttrain-logloss:0.00558\teval-logloss:0.08615\n",
      "[294]\ttrain-logloss:0.00557\teval-logloss:0.08620\n",
      "[295]\ttrain-logloss:0.00556\teval-logloss:0.08622\n",
      "[296]\ttrain-logloss:0.00556\teval-logloss:0.08631\n",
      "[297]\ttrain-logloss:0.00555\teval-logloss:0.08618\n",
      "[298]\ttrain-logloss:0.00554\teval-logloss:0.08626\n",
      "[299]\ttrain-logloss:0.00553\teval-logloss:0.08613\n",
      "[300]\ttrain-logloss:0.00553\teval-logloss:0.08618\n",
      "[301]\ttrain-logloss:0.00552\teval-logloss:0.08605\n",
      "[302]\ttrain-logloss:0.00551\teval-logloss:0.08602\n",
      "[303]\ttrain-logloss:0.00551\teval-logloss:0.08610\n",
      "[304]\ttrain-logloss:0.00550\teval-logloss:0.08598\n",
      "[305]\ttrain-logloss:0.00549\teval-logloss:0.08606\n",
      "[306]\ttrain-logloss:0.00548\teval-logloss:0.08597\n",
      "[307]\ttrain-logloss:0.00548\teval-logloss:0.08600\n",
      "[308]\ttrain-logloss:0.00547\teval-logloss:0.08600\n",
      "[309]\ttrain-logloss:0.00546\teval-logloss:0.08588\n",
      "[310]\ttrain-logloss:0.00546\teval-logloss:0.08592\n",
      "[311]\ttrain-logloss:0.00545\teval-logloss:0.08595\n",
      "[312]\ttrain-logloss:0.00544\teval-logloss:0.08603\n",
      "[313]\ttrain-logloss:0.00544\teval-logloss:0.08611\n",
      "[314]\ttrain-logloss:0.00543\teval-logloss:0.08599\n",
      "[315]\ttrain-logloss:0.00542\teval-logloss:0.08590\n",
      "[316]\ttrain-logloss:0.00542\teval-logloss:0.08595\n",
      "[317]\ttrain-logloss:0.00541\teval-logloss:0.08598\n",
      "[318]\ttrain-logloss:0.00540\teval-logloss:0.08600\n",
      "[319]\ttrain-logloss:0.00540\teval-logloss:0.08588\n",
      "[320]\ttrain-logloss:0.00539\teval-logloss:0.08597\n",
      "[321]\ttrain-logloss:0.00539\teval-logloss:0.08605\n",
      "[322]\ttrain-logloss:0.00538\teval-logloss:0.08609\n",
      "[323]\ttrain-logloss:0.00537\teval-logloss:0.08598\n",
      "[324]\ttrain-logloss:0.00537\teval-logloss:0.08598\n",
      "[325]\ttrain-logloss:0.00536\teval-logloss:0.08590\n",
      "[326]\ttrain-logloss:0.00535\teval-logloss:0.08578\n",
      "[327]\ttrain-logloss:0.00535\teval-logloss:0.08586\n",
      "[328]\ttrain-logloss:0.00534\teval-logloss:0.08594\n",
      "[329]\ttrain-logloss:0.00534\teval-logloss:0.08582\n",
      "[330]\ttrain-logloss:0.00533\teval-logloss:0.08587\n",
      "[331]\ttrain-logloss:0.00532\teval-logloss:0.08589\n",
      "[332]\ttrain-logloss:0.00532\teval-logloss:0.08592\n",
      "[333]\ttrain-logloss:0.00531\teval-logloss:0.08584\n",
      "[334]\ttrain-logloss:0.00531\teval-logloss:0.08574\n",
      "[335]\ttrain-logloss:0.00530\teval-logloss:0.08582\n",
      "[336]\ttrain-logloss:0.00529\teval-logloss:0.08589\n",
      "[337]\ttrain-logloss:0.00529\teval-logloss:0.08594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[338]\ttrain-logloss:0.00528\teval-logloss:0.08583\n",
      "[339]\ttrain-logloss:0.00528\teval-logloss:0.08591\n",
      "[340]\ttrain-logloss:0.00527\teval-logloss:0.08583\n",
      "[341]\ttrain-logloss:0.00527\teval-logloss:0.08573\n",
      "[342]\ttrain-logloss:0.00526\teval-logloss:0.08568\n",
      "[343]\ttrain-logloss:0.00525\teval-logloss:0.08572\n",
      "[344]\ttrain-logloss:0.00525\teval-logloss:0.08580\n",
      "[345]\ttrain-logloss:0.00524\teval-logloss:0.08582\n",
      "[346]\ttrain-logloss:0.00524\teval-logloss:0.08572\n",
      "[347]\ttrain-logloss:0.00523\teval-logloss:0.08579\n",
      "[348]\ttrain-logloss:0.00523\teval-logloss:0.08584\n",
      "[349]\ttrain-logloss:0.00522\teval-logloss:0.08573\n",
      "[350]\ttrain-logloss:0.00522\teval-logloss:0.08566\n",
      "[351]\ttrain-logloss:0.00521\teval-logloss:0.08573\n",
      "[352]\ttrain-logloss:0.00521\teval-logloss:0.08581\n",
      "[353]\ttrain-logloss:0.00520\teval-logloss:0.08571\n",
      "[354]\ttrain-logloss:0.00519\teval-logloss:0.08566\n",
      "[355]\ttrain-logloss:0.00519\teval-logloss:0.08570\n",
      "[356]\ttrain-logloss:0.00518\teval-logloss:0.08563\n",
      "[357]\ttrain-logloss:0.00518\teval-logloss:0.08553\n",
      "[358]\ttrain-logloss:0.00517\teval-logloss:0.08560\n",
      "[359]\ttrain-logloss:0.00517\teval-logloss:0.08568\n",
      "[360]\ttrain-logloss:0.00516\teval-logloss:0.08558\n",
      "[361]\ttrain-logloss:0.00516\teval-logloss:0.08560\n",
      "[362]\ttrain-logloss:0.00515\teval-logloss:0.08564\n",
      "[363]\ttrain-logloss:0.00515\teval-logloss:0.08571\n",
      "[364]\ttrain-logloss:0.00514\teval-logloss:0.08579\n",
      "[365]\ttrain-logloss:0.00514\teval-logloss:0.08569\n",
      "[366]\ttrain-logloss:0.00513\teval-logloss:0.08573\n",
      "[367]\ttrain-logloss:0.00513\teval-logloss:0.08568\n",
      "[368]\ttrain-logloss:0.00512\teval-logloss:0.08559\n",
      "[369]\ttrain-logloss:0.00512\teval-logloss:0.08552\n",
      "[370]\ttrain-logloss:0.00511\teval-logloss:0.08559\n",
      "[371]\ttrain-logloss:0.00511\teval-logloss:0.08550\n",
      "[372]\ttrain-logloss:0.00511\teval-logloss:0.08556\n",
      "[373]\ttrain-logloss:0.00510\teval-logloss:0.08560\n",
      "[374]\ttrain-logloss:0.00510\teval-logloss:0.08563\n",
      "[375]\ttrain-logloss:0.00509\teval-logloss:0.08553\n",
      "[376]\ttrain-logloss:0.00509\teval-logloss:0.08561\n",
      "[377]\ttrain-logloss:0.00508\teval-logloss:0.08567\n",
      "[378]\ttrain-logloss:0.00508\teval-logloss:0.08571\n",
      "[379]\ttrain-logloss:0.00507\teval-logloss:0.08562\n",
      "[380]\ttrain-logloss:0.00507\teval-logloss:0.08558\n",
      "[381]\ttrain-logloss:0.00506\teval-logloss:0.08562\n",
      "[382]\ttrain-logloss:0.00506\teval-logloss:0.08564\n",
      "[383]\ttrain-logloss:0.00506\teval-logloss:0.08555\n",
      "[384]\ttrain-logloss:0.00505\teval-logloss:0.08562\n",
      "[385]\ttrain-logloss:0.00505\teval-logloss:0.08562\n",
      "[386]\ttrain-logloss:0.00504\teval-logloss:0.08555\n",
      "[387]\ttrain-logloss:0.00504\teval-logloss:0.08546\n",
      "[388]\ttrain-logloss:0.00503\teval-logloss:0.08550\n",
      "[389]\ttrain-logloss:0.00503\teval-logloss:0.08546\n",
      "[390]\ttrain-logloss:0.00503\teval-logloss:0.08532\n",
      "[391]\ttrain-logloss:0.00502\teval-logloss:0.08539\n",
      "[392]\ttrain-logloss:0.00502\teval-logloss:0.08530\n",
      "[393]\ttrain-logloss:0.00501\teval-logloss:0.08537\n",
      "[394]\ttrain-logloss:0.00501\teval-logloss:0.08530\n",
      "[395]\ttrain-logloss:0.00500\teval-logloss:0.08537\n",
      "[396]\ttrain-logloss:0.00500\teval-logloss:0.08528\n",
      "[397]\ttrain-logloss:0.00500\teval-logloss:0.08532\n",
      "[398]\ttrain-logloss:0.00499\teval-logloss:0.08528\n",
      "[399]\ttrain-logloss:0.00499\teval-logloss:0.08520\n"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.train(params=params, dtrain=dtrain, num_boost_round=num_rounds, evals=eval_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "5UFWSwQp8yA8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict( ) 수행 결과값을 10개만 표시, 예측 확률 값으로 표시됨\n",
      "[0.95  0.003 0.9   0.086 0.993 1.    1.    0.999 0.998 0.   ]\n",
      "예측값 10개만 표시: [1, 0, 1, 0, 1, 1, 1, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "pred_probs = xgb_model.predict(dtest)\n",
    "print('predict( ) 수행 결과값을 10개만 표시, 예측 확률 값으로 표시됨')\n",
    "print(np.round(pred_probs[:10],3))\n",
    "\n",
    "# 예측 확률이 0.5 보다 크면 1 , 그렇지 않으면 0 으로 예측값 결정하여 List 객체인 preds에 저장\n",
    "preds = [ 1 if x > 0.5 else 0 for x in pred_probs ]\n",
    "print('예측값 10개만 표시:',preds[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mxk9DN5383sp"
   },
   "source": [
    "##**2-e. `get_eval_clf()` 을 통해 예측 평가를 진행해주세요**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "xS27kc1780cD"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "def get_clf_eval(y_test, pred=None, pred_proba=None):\n",
    "    confusion = confusion_matrix( y_test, pred)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    precision = precision_score(y_test , pred)\n",
    "    recall = recall_score(y_test , pred)\n",
    "    f1 = f1_score(y_test,pred)\n",
    "    # ROC-AUC 추가\n",
    "    roc_auc = roc_auc_score(y_test, pred_proba)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    # ROC-AUC print 추가\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\\\n",
    "    F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "v-foPK_M82hT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[35  2]\n",
      " [ 1 76]]\n",
      "정확도: 0.9737, 정밀도: 0.9744, 재현율: 0.9870,    F1: 0.9806, AUC:0.9951\n"
     ]
    }
   ],
   "source": [
    "get_clf_eval(y_test, preds, pred_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uvg4b6ap9lXg"
   },
   "source": [
    "# **3. LightGBM, HyperOpt**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f8SBYxBJ-vhb"
   },
   "source": [
    "## **3-1. LightGBM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SnRlTMVaIdU6"
   },
   "source": [
    "### **3-1-a. ```water_potability.csv```를 불러와 df에 저장해 주세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "3cg-dfFE-nOx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm==3.3.2\n",
      "  Using cached lightgbm-3.3.2.tar.gz (1.5 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: wheel in ./anaconda3/lib/python3.11/site-packages (from lightgbm==3.3.2) (0.38.4)\n",
      "Requirement already satisfied: numpy in ./anaconda3/lib/python3.11/site-packages (from lightgbm==3.3.2) (1.24.3)\n",
      "Requirement already satisfied: scipy in ./anaconda3/lib/python3.11/site-packages (from lightgbm==3.3.2) (1.10.0)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in ./anaconda3/lib/python3.11/site-packages (from lightgbm==3.3.2) (1.1.3)\n",
      "Requirement already satisfied: joblib>=1.0.0 in ./anaconda3/lib/python3.11/site-packages (from scikit-learn!=0.22.0->lightgbm==3.3.2) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./anaconda3/lib/python3.11/site-packages (from scikit-learn!=0.22.0->lightgbm==3.3.2) (2.2.0)\n",
      "Building wheels for collected packages: lightgbm\n",
      "  Building wheel for lightgbm (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[101 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m INFO:root:running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/1r/xjj371_x7v7cjx48l_txs48c0000gn/T/pip-install-ekjo9mua/lightgbm_8a027b0cb4734ea7bf3b1c4507302e82/setup.py:220: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         Please avoid running ``setup.py`` directly.\n",
      "  \u001b[31m   \u001b[0m         Instead, use pypa/build, pypa/installer or other\n",
      "  \u001b[31m   \u001b[0m         standards-based tools.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   install.initialize_options(self)\n",
      "  \u001b[31m   \u001b[0m INFO:root:running build\n",
      "  \u001b[31m   \u001b[0m INFO:root:running build_py\n",
      "  \u001b[31m   \u001b[0m INFO:root:creating build\n",
      "  \u001b[31m   \u001b[0m INFO:root:creating build/lib\n",
      "  \u001b[31m   \u001b[0m INFO:root:creating build/lib/lightgbm\n",
      "  \u001b[31m   \u001b[0m INFO:root:copying lightgbm/callback.py -> build/lib/lightgbm\n",
      "  \u001b[31m   \u001b[0m INFO:root:copying lightgbm/compat.py -> build/lib/lightgbm\n",
      "  \u001b[31m   \u001b[0m INFO:root:copying lightgbm/plotting.py -> build/lib/lightgbm\n",
      "  \u001b[31m   \u001b[0m INFO:root:copying lightgbm/__init__.py -> build/lib/lightgbm\n",
      "  \u001b[31m   \u001b[0m INFO:root:copying lightgbm/engine.py -> build/lib/lightgbm\n",
      "  \u001b[31m   \u001b[0m INFO:root:copying lightgbm/dask.py -> build/lib/lightgbm\n",
      "  \u001b[31m   \u001b[0m INFO:root:copying lightgbm/basic.py -> build/lib/lightgbm\n",
      "  \u001b[31m   \u001b[0m INFO:root:copying lightgbm/libpath.py -> build/lib/lightgbm\n",
      "  \u001b[31m   \u001b[0m INFO:root:copying lightgbm/sklearn.py -> build/lib/lightgbm\n",
      "  \u001b[31m   \u001b[0m INFO:root:running egg_info\n",
      "  \u001b[31m   \u001b[0m INFO:root:writing lightgbm.egg-info/PKG-INFO\n",
      "  \u001b[31m   \u001b[0m INFO:root:writing dependency_links to lightgbm.egg-info/dependency_links.txt\n",
      "  \u001b[31m   \u001b[0m INFO:root:writing requirements to lightgbm.egg-info/requires.txt\n",
      "  \u001b[31m   \u001b[0m INFO:root:writing top-level names to lightgbm.egg-info/top_level.txt\n",
      "  \u001b[31m   \u001b[0m INFO:root:reading manifest file 'lightgbm.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m INFO:root:reading manifest template 'MANIFEST.in'\n",
      "  \u001b[31m   \u001b[0m WARNING:root:no previously-included directories found matching 'build'\n",
      "  \u001b[31m   \u001b[0m WARNING:root:warning: no files found matching '*.so' under directory 'lightgbm'\n",
      "  \u001b[31m   \u001b[0m WARNING:root:warning: no files found matching '*.so' under directory 'compile'\n",
      "  \u001b[31m   \u001b[0m WARNING:root:warning: no files found matching '*.dll' under directory 'compile/Release'\n",
      "  \u001b[31m   \u001b[0m WARNING:root:warning: no files found matching '*.dll' under directory 'compile/windows/x64/DLL'\n",
      "  \u001b[31m   \u001b[0m WARNING:root:warning: no previously-included files matching '*.py[co]' found anywhere in distribution\n",
      "  \u001b[31m   \u001b[0m WARNING:root:warning: no previously-included files found matching 'compile/external_libs/compute/.git'\n",
      "  \u001b[31m   \u001b[0m INFO:root:adding license file 'LICENSE'\n",
      "  \u001b[31m   \u001b[0m INFO:root:writing manifest file 'lightgbm.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m INFO:root:copying lightgbm/VERSION.txt -> build/lib/lightgbm\n",
      "  \u001b[31m   \u001b[0m INFO:wheel:installing to build/bdist.macosx-11.1-arm64/wheel\n",
      "  \u001b[31m   \u001b[0m INFO:root:running install\n",
      "  \u001b[31m   \u001b[0m INFO:LightGBM:Starting to compile the library.\n",
      "  \u001b[31m   \u001b[0m INFO:LightGBM:Starting to compile with CMake.\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/1r/xjj371_x7v7cjx48l_txs48c0000gn/T/pip-install-ekjo9mua/lightgbm_8a027b0cb4734ea7bf3b1c4507302e82/setup.py\", line 95, in silent_call\n",
      "  \u001b[31m   \u001b[0m     subprocess.check_call(cmd, stderr=log, stdout=log)\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/jieun/anaconda3/lib/python3.11/subprocess.py\", line 408, in check_call\n",
      "  \u001b[31m   \u001b[0m     retcode = call(*popenargs, **kwargs)\n",
      "  \u001b[31m   \u001b[0m               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/jieun/anaconda3/lib/python3.11/subprocess.py\", line 389, in call\n",
      "  \u001b[31m   \u001b[0m     with Popen(*popenargs, **kwargs) as p:\n",
      "  \u001b[31m   \u001b[0m          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/jieun/anaconda3/lib/python3.11/subprocess.py\", line 1026, in __init__\n",
      "  \u001b[31m   \u001b[0m     self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/jieun/anaconda3/lib/python3.11/subprocess.py\", line 1950, in _execute_child\n",
      "  \u001b[31m   \u001b[0m     raise child_exception_type(errno_num, err_msg, err_filename)\n",
      "  \u001b[31m   \u001b[0m FileNotFoundError: [Errno 2] No such file or directory: 'cmake'\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m During handling of the above exception, another exception occurred:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/1r/xjj371_x7v7cjx48l_txs48c0000gn/T/pip-install-ekjo9mua/lightgbm_8a027b0cb4734ea7bf3b1c4507302e82/setup.py\", line 334, in <module>\n",
      "  \u001b[31m   \u001b[0m     setup(name='lightgbm',\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/jieun/anaconda3/lib/python3.11/site-packages/setuptools/__init__.py\", line 107, in setup\n",
      "  \u001b[31m   \u001b[0m     return distutils.core.setup(**attrs)\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/jieun/anaconda3/lib/python3.11/site-packages/setuptools/_distutils/core.py\", line 185, in setup\n",
      "  \u001b[31m   \u001b[0m     return run_commands(dist)\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/jieun/anaconda3/lib/python3.11/site-packages/setuptools/_distutils/core.py\", line 201, in run_commands\n",
      "  \u001b[31m   \u001b[0m     dist.run_commands()\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/jieun/anaconda3/lib/python3.11/site-packages/setuptools/_distutils/dist.py\", line 969, in run_commands\n",
      "  \u001b[31m   \u001b[0m     self.run_command(cmd)\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/jieun/anaconda3/lib/python3.11/site-packages/setuptools/dist.py\", line 1234, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/jieun/anaconda3/lib/python3.11/site-packages/setuptools/_distutils/dist.py\", line 988, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/jieun/anaconda3/lib/python3.11/site-packages/wheel/bdist_wheel.py\", line 360, in run\n",
      "  \u001b[31m   \u001b[0m     self.run_command(\"install\")\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/jieun/anaconda3/lib/python3.11/site-packages/setuptools/_distutils/cmd.py\", line 318, in run_command\n",
      "  \u001b[31m   \u001b[0m     self.distribution.run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/jieun/anaconda3/lib/python3.11/site-packages/setuptools/dist.py\", line 1234, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/jieun/anaconda3/lib/python3.11/site-packages/setuptools/_distutils/dist.py\", line 988, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/1r/xjj371_x7v7cjx48l_txs48c0000gn/T/pip-install-ekjo9mua/lightgbm_8a027b0cb4734ea7bf3b1c4507302e82/setup.py\", line 248, in run\n",
      "  \u001b[31m   \u001b[0m     compile_cpp(use_mingw=self.mingw, use_gpu=self.gpu, use_cuda=self.cuda, use_mpi=self.mpi,\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/1r/xjj371_x7v7cjx48l_txs48c0000gn/T/pip-install-ekjo9mua/lightgbm_8a027b0cb4734ea7bf3b1c4507302e82/setup.py\", line 198, in compile_cpp\n",
      "  \u001b[31m   \u001b[0m     silent_call(cmake_cmd, raise_error=True, error_msg='Please install CMake and all required dependencies first')\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/1r/xjj371_x7v7cjx48l_txs48c0000gn/T/pip-install-ekjo9mua/lightgbm_8a027b0cb4734ea7bf3b1c4507302e82/setup.py\", line 99, in silent_call\n",
      "  \u001b[31m   \u001b[0m     raise Exception(\"\\n\".join((error_msg, LOG_NOTICE)))\n",
      "  \u001b[31m   \u001b[0m Exception: Please install CMake and all required dependencies first\n",
      "  \u001b[31m   \u001b[0m The full version of error log was saved into /Users/jieun/LightGBM_compilation.log\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for lightgbm\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for lightgbm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to build lightgbm\r\n",
      "\u001b[31mERROR: Could not build wheels for lightgbm, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'lightgbm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 3.3.2 버전으로 LightGBM을 설치합니다(일부 파라미터가 4.0.0에선 작동하지 않아서 넣었습니다.)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install lightgbm==3.3.2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(lightgbm\u001b[38;5;241m.\u001b[39m__version__)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lightgbm' is not defined"
     ]
    }
   ],
   "source": [
    "# 3.3.2 버전으로 LightGBM을 설치합니다(일부 파라미터가 4.0.0에선 작동하지 않아서 넣었습니다.)\n",
    "\n",
    "!pip install lightgbm==3.3.2\n",
    "print(lightgbm.__version__) # 버전 확인용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ZcpuDJ8GIoBD"
   },
   "outputs": [],
   "source": [
    "import lightgbm\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "z3XVGeXr-_kt"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ph</th>\n",
       "      <th>Hardness</th>\n",
       "      <th>Solids</th>\n",
       "      <th>Chloramines</th>\n",
       "      <th>Sulfate</th>\n",
       "      <th>Conductivity</th>\n",
       "      <th>Organic_carbon</th>\n",
       "      <th>Trihalomethanes</th>\n",
       "      <th>Turbidity</th>\n",
       "      <th>Potability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>204.890455</td>\n",
       "      <td>20791.318981</td>\n",
       "      <td>7.300212</td>\n",
       "      <td>368.516441</td>\n",
       "      <td>564.308654</td>\n",
       "      <td>10.379783</td>\n",
       "      <td>86.990970</td>\n",
       "      <td>2.963135</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.716080</td>\n",
       "      <td>129.422921</td>\n",
       "      <td>18630.057858</td>\n",
       "      <td>6.635246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>592.885359</td>\n",
       "      <td>15.180013</td>\n",
       "      <td>56.329076</td>\n",
       "      <td>4.500656</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.099124</td>\n",
       "      <td>224.236259</td>\n",
       "      <td>19909.541732</td>\n",
       "      <td>9.275884</td>\n",
       "      <td>NaN</td>\n",
       "      <td>418.606213</td>\n",
       "      <td>16.868637</td>\n",
       "      <td>66.420093</td>\n",
       "      <td>3.055934</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.316766</td>\n",
       "      <td>214.373394</td>\n",
       "      <td>22018.417441</td>\n",
       "      <td>8.059332</td>\n",
       "      <td>356.886136</td>\n",
       "      <td>363.266516</td>\n",
       "      <td>18.436524</td>\n",
       "      <td>100.341674</td>\n",
       "      <td>4.628771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.092223</td>\n",
       "      <td>181.101509</td>\n",
       "      <td>17978.986339</td>\n",
       "      <td>6.546600</td>\n",
       "      <td>310.135738</td>\n",
       "      <td>398.410813</td>\n",
       "      <td>11.558279</td>\n",
       "      <td>31.997993</td>\n",
       "      <td>4.075075</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ph    Hardness        Solids  Chloramines     Sulfate  Conductivity  \\\n",
       "0       NaN  204.890455  20791.318981     7.300212  368.516441    564.308654   \n",
       "1  3.716080  129.422921  18630.057858     6.635246         NaN    592.885359   \n",
       "2  8.099124  224.236259  19909.541732     9.275884         NaN    418.606213   \n",
       "3  8.316766  214.373394  22018.417441     8.059332  356.886136    363.266516   \n",
       "4  9.092223  181.101509  17978.986339     6.546600  310.135738    398.410813   \n",
       "\n",
       "   Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
       "0       10.379783        86.990970   2.963135           0  \n",
       "1       15.180013        56.329076   4.500656           0  \n",
       "2       16.868637        66.420093   3.055934           0  \n",
       "3       18.436524       100.341674   4.628771           0  \n",
       "4       11.558279        31.997993   4.075075           0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./water_potability.csv')\n",
    "\n",
    "# 데이터 확인\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cXSVbYeI_DGz"
   },
   "source": [
    "### **3-1-b. 이럴수가! 결측값이 있는 것 같네요! 아래의 코드를 실행시켜 어느 변수에 결측값이 있는지 확인하고, 결측값들은 모두 해당하는 변수의 평균으로 바꿔주세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "r4nKg2mF_FHE"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ph                 491\n",
       "Hardness             0\n",
       "Solids               0\n",
       "Chloramines          0\n",
       "Sulfate            781\n",
       "Conductivity         0\n",
       "Organic_carbon       0\n",
       "Trihalomethanes    162\n",
       "Turbidity            0\n",
       "Potability           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "I3Iq_aHA_XUi"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ph</th>\n",
       "      <th>Hardness</th>\n",
       "      <th>Solids</th>\n",
       "      <th>Chloramines</th>\n",
       "      <th>Sulfate</th>\n",
       "      <th>Conductivity</th>\n",
       "      <th>Organic_carbon</th>\n",
       "      <th>Trihalomethanes</th>\n",
       "      <th>Turbidity</th>\n",
       "      <th>Potability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.080795</td>\n",
       "      <td>204.890455</td>\n",
       "      <td>20791.318981</td>\n",
       "      <td>7.300212</td>\n",
       "      <td>368.516441</td>\n",
       "      <td>564.308654</td>\n",
       "      <td>10.379783</td>\n",
       "      <td>86.990970</td>\n",
       "      <td>2.963135</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.716080</td>\n",
       "      <td>129.422921</td>\n",
       "      <td>18630.057858</td>\n",
       "      <td>6.635246</td>\n",
       "      <td>333.775777</td>\n",
       "      <td>592.885359</td>\n",
       "      <td>15.180013</td>\n",
       "      <td>56.329076</td>\n",
       "      <td>4.500656</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.099124</td>\n",
       "      <td>224.236259</td>\n",
       "      <td>19909.541732</td>\n",
       "      <td>9.275884</td>\n",
       "      <td>333.775777</td>\n",
       "      <td>418.606213</td>\n",
       "      <td>16.868637</td>\n",
       "      <td>66.420093</td>\n",
       "      <td>3.055934</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.316766</td>\n",
       "      <td>214.373394</td>\n",
       "      <td>22018.417441</td>\n",
       "      <td>8.059332</td>\n",
       "      <td>356.886136</td>\n",
       "      <td>363.266516</td>\n",
       "      <td>18.436524</td>\n",
       "      <td>100.341674</td>\n",
       "      <td>4.628771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.092223</td>\n",
       "      <td>181.101509</td>\n",
       "      <td>17978.986339</td>\n",
       "      <td>6.546600</td>\n",
       "      <td>310.135738</td>\n",
       "      <td>398.410813</td>\n",
       "      <td>11.558279</td>\n",
       "      <td>31.997993</td>\n",
       "      <td>4.075075</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ph    Hardness        Solids  Chloramines     Sulfate  Conductivity  \\\n",
       "0  7.080795  204.890455  20791.318981     7.300212  368.516441    564.308654   \n",
       "1  3.716080  129.422921  18630.057858     6.635246  333.775777    592.885359   \n",
       "2  8.099124  224.236259  19909.541732     9.275884  333.775777    418.606213   \n",
       "3  8.316766  214.373394  22018.417441     8.059332  356.886136    363.266516   \n",
       "4  9.092223  181.101509  17978.986339     6.546600  310.135738    398.410813   \n",
       "\n",
       "   Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
       "0       10.379783        86.990970   2.963135           0  \n",
       "1       15.180013        56.329076   4.500656           0  \n",
       "2       16.868637        66.420093   3.055934           0  \n",
       "3       18.436524       100.341674   4.628771           0  \n",
       "4       11.558279        31.997993   4.075075           0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 결측값을 해당 칼럼의 평균값으로 대체해 주세요.\n",
    "# 힌트: 파머완 138페이지\n",
    "def fillna(df):\n",
    "    df['ph'].fillna(df['ph'].mean(), inplace=True)\n",
    "    df['Sulfate'].fillna(df['Sulfate'].mean(), inplace=True)\n",
    "    df['Trihalomethanes'].fillna(df['Trihalomethanes'].mean(), inplace=True)\n",
    "    return df\n",
    "df = fillna(df)\n",
    "# 데이터 확인\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OyXaOw0X_aXZ"
   },
   "source": [
    "### **3-1-c. df를 학습용 데이터와 테스트용 데이터로 분리해 주세요.**  \n",
    "(random_state = 42, 학습용 데이터가 전체의 **80%**를 차지하도록 설정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "oWbfGB4c_Znx"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hW1x8hQI_krM"
   },
   "source": [
    "### **3-1-d. 위에서 만든 X_train, y_train을 다시 나누어 90%는 학습용으로, 10%는 검증용 데이터로 분리해 주세요.**  \n",
    "(random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "QPuPw7bb_qF8"
   },
   "outputs": [],
   "source": [
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hEyCPkHZ_tYC"
   },
   "source": [
    "### **3-1-e. 다음 조건에 따라 LGBMClassifier을 생성한 후 ```lgbm_wrapper```에 저장해 주세요.**\n",
    "- 반복 수행할 트리 개수: 800개\n",
    "- 학습률: 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "4gPkmQo3_zlS"
   },
   "outputs": [],
   "source": [
    "lgbm_wrapper = LGBMClassifier(n_estimators=800, learning_rate=0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "unGn5aOi_2LG"
   },
   "source": [
    "### **3-1-f. `lgbm_wrapper`가 100번 학습을 반복해도 성능이 향상되지 않으면 수행을 멈추도록 설정해서 학습시키세요.**\n",
    "- 평가 지표: logloss  \n",
    "\n",
    "(❓❓❓❓❓로 표시된 빈칸을 채워주세요!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "89l5qcaB_6QV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.667547\tvalid_1's binary_logloss: 0.664685\n",
      "[2]\ttraining's binary_logloss: 0.664047\tvalid_1's binary_logloss: 0.662495\n",
      "[3]\ttraining's binary_logloss: 0.660692\tvalid_1's binary_logloss: 0.660532\n",
      "[4]\ttraining's binary_logloss: 0.657277\tvalid_1's binary_logloss: 0.658939\n",
      "[5]\ttraining's binary_logloss: 0.65419\tvalid_1's binary_logloss: 0.657061\n",
      "[6]\ttraining's binary_logloss: 0.651193\tvalid_1's binary_logloss: 0.65562\n",
      "[7]\ttraining's binary_logloss: 0.648042\tvalid_1's binary_logloss: 0.65442\n",
      "[8]\ttraining's binary_logloss: 0.645251\tvalid_1's binary_logloss: 0.65276\n",
      "[9]\ttraining's binary_logloss: 0.642221\tvalid_1's binary_logloss: 0.651453\n",
      "[10]\ttraining's binary_logloss: 0.63971\tvalid_1's binary_logloss: 0.649738\n",
      "[11]\ttraining's binary_logloss: 0.637098\tvalid_1's binary_logloss: 0.648505\n",
      "[12]\ttraining's binary_logloss: 0.634355\tvalid_1's binary_logloss: 0.647447\n",
      "[13]\ttraining's binary_logloss: 0.631831\tvalid_1's binary_logloss: 0.6465\n",
      "[14]\ttraining's binary_logloss: 0.629512\tvalid_1's binary_logloss: 0.645076\n",
      "[15]\ttraining's binary_logloss: 0.627136\tvalid_1's binary_logloss: 0.644241\n",
      "[16]\ttraining's binary_logloss: 0.624549\tvalid_1's binary_logloss: 0.642928\n",
      "[17]\ttraining's binary_logloss: 0.622566\tvalid_1's binary_logloss: 0.641793\n",
      "[18]\ttraining's binary_logloss: 0.620011\tvalid_1's binary_logloss: 0.640239\n",
      "[19]\ttraining's binary_logloss: 0.617778\tvalid_1's binary_logloss: 0.639463\n",
      "[20]\ttraining's binary_logloss: 0.615404\tvalid_1's binary_logloss: 0.638609\n",
      "[21]\ttraining's binary_logloss: 0.613173\tvalid_1's binary_logloss: 0.637227\n",
      "[22]\ttraining's binary_logloss: 0.611319\tvalid_1's binary_logloss: 0.63608\n",
      "[23]\ttraining's binary_logloss: 0.609269\tvalid_1's binary_logloss: 0.635334\n",
      "[24]\ttraining's binary_logloss: 0.607131\tvalid_1's binary_logloss: 0.634674\n",
      "[25]\ttraining's binary_logloss: 0.604981\tvalid_1's binary_logloss: 0.633856\n",
      "[26]\ttraining's binary_logloss: 0.602973\tvalid_1's binary_logloss: 0.633035\n",
      "[27]\ttraining's binary_logloss: 0.600891\tvalid_1's binary_logloss: 0.632326\n",
      "[28]\ttraining's binary_logloss: 0.598837\tvalid_1's binary_logloss: 0.631523\n",
      "[29]\ttraining's binary_logloss: 0.597021\tvalid_1's binary_logloss: 0.630514\n",
      "[30]\ttraining's binary_logloss: 0.595074\tvalid_1's binary_logloss: 0.629968\n",
      "[31]\ttraining's binary_logloss: 0.593365\tvalid_1's binary_logloss: 0.629077\n",
      "[32]\ttraining's binary_logloss: 0.591409\tvalid_1's binary_logloss: 0.628504\n",
      "[33]\ttraining's binary_logloss: 0.589704\tvalid_1's binary_logloss: 0.627899\n",
      "[34]\ttraining's binary_logloss: 0.587997\tvalid_1's binary_logloss: 0.627062\n",
      "[35]\ttraining's binary_logloss: 0.586386\tvalid_1's binary_logloss: 0.626465\n",
      "[36]\ttraining's binary_logloss: 0.584785\tvalid_1's binary_logloss: 0.625355\n",
      "[37]\ttraining's binary_logloss: 0.582981\tvalid_1's binary_logloss: 0.624617\n",
      "[38]\ttraining's binary_logloss: 0.581404\tvalid_1's binary_logloss: 0.624309\n",
      "[39]\ttraining's binary_logloss: 0.579584\tvalid_1's binary_logloss: 0.623495\n",
      "[40]\ttraining's binary_logloss: 0.57818\tvalid_1's binary_logloss: 0.623059\n",
      "[41]\ttraining's binary_logloss: 0.576512\tvalid_1's binary_logloss: 0.622334\n",
      "[42]\ttraining's binary_logloss: 0.574888\tvalid_1's binary_logloss: 0.621196\n",
      "[43]\ttraining's binary_logloss: 0.573249\tvalid_1's binary_logloss: 0.619868\n",
      "[44]\ttraining's binary_logloss: 0.57189\tvalid_1's binary_logloss: 0.619827\n",
      "[45]\ttraining's binary_logloss: 0.570241\tvalid_1's binary_logloss: 0.619596\n",
      "[46]\ttraining's binary_logloss: 0.568716\tvalid_1's binary_logloss: 0.619083\n",
      "[47]\ttraining's binary_logloss: 0.5673\tvalid_1's binary_logloss: 0.619142\n",
      "[48]\ttraining's binary_logloss: 0.565919\tvalid_1's binary_logloss: 0.618903\n",
      "[49]\ttraining's binary_logloss: 0.564496\tvalid_1's binary_logloss: 0.618536\n",
      "[50]\ttraining's binary_logloss: 0.562884\tvalid_1's binary_logloss: 0.618233\n",
      "[51]\ttraining's binary_logloss: 0.561515\tvalid_1's binary_logloss: 0.618077\n",
      "[52]\ttraining's binary_logloss: 0.560285\tvalid_1's binary_logloss: 0.618009\n",
      "[53]\ttraining's binary_logloss: 0.558754\tvalid_1's binary_logloss: 0.617756\n",
      "[54]\ttraining's binary_logloss: 0.557339\tvalid_1's binary_logloss: 0.617285\n",
      "[55]\ttraining's binary_logloss: 0.556088\tvalid_1's binary_logloss: 0.61718\n",
      "[56]\ttraining's binary_logloss: 0.554629\tvalid_1's binary_logloss: 0.616633\n",
      "[57]\ttraining's binary_logloss: 0.553365\tvalid_1's binary_logloss: 0.616256\n",
      "[58]\ttraining's binary_logloss: 0.552168\tvalid_1's binary_logloss: 0.615741\n",
      "[59]\ttraining's binary_logloss: 0.550464\tvalid_1's binary_logloss: 0.61504\n",
      "[60]\ttraining's binary_logloss: 0.549265\tvalid_1's binary_logloss: 0.615171\n",
      "[61]\ttraining's binary_logloss: 0.548038\tvalid_1's binary_logloss: 0.614906\n",
      "[62]\ttraining's binary_logloss: 0.546864\tvalid_1's binary_logloss: 0.615046\n",
      "[63]\ttraining's binary_logloss: 0.545476\tvalid_1's binary_logloss: 0.615044\n",
      "[64]\ttraining's binary_logloss: 0.544288\tvalid_1's binary_logloss: 0.615147\n",
      "[65]\ttraining's binary_logloss: 0.542654\tvalid_1's binary_logloss: 0.614795\n",
      "[66]\ttraining's binary_logloss: 0.54164\tvalid_1's binary_logloss: 0.614296\n",
      "[67]\ttraining's binary_logloss: 0.540516\tvalid_1's binary_logloss: 0.614464\n",
      "[68]\ttraining's binary_logloss: 0.538924\tvalid_1's binary_logloss: 0.614556\n",
      "[69]\ttraining's binary_logloss: 0.537522\tvalid_1's binary_logloss: 0.614134\n",
      "[70]\ttraining's binary_logloss: 0.536069\tvalid_1's binary_logloss: 0.613612\n",
      "[71]\ttraining's binary_logloss: 0.534842\tvalid_1's binary_logloss: 0.613207\n",
      "[72]\ttraining's binary_logloss: 0.533493\tvalid_1's binary_logloss: 0.612727\n",
      "[73]\ttraining's binary_logloss: 0.532093\tvalid_1's binary_logloss: 0.61206\n",
      "[74]\ttraining's binary_logloss: 0.530997\tvalid_1's binary_logloss: 0.611842\n",
      "[75]\ttraining's binary_logloss: 0.529792\tvalid_1's binary_logloss: 0.611458\n",
      "[76]\ttraining's binary_logloss: 0.528547\tvalid_1's binary_logloss: 0.611183\n",
      "[77]\ttraining's binary_logloss: 0.52721\tvalid_1's binary_logloss: 0.610372\n",
      "[78]\ttraining's binary_logloss: 0.526187\tvalid_1's binary_logloss: 0.610703\n",
      "[79]\ttraining's binary_logloss: 0.524654\tvalid_1's binary_logloss: 0.610464\n",
      "[80]\ttraining's binary_logloss: 0.523712\tvalid_1's binary_logloss: 0.610687\n",
      "[81]\ttraining's binary_logloss: 0.522468\tvalid_1's binary_logloss: 0.610206\n",
      "[82]\ttraining's binary_logloss: 0.521323\tvalid_1's binary_logloss: 0.60944\n",
      "[83]\ttraining's binary_logloss: 0.520141\tvalid_1's binary_logloss: 0.609356\n",
      "[84]\ttraining's binary_logloss: 0.519102\tvalid_1's binary_logloss: 0.608809\n",
      "[85]\ttraining's binary_logloss: 0.517993\tvalid_1's binary_logloss: 0.608626\n",
      "[86]\ttraining's binary_logloss: 0.516937\tvalid_1's binary_logloss: 0.608656\n",
      "[87]\ttraining's binary_logloss: 0.515772\tvalid_1's binary_logloss: 0.608443\n",
      "[88]\ttraining's binary_logloss: 0.514632\tvalid_1's binary_logloss: 0.608518\n",
      "[89]\ttraining's binary_logloss: 0.513572\tvalid_1's binary_logloss: 0.608283\n",
      "[90]\ttraining's binary_logloss: 0.51251\tvalid_1's binary_logloss: 0.608352\n",
      "[91]\ttraining's binary_logloss: 0.511467\tvalid_1's binary_logloss: 0.608149\n",
      "[92]\ttraining's binary_logloss: 0.510382\tvalid_1's binary_logloss: 0.607771\n",
      "[93]\ttraining's binary_logloss: 0.508859\tvalid_1's binary_logloss: 0.607334\n",
      "[94]\ttraining's binary_logloss: 0.507781\tvalid_1's binary_logloss: 0.607239\n",
      "[95]\ttraining's binary_logloss: 0.506705\tvalid_1's binary_logloss: 0.606651\n",
      "[96]\ttraining's binary_logloss: 0.505648\tvalid_1's binary_logloss: 0.606788\n",
      "[97]\ttraining's binary_logloss: 0.504399\tvalid_1's binary_logloss: 0.607109\n",
      "[98]\ttraining's binary_logloss: 0.503404\tvalid_1's binary_logloss: 0.607263\n",
      "[99]\ttraining's binary_logloss: 0.501983\tvalid_1's binary_logloss: 0.607194\n",
      "[100]\ttraining's binary_logloss: 0.50099\tvalid_1's binary_logloss: 0.607282\n",
      "[101]\ttraining's binary_logloss: 0.499824\tvalid_1's binary_logloss: 0.607247\n",
      "[102]\ttraining's binary_logloss: 0.498856\tvalid_1's binary_logloss: 0.60742\n",
      "[103]\ttraining's binary_logloss: 0.497442\tvalid_1's binary_logloss: 0.607316\n",
      "[104]\ttraining's binary_logloss: 0.496373\tvalid_1's binary_logloss: 0.60732\n",
      "[105]\ttraining's binary_logloss: 0.495097\tvalid_1's binary_logloss: 0.607256\n",
      "[106]\ttraining's binary_logloss: 0.493956\tvalid_1's binary_logloss: 0.606972\n",
      "[107]\ttraining's binary_logloss: 0.492786\tvalid_1's binary_logloss: 0.607018\n",
      "[108]\ttraining's binary_logloss: 0.49182\tvalid_1's binary_logloss: 0.606827\n",
      "[109]\ttraining's binary_logloss: 0.490963\tvalid_1's binary_logloss: 0.606737\n",
      "[110]\ttraining's binary_logloss: 0.489966\tvalid_1's binary_logloss: 0.606608\n",
      "[111]\ttraining's binary_logloss: 0.489148\tvalid_1's binary_logloss: 0.606561\n",
      "[112]\ttraining's binary_logloss: 0.488277\tvalid_1's binary_logloss: 0.606796\n",
      "[113]\ttraining's binary_logloss: 0.487368\tvalid_1's binary_logloss: 0.606787\n",
      "[114]\ttraining's binary_logloss: 0.486279\tvalid_1's binary_logloss: 0.606649\n",
      "[115]\ttraining's binary_logloss: 0.485349\tvalid_1's binary_logloss: 0.606573\n",
      "[116]\ttraining's binary_logloss: 0.484404\tvalid_1's binary_logloss: 0.606804\n",
      "[117]\ttraining's binary_logloss: 0.483562\tvalid_1's binary_logloss: 0.606487\n",
      "[118]\ttraining's binary_logloss: 0.482428\tvalid_1's binary_logloss: 0.606461\n",
      "[119]\ttraining's binary_logloss: 0.481512\tvalid_1's binary_logloss: 0.606384\n",
      "[120]\ttraining's binary_logloss: 0.480715\tvalid_1's binary_logloss: 0.60617\n",
      "[121]\ttraining's binary_logloss: 0.479965\tvalid_1's binary_logloss: 0.606376\n",
      "[122]\ttraining's binary_logloss: 0.479068\tvalid_1's binary_logloss: 0.606733\n",
      "[123]\ttraining's binary_logloss: 0.477955\tvalid_1's binary_logloss: 0.606621\n",
      "[124]\ttraining's binary_logloss: 0.476929\tvalid_1's binary_logloss: 0.605802\n",
      "[125]\ttraining's binary_logloss: 0.475845\tvalid_1's binary_logloss: 0.605189\n",
      "[126]\ttraining's binary_logloss: 0.474794\tvalid_1's binary_logloss: 0.60524\n",
      "[127]\ttraining's binary_logloss: 0.473823\tvalid_1's binary_logloss: 0.604651\n",
      "[128]\ttraining's binary_logloss: 0.473117\tvalid_1's binary_logloss: 0.604408\n",
      "[129]\ttraining's binary_logloss: 0.472245\tvalid_1's binary_logloss: 0.60428\n",
      "[130]\ttraining's binary_logloss: 0.471411\tvalid_1's binary_logloss: 0.604563\n",
      "[131]\ttraining's binary_logloss: 0.470444\tvalid_1's binary_logloss: 0.604498\n",
      "[132]\ttraining's binary_logloss: 0.4696\tvalid_1's binary_logloss: 0.60433\n",
      "[133]\ttraining's binary_logloss: 0.468737\tvalid_1's binary_logloss: 0.604457\n",
      "[134]\ttraining's binary_logloss: 0.467882\tvalid_1's binary_logloss: 0.604643\n",
      "[135]\ttraining's binary_logloss: 0.467074\tvalid_1's binary_logloss: 0.60459\n",
      "[136]\ttraining's binary_logloss: 0.465983\tvalid_1's binary_logloss: 0.6041\n",
      "[137]\ttraining's binary_logloss: 0.465135\tvalid_1's binary_logloss: 0.603884\n",
      "[138]\ttraining's binary_logloss: 0.464335\tvalid_1's binary_logloss: 0.603975\n",
      "[139]\ttraining's binary_logloss: 0.463289\tvalid_1's binary_logloss: 0.603518\n",
      "[140]\ttraining's binary_logloss: 0.462394\tvalid_1's binary_logloss: 0.603927\n",
      "[141]\ttraining's binary_logloss: 0.461579\tvalid_1's binary_logloss: 0.603516\n",
      "[142]\ttraining's binary_logloss: 0.460654\tvalid_1's binary_logloss: 0.603582\n",
      "[143]\ttraining's binary_logloss: 0.45975\tvalid_1's binary_logloss: 0.603672\n",
      "[144]\ttraining's binary_logloss: 0.458865\tvalid_1's binary_logloss: 0.603851\n",
      "[145]\ttraining's binary_logloss: 0.457908\tvalid_1's binary_logloss: 0.603774\n",
      "[146]\ttraining's binary_logloss: 0.45706\tvalid_1's binary_logloss: 0.603484\n",
      "[147]\ttraining's binary_logloss: 0.456221\tvalid_1's binary_logloss: 0.60365\n",
      "[148]\ttraining's binary_logloss: 0.455435\tvalid_1's binary_logloss: 0.603882\n",
      "[149]\ttraining's binary_logloss: 0.454648\tvalid_1's binary_logloss: 0.60381\n",
      "[150]\ttraining's binary_logloss: 0.453867\tvalid_1's binary_logloss: 0.603974\n",
      "[151]\ttraining's binary_logloss: 0.45304\tvalid_1's binary_logloss: 0.603606\n",
      "[152]\ttraining's binary_logloss: 0.452142\tvalid_1's binary_logloss: 0.603745\n",
      "[153]\ttraining's binary_logloss: 0.451329\tvalid_1's binary_logloss: 0.603914\n",
      "[154]\ttraining's binary_logloss: 0.450524\tvalid_1's binary_logloss: 0.603933\n",
      "[155]\ttraining's binary_logloss: 0.449743\tvalid_1's binary_logloss: 0.604349\n",
      "[156]\ttraining's binary_logloss: 0.448834\tvalid_1's binary_logloss: 0.604694\n",
      "[157]\ttraining's binary_logloss: 0.448032\tvalid_1's binary_logloss: 0.60476\n",
      "[158]\ttraining's binary_logloss: 0.447105\tvalid_1's binary_logloss: 0.604317\n",
      "[159]\ttraining's binary_logloss: 0.446176\tvalid_1's binary_logloss: 0.604407\n",
      "[160]\ttraining's binary_logloss: 0.445418\tvalid_1's binary_logloss: 0.604685\n",
      "[161]\ttraining's binary_logloss: 0.444712\tvalid_1's binary_logloss: 0.604758\n",
      "[162]\ttraining's binary_logloss: 0.443915\tvalid_1's binary_logloss: 0.604907\n",
      "[163]\ttraining's binary_logloss: 0.443093\tvalid_1's binary_logloss: 0.605203\n",
      "[164]\ttraining's binary_logloss: 0.442318\tvalid_1's binary_logloss: 0.605045\n",
      "[165]\ttraining's binary_logloss: 0.441326\tvalid_1's binary_logloss: 0.605121\n",
      "[166]\ttraining's binary_logloss: 0.440627\tvalid_1's binary_logloss: 0.604886\n",
      "[167]\ttraining's binary_logloss: 0.43984\tvalid_1's binary_logloss: 0.604574\n",
      "[168]\ttraining's binary_logloss: 0.439218\tvalid_1's binary_logloss: 0.604623\n",
      "[169]\ttraining's binary_logloss: 0.43844\tvalid_1's binary_logloss: 0.604389\n",
      "[170]\ttraining's binary_logloss: 0.437732\tvalid_1's binary_logloss: 0.604601\n",
      "[171]\ttraining's binary_logloss: 0.436889\tvalid_1's binary_logloss: 0.604902\n",
      "[172]\ttraining's binary_logloss: 0.436101\tvalid_1's binary_logloss: 0.605497\n",
      "[173]\ttraining's binary_logloss: 0.435415\tvalid_1's binary_logloss: 0.605354\n",
      "[174]\ttraining's binary_logloss: 0.434636\tvalid_1's binary_logloss: 0.605431\n",
      "[175]\ttraining's binary_logloss: 0.433818\tvalid_1's binary_logloss: 0.605277\n",
      "[176]\ttraining's binary_logloss: 0.433069\tvalid_1's binary_logloss: 0.605222\n",
      "[177]\ttraining's binary_logloss: 0.432374\tvalid_1's binary_logloss: 0.605233\n",
      "[178]\ttraining's binary_logloss: 0.43162\tvalid_1's binary_logloss: 0.605042\n",
      "[179]\ttraining's binary_logloss: 0.43085\tvalid_1's binary_logloss: 0.605577\n",
      "[180]\ttraining's binary_logloss: 0.430095\tvalid_1's binary_logloss: 0.605771\n",
      "[181]\ttraining's binary_logloss: 0.429368\tvalid_1's binary_logloss: 0.606193\n",
      "[182]\ttraining's binary_logloss: 0.42862\tvalid_1's binary_logloss: 0.606251\n",
      "[183]\ttraining's binary_logloss: 0.427908\tvalid_1's binary_logloss: 0.606214\n",
      "[184]\ttraining's binary_logloss: 0.427279\tvalid_1's binary_logloss: 0.606474\n",
      "[185]\ttraining's binary_logloss: 0.42653\tvalid_1's binary_logloss: 0.6069\n",
      "[186]\ttraining's binary_logloss: 0.425813\tvalid_1's binary_logloss: 0.607007\n",
      "[187]\ttraining's binary_logloss: 0.425155\tvalid_1's binary_logloss: 0.607044\n",
      "[188]\ttraining's binary_logloss: 0.42445\tvalid_1's binary_logloss: 0.60725\n",
      "[189]\ttraining's binary_logloss: 0.423672\tvalid_1's binary_logloss: 0.607054\n",
      "[190]\ttraining's binary_logloss: 0.422997\tvalid_1's binary_logloss: 0.607556\n",
      "[191]\ttraining's binary_logloss: 0.422177\tvalid_1's binary_logloss: 0.607929\n",
      "[192]\ttraining's binary_logloss: 0.421462\tvalid_1's binary_logloss: 0.60826\n",
      "[193]\ttraining's binary_logloss: 0.420824\tvalid_1's binary_logloss: 0.608331\n",
      "[194]\ttraining's binary_logloss: 0.420159\tvalid_1's binary_logloss: 0.608811\n",
      "[195]\ttraining's binary_logloss: 0.419371\tvalid_1's binary_logloss: 0.60826\n",
      "[196]\ttraining's binary_logloss: 0.418572\tvalid_1's binary_logloss: 0.608784\n",
      "[197]\ttraining's binary_logloss: 0.417891\tvalid_1's binary_logloss: 0.608964\n",
      "[198]\ttraining's binary_logloss: 0.41717\tvalid_1's binary_logloss: 0.60936\n",
      "[199]\ttraining's binary_logloss: 0.416526\tvalid_1's binary_logloss: 0.609618\n",
      "[200]\ttraining's binary_logloss: 0.415756\tvalid_1's binary_logloss: 0.609881\n",
      "[201]\ttraining's binary_logloss: 0.415058\tvalid_1's binary_logloss: 0.609832\n",
      "[202]\ttraining's binary_logloss: 0.414324\tvalid_1's binary_logloss: 0.610014\n",
      "[203]\ttraining's binary_logloss: 0.413585\tvalid_1's binary_logloss: 0.610107\n",
      "[204]\ttraining's binary_logloss: 0.412798\tvalid_1's binary_logloss: 0.610432\n",
      "[205]\ttraining's binary_logloss: 0.41209\tvalid_1's binary_logloss: 0.610616\n",
      "[206]\ttraining's binary_logloss: 0.411336\tvalid_1's binary_logloss: 0.610971\n",
      "[207]\ttraining's binary_logloss: 0.410626\tvalid_1's binary_logloss: 0.611248\n",
      "[208]\ttraining's binary_logloss: 0.410003\tvalid_1's binary_logloss: 0.611792\n",
      "[209]\ttraining's binary_logloss: 0.409252\tvalid_1's binary_logloss: 0.612032\n",
      "[210]\ttraining's binary_logloss: 0.408566\tvalid_1's binary_logloss: 0.61221\n",
      "[211]\ttraining's binary_logloss: 0.407803\tvalid_1's binary_logloss: 0.612316\n",
      "[212]\ttraining's binary_logloss: 0.407127\tvalid_1's binary_logloss: 0.612495\n",
      "[213]\ttraining's binary_logloss: 0.4064\tvalid_1's binary_logloss: 0.611917\n",
      "[214]\ttraining's binary_logloss: 0.405728\tvalid_1's binary_logloss: 0.612519\n",
      "[215]\ttraining's binary_logloss: 0.405077\tvalid_1's binary_logloss: 0.612765\n",
      "[216]\ttraining's binary_logloss: 0.404356\tvalid_1's binary_logloss: 0.612383\n",
      "[217]\ttraining's binary_logloss: 0.403719\tvalid_1's binary_logloss: 0.61238\n",
      "[218]\ttraining's binary_logloss: 0.403095\tvalid_1's binary_logloss: 0.612218\n",
      "[219]\ttraining's binary_logloss: 0.402518\tvalid_1's binary_logloss: 0.61242\n",
      "[220]\ttraining's binary_logloss: 0.401921\tvalid_1's binary_logloss: 0.612454\n",
      "[221]\ttraining's binary_logloss: 0.401269\tvalid_1's binary_logloss: 0.612367\n",
      "[222]\ttraining's binary_logloss: 0.400617\tvalid_1's binary_logloss: 0.61241\n",
      "[223]\ttraining's binary_logloss: 0.399992\tvalid_1's binary_logloss: 0.612486\n",
      "[224]\ttraining's binary_logloss: 0.399321\tvalid_1's binary_logloss: 0.612776\n",
      "[225]\ttraining's binary_logloss: 0.398735\tvalid_1's binary_logloss: 0.613451\n",
      "[226]\ttraining's binary_logloss: 0.398141\tvalid_1's binary_logloss: 0.613401\n",
      "[227]\ttraining's binary_logloss: 0.397515\tvalid_1's binary_logloss: 0.613395\n",
      "[228]\ttraining's binary_logloss: 0.396858\tvalid_1's binary_logloss: 0.613893\n",
      "[229]\ttraining's binary_logloss: 0.396122\tvalid_1's binary_logloss: 0.613888\n",
      "[230]\ttraining's binary_logloss: 0.395476\tvalid_1's binary_logloss: 0.613876\n",
      "[231]\ttraining's binary_logloss: 0.394899\tvalid_1's binary_logloss: 0.613959\n",
      "[232]\ttraining's binary_logloss: 0.394239\tvalid_1's binary_logloss: 0.61386\n",
      "[233]\ttraining's binary_logloss: 0.393536\tvalid_1's binary_logloss: 0.613255\n",
      "[234]\ttraining's binary_logloss: 0.392961\tvalid_1's binary_logloss: 0.613403\n",
      "[235]\ttraining's binary_logloss: 0.39242\tvalid_1's binary_logloss: 0.613293\n",
      "[236]\ttraining's binary_logloss: 0.391727\tvalid_1's binary_logloss: 0.613704\n",
      "[237]\ttraining's binary_logloss: 0.391167\tvalid_1's binary_logloss: 0.613996\n",
      "[238]\ttraining's binary_logloss: 0.390586\tvalid_1's binary_logloss: 0.614283\n",
      "[239]\ttraining's binary_logloss: 0.389876\tvalid_1's binary_logloss: 0.614068\n",
      "[240]\ttraining's binary_logloss: 0.389311\tvalid_1's binary_logloss: 0.614001\n",
      "[241]\ttraining's binary_logloss: 0.38874\tvalid_1's binary_logloss: 0.613854\n",
      "[242]\ttraining's binary_logloss: 0.388173\tvalid_1's binary_logloss: 0.613195\n",
      "[243]\ttraining's binary_logloss: 0.38763\tvalid_1's binary_logloss: 0.613166\n",
      "[244]\ttraining's binary_logloss: 0.387089\tvalid_1's binary_logloss: 0.613315\n",
      "[245]\ttraining's binary_logloss: 0.386465\tvalid_1's binary_logloss: 0.613558\n",
      "[246]\ttraining's binary_logloss: 0.385861\tvalid_1's binary_logloss: 0.613781\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(learning_rate=0.02, n_estimators=800)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(learning_rate=0.02, n_estimators=800)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(learning_rate=0.02, n_estimators=800)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evals = [(X_tr, y_tr), (X_val, y_val)]\n",
    "lgbm_wrapper.fit(X_tr, y_tr, early_stopping_rounds=100, eval_metric=\"logloss\", eval_set=evals, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z3YiAxdOAhqh"
   },
   "source": [
    "### **3-1-g. 위에서 학습시킨 `lgbm_wrapper`의 정확도를 출력하세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "yrG3MF-JAom3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM 정확도: 0.6768\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "preds = lgbm_wrapper.predict(X_test)\n",
    "\n",
    "# 정확도 계산\n",
    "accuracy = accuracy_score(y_test, preds)\n",
    "print(\"LGBM 정확도: {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s5_joSurAjHs"
   },
   "source": [
    "### **3-1-i. 피처 중요도를 중요한 순서대로 시각화 해주세요.**\n",
    "(힌트: 파머완 252 페이지)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "5PG_98tJBfB9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Feature importance'}, xlabel='Feature importance', ylabel='Features'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from lightgbm import plot_importance\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "flg, ax = plt.subplots(figsize=(10, 12))\n",
    "plot_importance(lgbm_wrapper, ax=ax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "egUn68R9AjSZ"
   },
   "source": [
    "## **3-2. HyperOpt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "YQfqj1GmGiYa"
   },
   "outputs": [],
   "source": [
    "from hyperopt import hp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dt90nZGGAjaO"
   },
   "source": [
    "### **3-2-a. 주어진 정보를 바탕으로 검색 공간을 설정해 주세요.**\n",
    "(힌트: `hp.uniform`)\n",
    "\n",
    "- max_depth: 5에서 20까지, 간격 = 1\n",
    "- min_child_weight: 1에서 2까지, 간격 = 1\n",
    "- colsample_bytree: 0.5, 1\n",
    "- learning_rate: 0.01에서 0.2 사이, 정규 분포된 값으로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "j9hI35hEBenL"
   },
   "outputs": [],
   "source": [
    "search_space = {'max_depth': hp.quniform('max_depth', 5, 20, 1),\n",
    "               'min_child_weight': hp.quniform('min_child_weight', 1, 2, 1),\n",
    "               'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1),\n",
    "               'learning_rate': hp.uniform('learning_rate', 0.01, 0.2)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3cSRp1UDAji8"
   },
   "source": [
    "### **3-2-b. 검색 공간을 인자로 받아 목적함수를 완성해 주세요.**\n",
    "(n_estimators = 800)  \n",
    "(❓❓❓❓❓로 표시된 빈칸을 채워주세요!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "VIi05vIgHFKQ"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "from hyperopt import STATUS_OK\n",
    "\n",
    "\n",
    "def objective_func(search_space):\n",
    "    xgb_clf = XGBClassifier(n_estimators = 800,\n",
    "                            max_depth = int(search_space['max_depth']),\n",
    "                            min_child_weight = search_space['min_child_weight'],\n",
    "                            learning_rate = search_space['learning_rate'],\n",
    "                            colsample_bytree = search_space['colsample_bytree'],\n",
    "                            eval_metric = 'logloss')\n",
    "    accuracy = cross_val_score(xgb_clf, X_train, y_train, scoring = 'accuracy', cv = 3)\n",
    "\n",
    "    return {'loss':-1 * np.mean(accuracy), 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dpFPo2bIBKYA"
   },
   "source": [
    "### **3-2-c. best에 `fmin()` 함수를 이용하여 최적 파라미터 값들을 저장해 주세요.**\n",
    "- fn, 검색공간: 위에서 구한 값\n",
    "- 최대 반복 횟수: 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "oagDclMCKKmS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 50/50 [02:30<00:00,  3.01s/trial, best loss: -0.6595413030809006]\n",
      "best: {'colsample_bytree': 0.8192295651308084, 'learning_rate': 0.013817592525467237, 'max_depth': 12.0, 'min_child_weight': 1.0}\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, Trials\n",
    "\n",
    "trial_val = Trials()\n",
    "best = fmin(fn=objective_func,\n",
    "            space=search_space,\n",
    "            algo = tpe.suggest,\n",
    "            max_evals=50,\n",
    "            trials = trial_val,\n",
    "            rstate = np.random.default_rng(seed = 9))\n",
    "print('best:', best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X00SYdMqBKf-"
   },
   "source": [
    "### **3-2-d. 아래는 best에 포함된 최적 파라미터들을 할당한 분류기입니다. 해당 분류기의 정확도를 출력해 주세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "YWG7Vx8qLskd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.6875\n"
     ]
    }
   ],
   "source": [
    "xgb_wrapper = XGBClassifier(n_estimators = 400,\n",
    "                            learning_rate = round(best['learning_rate'], 5),\n",
    "                            max_depth = int(best['max_depth']),\n",
    "                            min_child_weight = int(best['min_child_weight']),\n",
    "                            colsample_bytree = round(best['colsample_bytree'], 5)\n",
    "                           )\n",
    "\n",
    "evals = [(X_tr, y_tr), (X_val, y_val)]\n",
    "xgb_wrapper.fit(X_tr, y_tr, early_stopping_rounds=50, eval_metric = 'logloss',\n",
    "                eval_set = evals, verbose = 0)\n",
    "\n",
    "preds = xgb_wrapper.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, preds)\n",
    "print('정확도:', accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zi7nlAXnaIvx"
   },
   "source": [
    "# **4. 스태킹**\n",
    "- 4번 문제는 3번 문제에서 전처리 된 `water_potability.csv` 데이터를 계속 활용하시면 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zo-EqV9IaOHE"
   },
   "source": [
    "## **4-a. 기본 스태킹 기법을 적용해 봅시다.**\n",
    "- `SVM`, `KNN`, `로지스틱 회귀`, `결정 트리` 모델 객체를 생성해 주세요.\n",
    "- 최종 메타 모델은 `랜덤 포레스트`를 활용해주세요.\n",
    "- 파라미터 설정\n",
    "  - SVM: random_state = 0\n",
    "  - KNN: n_neighbors = 8\n",
    "  - RandomForest: n_estimators = 100, random_state = 0\n",
    "  - 나머지: 기본 파라미터(base model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "A8oVE61iW2rE"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "-g8nzDlXW_hD"
   },
   "outputs": [],
   "source": [
    "# SVM, KNN, 로지스틱 회귀, 결정 트리 개별 모델들을 생성해 주세요.\n",
    "svm_clf = SVC(random_state=0)\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=8)\n",
    "lr_clf = LogisticRegression()\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "\n",
    "# 최종 메타 모델로 랜덤 포레스트를 생성해 주세요.\n",
    "rf_final = RandomForestClassifier(n_estimators=100, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_kiFDVuDZ92_"
   },
   "source": [
    "## **4-b. 개별 모델들을 학습시키고 예측을 수행합니다.**\n",
    "- 아래 코드를 완성시켜 봅시다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "Vda9AE6ga1ne"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf.fit(X_tr, y_tr)\n",
    "knn_clf.fit(X_tr, y_tr)\n",
    "lr_clf.fit(X_tr, y_tr)\n",
    "dt_clf.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "bqQEJMSwbXfz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM 정확도: 0.6145\n",
      "KNN 정확도: 0.6031\n",
      "로지스틱 회귀 정확도: 0.6145\n",
      "결정 트리 정확도: 0.5992\n"
     ]
    }
   ],
   "source": [
    "## 학습된 개별 모델들이 반환하는 예측 데이터셋을 생성하세요.\n",
    "# 예측 시 들어가는 테스트 데이터셋 이름은 X_val 입니다.\n",
    "svm_pred = svm_clf.predict(X_val)\n",
    "knn_pred = knn_clf.predict(X_val)\n",
    "lr_pred = lr_clf.predict(X_val)\n",
    "dt_pred = dt_clf.predict(X_val)\n",
    "\n",
    "## 예측 정확도를 반환하세요. 테스트 레이블 데이터셋 이름은 y_val 입니다.\n",
    "# hint : accuracy_score()\n",
    "print('SVM 정확도: {0:.4f}'.format(accuracy_score(y_val, svm_pred)))\n",
    "print('KNN 정확도: {0:.4f}'.format(accuracy_score(y_val, knn_pred)))\n",
    "print('로지스틱 회귀 정확도: {0:.4f}'.format(accuracy_score(y_val, lr_pred)))\n",
    "print('결정 트리 정확도: {0:.4f}'.format(accuracy_score(y_val, dt_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AmQiW4i4c_9B"
   },
   "source": [
    "## **4-c. 반환된 예측 데이터셋을 행 형태로 묶어 pred 데이터셋에 저장합니다**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "Od3yHZ3fc8Uf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 262)\n",
      "(262, 4)\n"
     ]
    }
   ],
   "source": [
    "pred = np.array([svm_pred, knn_pred, lr_pred, dt_pred])\n",
    "print(pred.shape)\n",
    "\n",
    "# 행과 열의 위치를 교환해 원본 데이터 값 하나 당 예측 데이터셋의 값이 1대1 매칭이 되도록 하세요.\n",
    "pred = np.transpose(pred)\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h8rhG78DdzpT"
   },
   "source": [
    "## **4-d. 완성된 최종 데이터셋을 최종 메타 모델에 학습시키고 예측시킵니다.**\n",
    "- 기본 스태킹 모델이므로 학습과 예측 모두 **동일한** 데이터셋을 사용합니다.\n",
    "- **정확도**도 함께 출력해 주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "eDf69kCPebqf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 메타 모델의 예측 정확도: 0.6260\n"
     ]
    }
   ],
   "source": [
    "rf_final.fit(pred, y_val)\n",
    "final = rf_final.predict(pred)\n",
    "\n",
    "print('최종 메타 모델의 예측 정확도: {0:.4f}'.format(accuracy_score(y_val , final)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bt9i77_NqqJp"
   },
   "source": [
    "# **5. CatBoost**\n",
    "- 책에서 다루지 않는 부분이기 때문에 간단한 실습만 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "bUp-KlCjr7nt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Obtaining dependency information for optuna from https://files.pythonhosted.org/packages/69/60/87a06ef66b34cbe2f2eb0ab66f003664404a7f40c21403a69fad7e28a82b/optuna-3.3.0-py3-none-any.whl.metadata\n",
      "  Downloading optuna-3.3.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting alembic>=1.5.0 (from optuna)\n",
      "  Obtaining dependency information for alembic>=1.5.0 from https://files.pythonhosted.org/packages/a2/8b/46919127496036c8e990b2b236454a0d8655fd46e1df2fd35610a9cbc842/alembic-1.12.0-py3-none-any.whl.metadata\n",
      "  Downloading alembic-1.12.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting cmaes>=0.10.0 (from optuna)\n",
      "  Obtaining dependency information for cmaes>=0.10.0 from https://files.pythonhosted.org/packages/f7/46/7d9544d453346f6c0c405916c95fdb653491ea2e9976cabb810ba2fe8cd4/cmaes-0.10.0-py3-none-any.whl.metadata\n",
      "  Downloading cmaes-0.10.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting colorlog (from optuna)\n",
      "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: numpy in ./anaconda3/lib/python3.11/site-packages (from optuna) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in ./anaconda3/lib/python3.11/site-packages (from optuna) (23.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in ./anaconda3/lib/python3.11/site-packages (from optuna) (1.4.39)\n",
      "Requirement already satisfied: tqdm in ./anaconda3/lib/python3.11/site-packages (from optuna) (4.65.0)\n",
      "Requirement already satisfied: PyYAML in ./anaconda3/lib/python3.11/site-packages (from optuna) (6.0)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna)\n",
      "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in ./anaconda3/lib/python3.11/site-packages (from alembic>=1.5.0->optuna) (4.7.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in ./anaconda3/lib/python3.11/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.1)\n",
      "Downloading optuna-3.3.0-py3-none-any.whl (404 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.2/404.2 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading alembic-1.12.0-py3-none-any.whl (226 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.0/226.0 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cmaes-0.10.0-py3-none-any.whl (29 kB)\n",
      "Installing collected packages: Mako, colorlog, cmaes, alembic, optuna\n",
      "Successfully installed Mako-1.2.4 alembic-1.12.0 cmaes-0.10.0 colorlog-6.7.0 optuna-3.3.0\n",
      "Requirement already satisfied: catboost in ./anaconda3/lib/python3.11/site-packages (1.2)\n",
      "Requirement already satisfied: graphviz in ./anaconda3/lib/python3.11/site-packages (from catboost) (0.20.1)\n",
      "Requirement already satisfied: matplotlib in ./anaconda3/lib/python3.11/site-packages (from catboost) (3.7.1)\n",
      "Requirement already satisfied: numpy>=1.16.0 in ./anaconda3/lib/python3.11/site-packages (from catboost) (1.24.3)\n",
      "Requirement already satisfied: pandas>=0.24 in ./anaconda3/lib/python3.11/site-packages (from catboost) (1.5.3)\n",
      "Requirement already satisfied: scipy in ./anaconda3/lib/python3.11/site-packages (from catboost) (1.10.0)\n",
      "Requirement already satisfied: plotly in ./anaconda3/lib/python3.11/site-packages (from catboost) (5.9.0)\n",
      "Requirement already satisfied: six in ./anaconda3/lib/python3.11/site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in ./anaconda3/lib/python3.11/site-packages (from pandas>=0.24->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./anaconda3/lib/python3.11/site-packages (from pandas>=0.24->catboost) (2022.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./anaconda3/lib/python3.11/site-packages (from matplotlib->catboost) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in ./anaconda3/lib/python3.11/site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./anaconda3/lib/python3.11/site-packages (from matplotlib->catboost) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./anaconda3/lib/python3.11/site-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./anaconda3/lib/python3.11/site-packages (from matplotlib->catboost) (23.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in ./anaconda3/lib/python3.11/site-packages (from matplotlib->catboost) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./anaconda3/lib/python3.11/site-packages (from matplotlib->catboost) (3.0.9)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in ./anaconda3/lib/python3.11/site-packages (from plotly->catboost) (8.2.2)\n"
     ]
    }
   ],
   "source": [
    "# catboost를 사용하기 위해 다음 코드를 실행합니다.\n",
    "\n",
    "!pip install optuna\n",
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "xbcYHmIsqycq"
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "cT3d6EKqsJRj"
   },
   "outputs": [],
   "source": [
    "df = datasets.load_iris()\n",
    "X = df.data\n",
    "y = df.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "8t-R1-Wfskfm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x17f913410>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CatBoostClassifier 객체를 생성하고 학습시켜 주세요.\n",
    "\n",
    "model_CBC = CatBoostClassifier()\n",
    "model_CBC.fit(X_train, y_train, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "7yfAnYNXs4LW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost의 예측 정확도: 0.9778\n"
     ]
    }
   ],
   "source": [
    "# pred에 X_test에 대한 예측 결과를 저장해 주세요.\n",
    "pred = model_CBC.predict(X_test)\n",
    "\n",
    "# 아래 코드를 완성해서 정확도를 출력하세요.\n",
    "print('CatBoost의 예측 정확도: {0:.4f}'.format(accuracy_score(y_test , pred)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
