{"cells":[{"cell_type":"markdown","metadata":{"id":"5l1bXj5uwAks"},"source":["# **1.선형 회귀 모델**"]},{"cell_type":"markdown","metadata":{"id":"vOERgLcGbtUw"},"source":["## **1-a. 데이터 불러오기**"]},{"cell_type":"markdown","metadata":{"id":"LGCYjhRDnRoC"},"source":["### **당뇨병 환자 데이터 불러오기**\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jd4EC8OvnY3M"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.datasets import load_diabetes\n","from sklearn.model_selection import train_test_split\n","\n","diabetes = load_diabetes()\n","df = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)"]},{"cell_type":"markdown","metadata":{"id":"RHCEHMjxb63B"},"source":["### **데이터 세트 확인 및 변환**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kWDajAn7cB7G"},"outputs":[],"source":["# diabetes 데이터 세트 설명 출력 (실행해서 확인해주세요.)\n","print(diabetes.DESCR)"]},{"cell_type":"markdown","metadata":{"id":"N_Bz6z3WcGfH"},"source":["* age : 나이\n","* sex : 성별\n","* bmi : 체질량지수\n","* bp : 평균 혈압\n","* s1 : 혈중 총콜레스테롤\n","* s2 : 저밀도 지질단백질\n","* s3 : 고밀도 지질단백질\n","* s4 : 총 콜레스테롤 수치\n","* s5 : 혈중 트리글리세라이드 수치\n","* s6 : 혈당 수치"]},{"cell_type":"markdown","metadata":{"id":"hsXruyc0cU2N"},"source":["**``` ##### ``` 을 채워주세요.**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xiAvzF5mcF3a"},"outputs":[],"source":["# diabetes 데이터 세트의 target 배열은 1년 후의 당뇨병이 진전된 정도임. 이를 y 칼럼으로 DataFrame에 추가함.\n","df['y'] = #####"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U91AYjjjddeQ"},"outputs":[],"source":["# 데이터 세트의 shape 확인\n","print('diabetes 데이터 세트 크기 :', df.#####)\n","\n","# 데이터 세트의 상위 5개 행 출력\n","df.#####"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AYCqSAsNzikc"},"outputs":[],"source":["# 데이터 세트 피처의 Null 값 유무와 자료형 확인\n","df.#####"]},{"cell_type":"markdown","metadata":{"id":"8LHkHIDqdtfL"},"source":["## **1-b. 각 칼럼이 회귀 결과에 미치는 영향 알아보기**"]},{"cell_type":"markdown","metadata":{"id":"iEiIN7VzeGos"},"source":["**``` ##### ``` 을 채워주세요**"]},{"cell_type":"markdown","metadata":{"id":"J0j31e7hjFtM"},"source":["### **시각화로 알아보기**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kb_k4WueeCJz"},"outputs":[],"source":["import seaborn as sns\n","\n","%matplotlib inline"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WtSRkuZTdune"},"outputs":[],"source":["# 3개의 행과 3개의 열을 가진 subplots를 이용. axs는 3x3개의 ax를 가짐.\n","fig, axs = plt.subplots(figsize=(10,10), ncols=3, nrows=3)\n","lm_features = ['age', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']\n","for i, feature in enumerate(lm_features):\n","    row = int(i/3)\n","    col = i%3\n","    # 시본의 regplot을 이용해 산점도와 선형 회귀 직선을 함께 표현\n","    sns.regplot(x=feature, y=#####, data=#####, ax=axs[row][col])"]},{"cell_type":"markdown","metadata":{"id":"-gQ9ly9keWJO"},"source":["**Q. 어떤 변수의 feature 중요도가 가장 높게 나타나나요?**\n","\n","A. #####"]},{"cell_type":"markdown","metadata":{"id":"zdrE8nr-jBEy"},"source":["### **상관계수로 알아보기**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yUznz8SgjI0d"},"outputs":[],"source":["# 변수 사이의 상관 계수 구하기\n","# hint: df는 pandas dataframe 이다. corr함수 이용하기)\n","diabetes_corr = df.#####"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oVBCTFkBjOSf"},"outputs":[],"source":["# 회귀 분석 대상인 피처들과 target 사이의 상관계수만 슬라이싱한 후, abs()를 통해 양수로 변환하여 큰 순서대로 출력\n","diabetes_corr.loc[:'s6', 'y'].abs().sort_values(ascending=False)"]},{"cell_type":"markdown","metadata":{"id":"2KYErUywjaLo"},"source":["**Q. 어떤 변수의 feature 중요도가 가장 높게 나타나나요?**\n","\n","A. #####"]},{"cell_type":"markdown","metadata":{"id":"NEhyOolyjm1A"},"source":["## **1-c. 단순 선형 회귀 모델**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nE23FUX_jz5g"},"outputs":[],"source":["from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_squared_error, r2_score"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hVMRPAK5jqk4"},"outputs":[],"source":["# 상관계수가 가장 큰 변수 'bmi'를 독립변수로 설정\n","X = df.bmi.values\n","y = df.y.values\n","\n","X = X.reshape(-1, 1)\n","y = y.reshape(-1, 1)\n","\n","# 데이터 세트 분리하기\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state =156)\n","\n","# 선형 회귀 OLS로 학습/예측/평가 수행.\n","lr1 = LinearRegression()\n","lr1.fit(X_train, y_train)\n","y_preds1 = lr1.predict(X_test)\n","\n","mse1 = #####\n","rmse1 = #####\n","\n","print('단순 선형 회귀 평가 지표')\n","print('MSE : {0:.3f} , RMSE : {1:.3F}'.format(#####, #####))\n","# 결정계수 R2 출력하기\n","print('Variance score : {0:.3f}'.format(#####(#####, #####)))"]},{"cell_type":"markdown","metadata":{"id":"LQ3ltCOSjrBw"},"source":["## **1-d. 다중 선형 회귀 모델**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I-fYNsLhlvCk"},"outputs":[],"source":["y = df['y']\n","X = df.drop(['y'], axis=1, inplace=False)\n","\n","# 데이터 세트 분리하기\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state =156)\n","\n","# 선형 회귀 OLS로 학습/예측/평가 수행.\n","lr2 = LinearRegression()\n","lr2.fit(X_train, y_train)\n","y_preds2 = lr2.predict(X_test)\n","\n","mse2 = #####\n","rmse2 = #####\n","\n","print('다중 선형 회귀 평가 지표')\n","print('MSE : {0:.3f} , RMSE : {1:.3F}'.format(#####, #####))\n","# 결정계수 R2 출력하기\n","print('Variance score : {0:.3f}'.format(#####(#####, #####)))"]},{"cell_type":"markdown","metadata":{"id":"6w45_6_7mKhz"},"source":["**Q. 단순 선형 회귀 모델 ```lr1``` 과 다중 선형 회귀 모델 ```lr2``` 중 어떤 모델의 예측값이 더 믿을만한가요? 이유와 함께 답해주세요.**\n","\n","A. #####"]},{"cell_type":"markdown","metadata":{"id":"BDzbyI4UUr7y"},"source":["# **2. 경사 하강법**\n"]},{"cell_type":"markdown","metadata":{"id":"tm2meycdaTl1"},"source":["## **2-a. 데이터 불러오기**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vzomq9tPaYAa"},"outputs":[],"source":["X = diabetes.data[:, 2:3]\n","y = diabetes.target.reshape(-1, 1)\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state =156)"]},{"cell_type":"markdown","metadata":{"id":"Ith4RLXTVOjG"},"source":["## **2-b. 데이터 시각화**\n","- 주어진 당뇨병 환자 데이터를 산점도로 시각화 해보겠습니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cnvL85feU0Ae"},"outputs":[],"source":["plt.scatter(X,y)\n","plt.xlabel('x')\n","plt.ylabel('y')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"hv-Ln9T1WIMc"},"source":["## **2-c. 비용 함수 정의**\n","\n","RSS 방식으로 비용을 계산하는 ```get_cost()``` 함수의 빈칸을 채워주세요."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pCmarzMCWMMc"},"outputs":[],"source":["def get_cost(y, y_pred):\n","    N = len(y)\n","    # Q. RSS 방식으로 비용을 계산하는 get_cost 함수의 빈칸을 채워주세요\n","    cost = #### 여기를 채워주세요 ####\n","    return cost"]},{"cell_type":"markdown","metadata":{"id":"ujhjOWuZWa5k"},"source":["## **2-d. 회귀 계수 업데이트 함수 정의**\n","회귀 계수 w0, w1를 업데이트하는 ```get_weight_updates()``` 함수의 빈칸을 채워주세요."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3PqiSnkOWpzQ"},"outputs":[],"source":["def get_weight_updates(w1, w0, X, y, learning_rate=0.01):\n","    N = len(y)\n","\n","    w1_update = np.zeros_like(w1)\n","    w0_update = np.zeros_like(w0)\n","\n","    # Q. 예측 값 계산, dot()를 사용해서 배열 X와 W1의 내적을 포함해서 구해주세요.\n","    y_pred = ### 여기를 채워주세요 ###\n","\n","    diff = y-y_pred\n","    w0_factors = np.ones((N,1))\n","\n","    # Q. w1, w0 업데이트 값 계산식을 참고하여, 배열 X와 diff의 내적을 포함해서 구해주세요.\n","    w1_update = ### 여기를 채워주세요 ###\n","    w0_update = ### 여기를 채워주세요 ###\n","\n","    return w1_update, w0_update"]},{"cell_type":"markdown","metadata":{"id":"lq4b_hDnXF4U"},"source":["## **2-e. 미니배치 확률적 경사 하강법 구현**\n","- ```batch_size``` 만큼 일부 데이터를 추출해서 w값 업데이트에 사용하는 미니 배치 확률적 경사 하강 함수 ```stochastic_gradient_descent_steps()```의 빈칸을 채워주세요."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZtFJjD99XIRi"},"outputs":[],"source":["def stochastic_gradient_descent_steps(X, y, batch_size=100, iters=100000):\n","    w1 = np.zeros((1, X.shape[1]))\n","    w0 = np.zeros((1, 1))\n","\n","    prev_cost = 100000\n","    iter_index =0\n","\n","    for ind in range(iters):\n","        np.random.seed(ind)\n","\n","        stochastic_random_index = np.random.permutation(X.shape[0])\n","        sample_X = X[stochastic_random_index[0:batch_size]]\n","        sample_y = y[stochastic_random_index[0:batch_size]]\n","\n","        # Q. learning_rate = 0.01로 업데이트 값을 구해주세요.\n","        w1_update, w0_update = ### 여기를 채워주세요 ###\n","        w1 = w1 - w1_update\n","        w0 = w0 - w0_update\n","\n","    return w1, w0"]},{"cell_type":"markdown","metadata":{"id":"ZhraLRwRXylg"},"source":["## **2-f. w1, w0를 구하고 비용 계산하기**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TdNCUt3LYAs-"},"outputs":[],"source":["w1, w0 =  stochastic_gradient_descent_steps(X, y, iters=100000)\n","print(\"w1:{0:.3f} w0:{1:.3f}\".format(w1[0,0], w0[0,0]))\n","y_pred = w1 * X + w0\n","print('Gradient Descent Total Cost:{0:.4f}'.format(get_cost(y, y_pred)))"]},{"cell_type":"markdown","metadata":{"id":"WYOsG95vYOwl"},"source":["## **2-g. 회귀 plot 그리기**\n","구한 회귀 계수를 바탕으로, 선형 회귀 plot을 그려 확인해보겠습니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9dJQY3eZYWI7"},"outputs":[],"source":["plt.scatter(X,y)\n","plt.plot(X, y_pred, color='red')\n","plt.xlabel('x')\n","plt.ylabel('y')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"cqzqHIdGYn0Z"},"source":["# **3.다항 회귀**\n"]},{"cell_type":"markdown","metadata":{"id":"kI66DaMAg5r2"},"source":["## **3-a. Pipeline을 이용한 다항 회귀 분석**\n","- 2차 다항 피처로 변환하고, 선형 회귀 모델을 만드는 과정을 Pipeline으로 연결해주세요.\n","- Pipeline의 step에 접근하여 회귀 계수를 구해주세요."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2eONrKmGZAhr"},"outputs":[],"source":["from sklearn.preprocessing import PolynomialFeatures\n","from sklearn.linear_model import LinearRegression\n","from sklearn.pipeline import Pipeline\n","import numpy as np\n","\n","# Q. 2차 다항 피처로 변환하고, 선형회귀 모델 선언하는 과정을 Pipeline으로 연결해주세요\n","model = Pipeline(## 여기를 채워주세요 ##\n","                 )\n","\n","model = model.fit(X, y)\n","\n","# Q. named_steps를 이용해 회귀 계수를 구하고, 소수점 둘째 자리까지 반올림하여 저장해주세요\n","W = ## 여기를 채워주세요 ##\n","print('Polynomial 회귀 계수\\n', W)"]},{"cell_type":"markdown","metadata":{"id":"Kh48I92IgsQv"},"source":["# **4.규제 선형 모델**"]},{"cell_type":"markdown","metadata":{"id":"3qqN_EnLg2lC"},"source":["## **4-a.릿지(Ridge) 회귀**\n","- 앞에서 실행했던 당뇨병 환자 데이터를 Ridge 클래스로 다시 예측하고, 예측 성능을 ```cross_val_score()```로 평가해 보겠습니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k7y8mrogGx5o"},"outputs":[],"source":["# 코드를 실행해 주세요.\n","X_data = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)\n","y_target = diabetes.target\n","\n","X_train, X_test, y_train, y_test = train_test_split(X_data, y_target, test_size=0.3, random_state =156)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7SCoBBe5grIf"},"outputs":[],"source":["from sklearn.linear_model import Ridge\n","from sklearn.model_selection import cross_val_score"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mQFUzKoTz44h"},"outputs":[],"source":["# 릿지의 alpha 값을 10으로 설정해 평균 rmse 살펴보기(cv = 5)\n","# 5 folds의 개별 rmse 값과 평균 rmse 값을 모두 출력하는 코드까지 작성하세요!\n","\n","ridge =\n","neg_mse_scores =\n","rmse_scores =\n","avg_rmse =\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"XtNniVxuSAJ5"},"source":["**이제 릿지의 alpha 값을 [0, 0.1, 1, 10, 100] 으로 변화시키면서 rmse와 회귀 계수 값의 변화를 살펴보겠습니다.**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C9kpEXKNQjMJ"},"outputs":[],"source":["# 릿지에 사용될 alpha 파라미터 값 정의\n","alphas =\n","\n","# 회귀계수 df 만들기\n","coeff_df =\n","\n","# alphas의 리스트 값을 반복하면서 alpha에 따른 평균 rmse 출력하\n","# (for문을 사용하고, for문 안에 위에서 실행했던 코드를 참고해 5 폴드의 평균 rmse를 계산하세요.)\n","# 아래에 코드 작성.\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eLKXy25-R9nO"},"outputs":[],"source":["# 회귀계수 df 만들기\n","coeff_df = pd.DataFrame()\n","\n","# alpha에 따른 피처별 회귀 계수를 Series로 변환하고 이를 DataFrame의 칼럼으로 추가하세요\n","# hint: 파머완 p.323 참조, for문을 사용하세요\n","# 아래에 코드 작성.\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"9QBTQM1gDB43"},"source":["## **4-b.라쏘(Lasso) 회귀**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u5uoEFFiIPyB"},"outputs":[],"source":["from sklearn.linear_model import Lasso, ElasticNet"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c7FpESTiDMpX"},"outputs":[],"source":["# 5주차 예습과제에서 생성했던 get_linear_reg_eval() 함수를 불러오세요.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wh49amQQIWBh"},"outputs":[],"source":["# 라쏘에 사용될 alpha 파라미터 값을 리스트에 저장하세요.\n","# (alpha 값은 0.05, 0.1, 0.5, 1, 3)\n","\n","lasso_alphas =\n","\n","# alpha 값의 변화에 따른 평균 RMSE를 출력하세요.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zRoaR7h_Ortj"},"outputs":[],"source":["# alpha 값에 따른 피처별 회귀 계수 살펴보기\n","# 반환된 coeff_lasso_df를 첫번째 칼럼 순으로 내림차순 정렬해 회귀계수 df를 출력하세요.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"8GgfRG9eRA3M"},"source":["## **4-c. 엘라스틱넷(ElasticNet) 회귀**"]},{"cell_type":"markdown","metadata":{"id":"Dw3iI0OERVZW"},"source":["**alpha 값들의 변화만 살펴보기 위해 엘라스틱넷 회귀의 주요 파라미터 중 하나인 ```l1_ratio```는 <U>0.7</U>로 고정 시키겠습니다.**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yqSWRHglRPsp"},"outputs":[],"source":["# 엘라스틱넷에 사용될 alpha 파라미터 값을 리스트에 저장하세요.\n","# (alpha 값은 0.05, 0.1, 0.5, 1, 3)\n","\n","elastic_alphas =\n","\n","# alpha 값의 변화에 따른 평균 RMSE를 출력하세요.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8Y-Z4btNRuYw"},"outputs":[],"source":["# alpha 값에 따른 피처별 회귀 계수 살펴보기\n","# 반환된 coeff_elastic_df를 첫번째 칼럼 순으로 내림차순 정렬해 회귀계수 df 출력하세요.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"MucaatmsTAgw"},"source":["## **4-e. 데이터 스케일링**\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ums0X9ZSTv_5"},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler, MinMaxScaler, PolynomialFeatures"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YwoeOX6TTSQM"},"outputs":[],"source":["# 5주차 예습과제에서 생성했던 get_scaled_data를 불러오세요.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ynWub8fvT052"},"outputs":[],"source":["# 알파값은 0.1, 1, 10, 100으로 지정하겠습니다.\n","alphas = [0.1, 1, 10, 100]\n","\n","# 파머완 330p에 소개된 5가지의 스케일링 방법을 사용하겠습니다.\n","scale_methods = [(None, None), ('Standard', None), ('Standard,', 2),\n","                ('MinMax', None), ('MinMax', 2), ('Log', None)]\n","\n","# 이제, for문을 활용해 릿지회귀의 데이터 변환을 반복해주세요.\n","# '#######'을 채워주시면 됩니다.\n","\n","for scale_method in scale_methods:\n","    X_data_scaled = get_scaled_data(method = scale_method[0], p_degree = scale_method[1],input_data = X_data)\n","    print('\\n##변환 유형 :{0}, Polynomial Degree:{1}'.format(scale_method[0], scale_method[1]))\n","    get_linear_reg_eval(########)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Uf2iWtdLVZL0"},"outputs":[],"source":["# 이번에는 같은 방식으로 라쏘회귀의 데이터 변환을 반복해주세요.\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kRMfTL5eVeov"},"outputs":[],"source":["# 마지막으로, 엘라스틱넷 회귀의 데이터 변환을 반복해주세요.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"BxEHuoO2u7Uf"},"source":["# **5.로지스틱 회귀**\n","- 사이킷런에서 제공하는 와인 등급 데이터 세트로 로지스틱 회귀 분석 실습하기"]},{"cell_type":"markdown","metadata":{"id":"Jwt7s8wkvCau"},"source":["## **5-a 데이터 불러오기**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J61-obhZvAvK"},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import warnings\n","warnings.filterwarnings('ignore')\n","%matplotlib inline\n","\n","from sklearn.datasets import load_wine\n","from sklearn.linear_model import LogisticRegression\n","\n","df = load_wine()\n","X, y = df.data, df.target"]},{"cell_type":"markdown","metadata":{"id":"YjPLmnVWvFxw"},"source":["## **5-b. 데이터 세트 분리**"]},{"cell_type":"markdown","metadata":{"id":"Z_Hj2ipWvIHb"},"source":["**정규 분포 형태 표준 스케일링 적용**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gNflt91LvFXk"},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","\n","# 아래에 코드를 입력해주세요\n","scaler =\n","data_scaled ="]},{"cell_type":"markdown","metadata":{"id":"Hl8j1w4pvOfl"},"source":["**학습/테스트 데이터 세트 분리**\n","- test_size = 0.3"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TyVIG5ryvN0j"},"outputs":[],"source":["# 괄호 안의 빈칸을 채워주세요\n","X_train , X_test, y_train , y_test = train_test_split( ## , ## , ## )"]},{"cell_type":"markdown","metadata":{"id":"lohgsYQ7vTrp"},"source":["## **5-c.로지스틱 회귀를 이용한 학습 및 예측 수행**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cwMGR8pXvT97"},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression\n","\n","# 로지스틱 회귀 모델 생성\n","lr_clf =\n","\n","# 학습\n","\n","\n","# 예측\n","lr_preds ="]},{"cell_type":"markdown","metadata":{"id":"Iy87EWCbvcxP"},"source":["**정확도 측정**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FYUa7Kk3vd29"},"outputs":[],"source":["from sklearn.metrics import accuracy_score, roc_auc_score\n","\n","# 괄호 안의 빈칸을 채워주세요\n","print('accuracy: {0:.3f}'.format( ### ))"]},{"cell_type":"markdown","metadata":{"id":"LYDyF9YTvmV1"},"source":["## **5-d.하이퍼 파라미터 최적화**\n","```GridSearchCV```를 이용해 하이퍼 파라미터 최적화하기\n","- solver: ['liblinear', 'lbfgs']\n","- penalty: ['l2', 'l1']\n","- C: [0.01, 0.1, 1, 1, 5, 10]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BQZzJTCbvmyU"},"outputs":[],"source":["from sklearn.model_selection import GridSearchCV\n","\n","# 괄호 안의 빈칸을 채워주세요\n","params={ ## ,\n","         ## ,\n","         ##  }\n","\n","grid_clf = GridSearchCV( ### )\n","grid_clf.fit(###)\n","print('최적 하이퍼 파라미터:{0}, 최적 평균 정확도:{1:.3f}'.format( ###(1)###, ###(2)###)"]},{"cell_type":"markdown","metadata":{"id":"g_Y0Uh0kwE4R"},"source":["# **6.회귀 트리**\n","* 앞 예제들에서 사용한 당뇨병 환자 데이터 세트 사용"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PFIbaei_wKlr"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.datasets import load_diabetes\n","from sklearn.model_selection import cross_val_score\n","from sklearn.ensemble import RandomForestRegressor"]},{"cell_type":"markdown","metadata":{"id":"kxJPk-6AwMSG"},"source":["## **6-a.데이터 세트 불러오기**\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iiFvLH9zwLF3"},"outputs":[],"source":["# 데이터 세트 로드\n","diabetes = load_diabetes()\n","df = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)\n","\n","df['y']=diabetes.target\n","X = df.drop(['y'],axis=1,inplace=False)\n","y = df['y']"]},{"cell_type":"markdown","metadata":{"id":"whXjUaxFwcVc"},"source":["## **6-b. 랜덤 포레스트 회귀 트리 이용**\n","- random_state = 0\n","- n_estimators = 1000"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gON7dXe_wRxt"},"outputs":[],"source":["rf = RandomForestRegressor( ### , ### )\n","\n","# 개별 negative MSE scores 계산하기\n","neg_mse_scores = cross_val_score(## , ## , ## , scoring=\"neg_mean_squared_error\", cv = 5)\n","# 개별 RMSE scores 계산하기\n","rmse_scores  =\n","# 평균 MSE scores 계산하기\n","avg_rmse ="]},{"cell_type":"markdown","metadata":{"id":"3SN2Lv4DxRBB"},"source":["**출력**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xWweetzdxVLl"},"outputs":[],"source":["print(' 5 교차 검증의 개별 Negative MSE scores: ', np.round(neg_mse_scores, 2))\n","print(' 5 교차 검증의 개별 RMSE scores : ', np.round(rmse_scores, 2))\n","print(' 5 교차 검증의 평균 RMSE : {0:.3f} '.format(avg_rmse))"]},{"cell_type":"markdown","metadata":{"id":"FbVZBYnBxbWd"},"source":["## **6-c. 랜덤 포레스트, 결정 트리, GBM, XGBoost, LightGBM 모두 이용**"]},{"cell_type":"markdown","metadata":{"id":"tuhIAlFoxlJT"},"source":["**입력 모델과 데이터 세트를 입력 받아 교차 검증으로 평균 RMSE 계산하는 함수 정의**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KFV6Y0Tmxgxg"},"outputs":[],"source":["def get_model_cv_prediction(model, X_data, y_target):\n","    neg_mse_scores = cross_val_score(model, X_data, y_target, scoring=\"neg_mean_squared_error\", cv = 5)\n","    rmse_scores  = np.sqrt(-1 * neg_mse_scores)\n","    avg_rmse = np.mean(rmse_scores)\n","    print('##### ',model.__class__.__name__ , ' #####')\n","    print(' 5 교차 검증의 평균 RMSE : {0:.3f} '.format(avg_rmse))"]},{"cell_type":"markdown","metadata":{"id":"-aKa9o3Exvu9"},"source":["**각 유형의 회귀 트리 생성**\n","- 결정트리: random_state=0, max_depth=4\n","- 랜덤 포레스트: random_state=0, n_estimators=1000\n","- GBM: random_state=0, n_estimators=1000\n","- XGBoost: n_estimators=1000\n","- LightGBM: n_estimators=1000\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TizuVS6ZxtVF"},"outputs":[],"source":["from sklearn.tree import DecisionTreeRegressor\n","from sklearn.ensemble import GradientBoostingRegressor\n","from xgboost import XGBRegressor\n","from lightgbm import LGBMRegressor"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cI6rf8XoxuRj"},"outputs":[],"source":["dt_reg =\n","rf_reg =\n","gb_reg =\n","xgb_reg =\n","lgb_reg ="]},{"cell_type":"markdown","metadata":{"id":"E-65oA1OyXS2"},"source":["**회귀 모델 반복하면서 평가 수행**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_egK6SbJyVU0"},"outputs":[],"source":["# 트리 기반의 회귀 모델을 반복하면서 평가 수행\n","models = [ ## , ## , ## , ## , ## ]\n","for model in models:\n","    get_model_cv_prediction(model, X, y)"]},{"cell_type":"markdown","metadata":{"id":"f7BWD-1ryjH-"},"source":["## **6-d.피처 중요도 시각화**\n","- ```index = X.columns```\n","- 중요도 순으로 정렬"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XwwERElMylNd"},"outputs":[],"source":["import seaborn as sns\n","%matplotlib inline\n","\n","rf_reg = RandomForestRegressor(n_estimators = 1000)\n","rf_reg.fit(X, y)\n","\n","feature_series =\n","feature_series =\n","sns.barplot(x= feature_series, y=feature_series.index)"]},{"cell_type":"markdown","metadata":{"id":"SMNYjt-QzZwx"},"source":["## **6-e.선형 회귀와 비교하여 회귀 트리의 예측값 판단 시각화**\n","- 데이터 세트 100개만 샘플링\n","- ```random_state = 0```"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fnXRYdCfzWoC"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","# 가장 큰 상관관계를 가지는 칼럼만 이용 (위 예제의 시각화 결과 참고)\n","\n","df_sample = df[[ ### ,'y']]\n","df_sample = df_sample.sample( ### )\n","print(df_sample.shape)\n","\n","# 산점도로 시각화 하는 코드를 작성해주세요\n","\n"]},{"cell_type":"markdown","metadata":{"id":"TFYCC6Wq0q_a"},"source":["**선형 회귀, 결정 트리 이용하여 학습 및 예측**\n","- DecisionTreeRegressor의 ```max_depth```는 각각 2, 7"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jTSbTin50Usm"},"outputs":[],"source":["import numpy as np\n","from sklearn.linear_model import LinearRegression\n","\n","# 선형 회귀와 결정 트리 기반의 Regressor 생성\n","lr_reg =\n","rf_reg2 =\n","rf_reg7 ="]},{"cell_type":"markdown","metadata":{"id":"K8ReY4_M1K2V"},"source":["- X값을 ```-0.1~0.1```까지의 100개의 테스트 데이터 세트로 제공\n","* Hint: ```arange (step size = 0.002)```"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"73Gk0sxf0-eZ"},"outputs":[],"source":["X_test = ### .reshape(-1, 1)"]},{"cell_type":"markdown","metadata":{"id":"H5G-bMv12P9S"},"source":["- 피처는 상관관계가 가장 큰 칼럼만 추출\n","- 결정 데이터 y 추출"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jcIZoMdv2Qrn"},"outputs":[],"source":["X_feature = df_sample[ ## ].values.reshape(-1,1)\n","y_target = df_sample[ ## ].values.reshape(-1,1)"]},{"cell_type":"markdown","metadata":{"id":"XFpc_ToU2lsC"},"source":["- 학습 및 예측 수행"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"do4_3wcZ2kQh"},"outputs":[],"source":["# 학습\n","###\n","###\n","###\n","\n","# 예측\n","pred_lr =\n","pred_rf2 =\n","pred_rf7 ="]},{"cell_type":"markdown","metadata":{"id":"7COMSmdZ2x0Y"},"source":["**학습된 Regressor에 예측한 회귀선 그리기**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"paKtOPmf2xVD"},"outputs":[],"source":["fig , (ax1, ax2, ax3) = plt.subplots(figsize=(14,4), ncols=3)\n","\n","# 선형 회귀로 학습된 모델 회귀 예측선\n","ax1.set_title('Linear Regression')\n","ax1.###   # 산점도 그리기\n","ax1.###   # 회귀선 그리기\n","\n","# DecisionTreeRegressor의 max_depth를 2로 했을 때 회귀 예측선\n","ax2.set_title('Decision Tree Regression: \\n max_depth=2')\n","ax2.###   # 산점도 그리기\n","ax2.###   # 회귀선 그리기\n","\n","# DecisionTreeRegressor의 max_depth를 7로 했을 때 회귀 예측선\n","ax3.set_title('Decision Tree Regression: \\n max_depth=7')\n","ax3.###   # 산점도 그리기\n","ax3.###   # 회귀선 그리기"]}],"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}