{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oW4LpW9lRj3n"
   },
   "source": [
    "# **1. GBM**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s3_1vAdpRxoo"
   },
   "source": [
    "## **1-a. `creditcard.csv`를 다운받은 후 실습을 진행해 주세요.**\n",
    "- 데이터 출처: [Credit Card Fraud Detection](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3vR5gQ4HYGAX"
   },
   "outputs": [],
   "source": [
    "## Colab - 구글 드라이브 마운트\n",
    "# Colab을 사용하시는 분들만 실행시켜 주시면 됩니다.\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lkOKaEKZG2Yn"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./creditcard.csv\", encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2_tC0W-5Ryje"
   },
   "source": [
    "## **1-b. GradientBoostingClassifier을 이용하여 훈련 데이터를 fit한 후, GBM 정확도와 수행시간을 구하세요.**\n",
    "(test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7zBOFln9ZENb"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "967Hgk2YZXfa",
    "outputId": "aa8b3623-a718-43f5-d07d-87cd0ec29b85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.9989\n"
     ]
    }
   ],
   "source": [
    "## 데이터 분할: 훈련 데이터와 테스트 데이터\n",
    "\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "## GBM 모델링\n",
    "# 아래에 코드를 작성해 주세요.\n",
    "gb_clf = GradientBoostingClassifier(random_state = 42)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "gb_pred= gb_clf.predict(X_test)\n",
    "gb_accuracy = accuracy_score(y_test, gb_pred)\n",
    "\n",
    "print('정확도: {0:.4f}'.format(gb_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0_npf7xNR1BZ"
   },
   "source": [
    "## **1-b(2). GBM으로 학습하는 시간이 얼마나 걸리는지 수행 시간을 출력해 주세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FdMUSczWa8_A",
    "outputId": "c47927fd-a125-4cab-a190-761f256d0009"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM 수행 시간: 238.3 초\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "gb_clf = GradientBoostingClassifier(random_state = 42)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "print('GBM 수행 시간: {0:.1f} 초'.format(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xqzN9Hy8TaOk"
   },
   "source": [
    "## **1-c. ```subsample``` 파라미터를 설정하여 gbm 모델을 학습시키고 학습 시간을 비교해 보세요.**  \n",
    "(subsample = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "FxWwRW_7TbT0"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4HAD9Ebsgte4",
    "outputId": "78b3f503-efbf-44f5-d170-4a05d34651e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.9992\n",
      "수행 시간: 1696177259.4\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "gbm_clf = GradientBoostingClassifier(subsample=0.8)\n",
    "gbm_clf.fit(X_train, y_train)\n",
    "gbm_pred = gbm_clf.predict(X_test)\n",
    "gbm_accuracy = accuracy_score(y_test, gbm_pred)\n",
    "gbm_start_time = time.time()\n",
    "\n",
    "print('정확도: {0:.4f}'.format(gbm_accuracy))\n",
    "print('수행 시간: {0:.1f}'.format(gbm_start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D52196vv7JoI"
   },
   "source": [
    "# **2. XGBoost**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "koZCKhp8HW4o"
   },
   "source": [
    "- 모델 : Python Wrapper XGBoost\n",
    "- 적용 데이터 : 위스콘신 유방암 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ECMkbXJ-7KT6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.3\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "\n",
    "print(xgboost.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5kFl0zeC7tQR"
   },
   "source": [
    "- 출력 : 1.7.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "fHDjuv_V7vAf"
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L11sPCSZ74oH"
   },
   "source": [
    "##**2-a. cancer_df의 shape을 프린트하고, 상위 5개 행을 확인해 주세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "4wBOlQxn72Te"
   },
   "outputs": [],
   "source": [
    "dataset = load_breast_cancer()\n",
    "X_features = dataset.data\n",
    "y_label = dataset.target\n",
    "\n",
    "cancer_df = pd.DataFrame(data = X_features, columns = dataset.feature_names)\n",
    "cancer_df['target'] = y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "cMfEC-nZ8HH-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 31)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "3          0.6638                  0.17300       0  \n",
       "4          0.2364                  0.07678       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(cancer_df.shape)\n",
    "cancer_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tOKlsQLD8HoD"
   },
   "source": [
    "## **2-b. 전체 데이터 중 80%는 학습용 데이터, 20%는 테스트용 데이터로 추출하고, 각각의 shape을 print해주세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "o6k1w2nf8SCm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455, 30) (114, 30)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y_label, test_size = 0.2, random_state = 156)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "9ZB87ux88a6w"
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(data = X_train, label = y_train)\n",
    "dtest = xgb.DMatrix(data = X_test, label = y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tzzNfY028f5b"
   },
   "source": [
    "##**2-c. 주어진 정보를 바탕으로 하이퍼 파라미터 목록을 완성해 주세요.**\n",
    "- 트리의 최대 깊이 : 3\n",
    "- 학습률 : 0.1\n",
    "- 반복 횟수 : 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "BZIEP5CS8jSs"
   },
   "outputs": [],
   "source": [
    "params = {'max_depth':3,\n",
    "          'eta':0.1,\n",
    "          'objective':'binary:logistic',\n",
    "          'eval_metric':'logloss'\n",
    "         }\n",
    "num_rounds = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "UInEOEh98t6z"
   },
   "outputs": [],
   "source": [
    "eval_list = [(dtrain,'train'),(dtest,'eval')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mzl7NufX8utk"
   },
   "source": [
    "## **2-d. 하이퍼 파라미터를 `train( )` 함수의 파라미터로 전달해 주세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "5vgia5qw8vCa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.60969\teval-logloss:0.61352\n",
      "[1]\ttrain-logloss:0.54080\teval-logloss:0.54784\n",
      "[2]\ttrain-logloss:0.48375\teval-logloss:0.49425\n",
      "[3]\ttrain-logloss:0.43446\teval-logloss:0.44799\n",
      "[4]\ttrain-logloss:0.39055\teval-logloss:0.40911\n",
      "[5]\ttrain-logloss:0.35415\teval-logloss:0.37498\n",
      "[6]\ttrain-logloss:0.32122\teval-logloss:0.34571\n",
      "[7]\ttrain-logloss:0.29259\teval-logloss:0.32053\n",
      "[8]\ttrain-logloss:0.26747\teval-logloss:0.29721\n",
      "[9]\ttrain-logloss:0.24515\teval-logloss:0.27799\n",
      "[10]\ttrain-logloss:0.22569\teval-logloss:0.26030\n",
      "[11]\ttrain-logloss:0.20794\teval-logloss:0.24604\n",
      "[12]\ttrain-logloss:0.19218\teval-logloss:0.23156\n",
      "[13]\ttrain-logloss:0.17792\teval-logloss:0.22005\n",
      "[14]\ttrain-logloss:0.16522\teval-logloss:0.20857\n",
      "[15]\ttrain-logloss:0.15362\teval-logloss:0.19999\n",
      "[16]\ttrain-logloss:0.14333\teval-logloss:0.19012\n",
      "[17]\ttrain-logloss:0.13398\teval-logloss:0.18182\n",
      "[18]\ttrain-logloss:0.12560\teval-logloss:0.17473\n",
      "[19]\ttrain-logloss:0.11729\teval-logloss:0.16766\n",
      "[20]\ttrain-logloss:0.10969\teval-logloss:0.15820\n",
      "[21]\ttrain-logloss:0.10297\teval-logloss:0.15472\n",
      "[22]\ttrain-logloss:0.09707\teval-logloss:0.14895\n",
      "[23]\ttrain-logloss:0.09143\teval-logloss:0.14331\n",
      "[24]\ttrain-logloss:0.08634\teval-logloss:0.13634\n",
      "[25]\ttrain-logloss:0.08131\teval-logloss:0.13278\n",
      "[26]\ttrain-logloss:0.07686\teval-logloss:0.12791\n",
      "[27]\ttrain-logloss:0.07284\teval-logloss:0.12526\n",
      "[28]\ttrain-logloss:0.06925\teval-logloss:0.11998\n",
      "[29]\ttrain-logloss:0.06555\teval-logloss:0.11641\n",
      "[30]\ttrain-logloss:0.06241\teval-logloss:0.11450\n",
      "[31]\ttrain-logloss:0.05959\teval-logloss:0.11257\n",
      "[32]\ttrain-logloss:0.05710\teval-logloss:0.11154\n",
      "[33]\ttrain-logloss:0.05441\teval-logloss:0.10868\n",
      "[34]\ttrain-logloss:0.05204\teval-logloss:0.10668\n",
      "[35]\ttrain-logloss:0.04975\teval-logloss:0.10421\n",
      "[36]\ttrain-logloss:0.04775\teval-logloss:0.10296\n",
      "[37]\ttrain-logloss:0.04585\teval-logloss:0.10058\n",
      "[38]\ttrain-logloss:0.04401\teval-logloss:0.09868\n",
      "[39]\ttrain-logloss:0.04226\teval-logloss:0.09644\n",
      "[40]\ttrain-logloss:0.04065\teval-logloss:0.09587\n",
      "[41]\ttrain-logloss:0.03913\teval-logloss:0.09424\n",
      "[42]\ttrain-logloss:0.03738\teval-logloss:0.09471\n",
      "[43]\ttrain-logloss:0.03611\teval-logloss:0.09427\n",
      "[44]\ttrain-logloss:0.03494\teval-logloss:0.09389\n",
      "[45]\ttrain-logloss:0.03365\teval-logloss:0.09418\n",
      "[46]\ttrain-logloss:0.03253\teval-logloss:0.09402\n",
      "[47]\ttrain-logloss:0.03148\teval-logloss:0.09236\n",
      "[48]\ttrain-logloss:0.03039\teval-logloss:0.09301\n",
      "[49]\ttrain-logloss:0.02947\teval-logloss:0.09127\n",
      "[50]\ttrain-logloss:0.02854\teval-logloss:0.09005\n",
      "[51]\ttrain-logloss:0.02753\teval-logloss:0.08961\n",
      "[52]\ttrain-logloss:0.02656\teval-logloss:0.08958\n",
      "[53]\ttrain-logloss:0.02568\teval-logloss:0.09070\n",
      "[54]\ttrain-logloss:0.02500\teval-logloss:0.08958\n",
      "[55]\ttrain-logloss:0.02430\teval-logloss:0.09036\n",
      "[56]\ttrain-logloss:0.02357\teval-logloss:0.09159\n",
      "[57]\ttrain-logloss:0.02296\teval-logloss:0.09153\n",
      "[58]\ttrain-logloss:0.02249\teval-logloss:0.09199\n",
      "[59]\ttrain-logloss:0.02185\teval-logloss:0.09195\n",
      "[60]\ttrain-logloss:0.02132\teval-logloss:0.09194\n",
      "[61]\ttrain-logloss:0.02079\teval-logloss:0.09146\n",
      "[62]\ttrain-logloss:0.02022\teval-logloss:0.09031\n",
      "[63]\ttrain-logloss:0.01970\teval-logloss:0.08941\n",
      "[64]\ttrain-logloss:0.01918\teval-logloss:0.08972\n",
      "[65]\ttrain-logloss:0.01872\teval-logloss:0.08974\n",
      "[66]\ttrain-logloss:0.01833\teval-logloss:0.08962\n",
      "[67]\ttrain-logloss:0.01787\teval-logloss:0.08873\n",
      "[68]\ttrain-logloss:0.01760\teval-logloss:0.08862\n",
      "[69]\ttrain-logloss:0.01724\teval-logloss:0.08974\n",
      "[70]\ttrain-logloss:0.01688\teval-logloss:0.08998\n",
      "[71]\ttrain-logloss:0.01664\teval-logloss:0.08978\n",
      "[72]\ttrain-logloss:0.01629\teval-logloss:0.08958\n",
      "[73]\ttrain-logloss:0.01598\teval-logloss:0.08953\n",
      "[74]\ttrain-logloss:0.01566\teval-logloss:0.08875\n",
      "[75]\ttrain-logloss:0.01539\teval-logloss:0.08860\n",
      "[76]\ttrain-logloss:0.01515\teval-logloss:0.08812\n",
      "[77]\ttrain-logloss:0.01488\teval-logloss:0.08840\n",
      "[78]\ttrain-logloss:0.01464\teval-logloss:0.08874\n",
      "[79]\ttrain-logloss:0.01449\teval-logloss:0.08815\n",
      "[80]\ttrain-logloss:0.01418\teval-logloss:0.08758\n",
      "[81]\ttrain-logloss:0.01400\teval-logloss:0.08741\n",
      "[82]\ttrain-logloss:0.01377\teval-logloss:0.08849\n",
      "[83]\ttrain-logloss:0.01357\teval-logloss:0.08857\n",
      "[84]\ttrain-logloss:0.01341\teval-logloss:0.08807\n",
      "[85]\ttrain-logloss:0.01325\teval-logloss:0.08764\n",
      "[86]\ttrain-logloss:0.01311\teval-logloss:0.08742\n",
      "[87]\ttrain-logloss:0.01293\teval-logloss:0.08761\n",
      "[88]\ttrain-logloss:0.01271\teval-logloss:0.08707\n",
      "[89]\ttrain-logloss:0.01254\teval-logloss:0.08727\n",
      "[90]\ttrain-logloss:0.01235\teval-logloss:0.08716\n",
      "[91]\ttrain-logloss:0.01223\teval-logloss:0.08696\n",
      "[92]\ttrain-logloss:0.01206\teval-logloss:0.08717\n",
      "[93]\ttrain-logloss:0.01193\teval-logloss:0.08707\n",
      "[94]\ttrain-logloss:0.01182\teval-logloss:0.08659\n",
      "[95]\ttrain-logloss:0.01165\teval-logloss:0.08612\n",
      "[96]\ttrain-logloss:0.01148\teval-logloss:0.08714\n",
      "[97]\ttrain-logloss:0.01136\teval-logloss:0.08677\n",
      "[98]\ttrain-logloss:0.01124\teval-logloss:0.08669\n",
      "[99]\ttrain-logloss:0.01113\teval-logloss:0.08655\n",
      "[100]\ttrain-logloss:0.01100\teval-logloss:0.08650\n",
      "[101]\ttrain-logloss:0.01085\teval-logloss:0.08641\n",
      "[102]\ttrain-logloss:0.01075\teval-logloss:0.08629\n",
      "[103]\ttrain-logloss:0.01064\teval-logloss:0.08626\n",
      "[104]\ttrain-logloss:0.01050\teval-logloss:0.08683\n",
      "[105]\ttrain-logloss:0.01040\teval-logloss:0.08677\n",
      "[106]\ttrain-logloss:0.01030\teval-logloss:0.08732\n",
      "[107]\ttrain-logloss:0.01020\teval-logloss:0.08730\n",
      "[108]\ttrain-logloss:0.01007\teval-logloss:0.08728\n",
      "[109]\ttrain-logloss:0.01000\teval-logloss:0.08730\n",
      "[110]\ttrain-logloss:0.00991\teval-logloss:0.08729\n",
      "[111]\ttrain-logloss:0.00980\teval-logloss:0.08800\n",
      "[112]\ttrain-logloss:0.00971\teval-logloss:0.08794\n",
      "[113]\ttrain-logloss:0.00963\teval-logloss:0.08784\n",
      "[114]\ttrain-logloss:0.00956\teval-logloss:0.08807\n",
      "[115]\ttrain-logloss:0.00948\teval-logloss:0.08765\n",
      "[116]\ttrain-logloss:0.00942\teval-logloss:0.08730\n",
      "[117]\ttrain-logloss:0.00931\teval-logloss:0.08780\n",
      "[118]\ttrain-logloss:0.00923\teval-logloss:0.08775\n",
      "[119]\ttrain-logloss:0.00915\teval-logloss:0.08768\n",
      "[120]\ttrain-logloss:0.00912\teval-logloss:0.08763\n",
      "[121]\ttrain-logloss:0.00902\teval-logloss:0.08757\n",
      "[122]\ttrain-logloss:0.00897\teval-logloss:0.08755\n",
      "[123]\ttrain-logloss:0.00890\teval-logloss:0.08716\n",
      "[124]\ttrain-logloss:0.00884\teval-logloss:0.08767\n",
      "[125]\ttrain-logloss:0.00880\teval-logloss:0.08774\n",
      "[126]\ttrain-logloss:0.00871\teval-logloss:0.08827\n",
      "[127]\ttrain-logloss:0.00865\teval-logloss:0.08831\n",
      "[128]\ttrain-logloss:0.00861\teval-logloss:0.08827\n",
      "[129]\ttrain-logloss:0.00856\teval-logloss:0.08789\n",
      "[130]\ttrain-logloss:0.00846\teval-logloss:0.08886\n",
      "[131]\ttrain-logloss:0.00842\teval-logloss:0.08868\n",
      "[132]\ttrain-logloss:0.00839\teval-logloss:0.08874\n",
      "[133]\ttrain-logloss:0.00830\teval-logloss:0.08922\n",
      "[134]\ttrain-logloss:0.00827\teval-logloss:0.08918\n",
      "[135]\ttrain-logloss:0.00822\teval-logloss:0.08882\n",
      "[136]\ttrain-logloss:0.00816\teval-logloss:0.08851\n",
      "[137]\ttrain-logloss:0.00808\teval-logloss:0.08848\n",
      "[138]\ttrain-logloss:0.00805\teval-logloss:0.08839\n",
      "[139]\ttrain-logloss:0.00797\teval-logloss:0.08915\n",
      "[140]\ttrain-logloss:0.00795\teval-logloss:0.08911\n",
      "[141]\ttrain-logloss:0.00790\teval-logloss:0.08876\n",
      "[142]\ttrain-logloss:0.00787\teval-logloss:0.08868\n",
      "[143]\ttrain-logloss:0.00785\teval-logloss:0.08839\n",
      "[144]\ttrain-logloss:0.00778\teval-logloss:0.08927\n",
      "[145]\ttrain-logloss:0.00775\teval-logloss:0.08924\n",
      "[146]\ttrain-logloss:0.00773\teval-logloss:0.08914\n",
      "[147]\ttrain-logloss:0.00769\teval-logloss:0.08891\n",
      "[148]\ttrain-logloss:0.00762\teval-logloss:0.08942\n",
      "[149]\ttrain-logloss:0.00760\teval-logloss:0.08939\n",
      "[150]\ttrain-logloss:0.00757\teval-logloss:0.08911\n",
      "[151]\ttrain-logloss:0.00752\teval-logloss:0.08873\n",
      "[152]\ttrain-logloss:0.00750\teval-logloss:0.08872\n",
      "[153]\ttrain-logloss:0.00746\teval-logloss:0.08848\n",
      "[154]\ttrain-logloss:0.00741\teval-logloss:0.08847\n",
      "[155]\ttrain-logloss:0.00739\teval-logloss:0.08855\n",
      "[156]\ttrain-logloss:0.00737\teval-logloss:0.08852\n",
      "[157]\ttrain-logloss:0.00735\teval-logloss:0.08855\n",
      "[158]\ttrain-logloss:0.00732\teval-logloss:0.08827\n",
      "[159]\ttrain-logloss:0.00730\teval-logloss:0.08830\n",
      "[160]\ttrain-logloss:0.00728\teval-logloss:0.08828\n",
      "[161]\ttrain-logloss:0.00726\teval-logloss:0.08801\n",
      "[162]\ttrain-logloss:0.00724\teval-logloss:0.08776\n",
      "[163]\ttrain-logloss:0.00722\teval-logloss:0.08778\n",
      "[164]\ttrain-logloss:0.00720\teval-logloss:0.08778\n",
      "[165]\ttrain-logloss:0.00718\teval-logloss:0.08752\n",
      "[166]\ttrain-logloss:0.00716\teval-logloss:0.08754\n",
      "[167]\ttrain-logloss:0.00714\teval-logloss:0.08764\n",
      "[168]\ttrain-logloss:0.00712\teval-logloss:0.08739\n",
      "[169]\ttrain-logloss:0.00710\teval-logloss:0.08738\n",
      "[170]\ttrain-logloss:0.00708\teval-logloss:0.08730\n",
      "[171]\ttrain-logloss:0.00707\teval-logloss:0.08737\n",
      "[172]\ttrain-logloss:0.00705\teval-logloss:0.08740\n",
      "[173]\ttrain-logloss:0.00703\teval-logloss:0.08739\n",
      "[174]\ttrain-logloss:0.00701\teval-logloss:0.08713\n",
      "[175]\ttrain-logloss:0.00699\teval-logloss:0.08716\n",
      "[176]\ttrain-logloss:0.00697\teval-logloss:0.08695\n",
      "[177]\ttrain-logloss:0.00695\teval-logloss:0.08705\n",
      "[178]\ttrain-logloss:0.00694\teval-logloss:0.08697\n",
      "[179]\ttrain-logloss:0.00692\teval-logloss:0.08697\n",
      "[180]\ttrain-logloss:0.00690\teval-logloss:0.08704\n",
      "[181]\ttrain-logloss:0.00688\teval-logloss:0.08680\n",
      "[182]\ttrain-logloss:0.00687\teval-logloss:0.08683\n",
      "[183]\ttrain-logloss:0.00685\teval-logloss:0.08658\n",
      "[184]\ttrain-logloss:0.00683\teval-logloss:0.08659\n",
      "[185]\ttrain-logloss:0.00681\teval-logloss:0.08661\n",
      "[186]\ttrain-logloss:0.00680\teval-logloss:0.08637\n",
      "[187]\ttrain-logloss:0.00678\teval-logloss:0.08637\n",
      "[188]\ttrain-logloss:0.00676\teval-logloss:0.08630\n",
      "[189]\ttrain-logloss:0.00675\teval-logloss:0.08610\n",
      "[190]\ttrain-logloss:0.00673\teval-logloss:0.08602\n",
      "[191]\ttrain-logloss:0.00671\teval-logloss:0.08605\n",
      "[192]\ttrain-logloss:0.00670\teval-logloss:0.08615\n",
      "[193]\ttrain-logloss:0.00668\teval-logloss:0.08592\n",
      "[194]\ttrain-logloss:0.00667\teval-logloss:0.08591\n",
      "[195]\ttrain-logloss:0.00665\teval-logloss:0.08598\n",
      "[196]\ttrain-logloss:0.00663\teval-logloss:0.08601\n",
      "[197]\ttrain-logloss:0.00662\teval-logloss:0.08592\n",
      "[198]\ttrain-logloss:0.00660\teval-logloss:0.08585\n",
      "[199]\ttrain-logloss:0.00659\teval-logloss:0.08587\n",
      "[200]\ttrain-logloss:0.00657\teval-logloss:0.08589\n",
      "[201]\ttrain-logloss:0.00656\teval-logloss:0.08595\n",
      "[202]\ttrain-logloss:0.00654\teval-logloss:0.08573\n",
      "[203]\ttrain-logloss:0.00653\teval-logloss:0.08573\n",
      "[204]\ttrain-logloss:0.00651\teval-logloss:0.08575\n",
      "[205]\ttrain-logloss:0.00650\teval-logloss:0.08582\n",
      "[206]\ttrain-logloss:0.00648\teval-logloss:0.08584\n",
      "[207]\ttrain-logloss:0.00647\teval-logloss:0.08578\n",
      "[208]\ttrain-logloss:0.00645\teval-logloss:0.08569\n",
      "[209]\ttrain-logloss:0.00644\teval-logloss:0.08571\n",
      "[210]\ttrain-logloss:0.00643\teval-logloss:0.08581\n",
      "[211]\ttrain-logloss:0.00641\teval-logloss:0.08559\n",
      "[212]\ttrain-logloss:0.00640\teval-logloss:0.08580\n",
      "[213]\ttrain-logloss:0.00639\teval-logloss:0.08581\n",
      "[214]\ttrain-logloss:0.00637\teval-logloss:0.08574\n",
      "[215]\ttrain-logloss:0.00636\teval-logloss:0.08566\n",
      "[216]\ttrain-logloss:0.00635\teval-logloss:0.08584\n",
      "[217]\ttrain-logloss:0.00633\teval-logloss:0.08563\n",
      "[218]\ttrain-logloss:0.00632\teval-logloss:0.08573\n",
      "[219]\ttrain-logloss:0.00631\teval-logloss:0.08578\n",
      "[220]\ttrain-logloss:0.00629\teval-logloss:0.08579\n",
      "[221]\ttrain-logloss:0.00628\teval-logloss:0.08582\n",
      "[222]\ttrain-logloss:0.00627\teval-logloss:0.08576\n",
      "[223]\ttrain-logloss:0.00626\teval-logloss:0.08567\n",
      "[224]\ttrain-logloss:0.00624\teval-logloss:0.08586\n",
      "[225]\ttrain-logloss:0.00623\teval-logloss:0.08587\n",
      "[226]\ttrain-logloss:0.00622\teval-logloss:0.08593\n",
      "[227]\ttrain-logloss:0.00621\teval-logloss:0.08595\n",
      "[228]\ttrain-logloss:0.00619\teval-logloss:0.08587\n",
      "[229]\ttrain-logloss:0.00618\teval-logloss:0.08606\n",
      "[230]\ttrain-logloss:0.00617\teval-logloss:0.08600\n",
      "[231]\ttrain-logloss:0.00616\teval-logloss:0.08592\n",
      "[232]\ttrain-logloss:0.00615\teval-logloss:0.08610\n",
      "[233]\ttrain-logloss:0.00614\teval-logloss:0.08611\n",
      "[234]\ttrain-logloss:0.00612\teval-logloss:0.08617\n",
      "[235]\ttrain-logloss:0.00611\teval-logloss:0.08626\n",
      "[236]\ttrain-logloss:0.00610\teval-logloss:0.08629\n",
      "[237]\ttrain-logloss:0.00609\teval-logloss:0.08622\n",
      "[238]\ttrain-logloss:0.00608\teval-logloss:0.08639\n",
      "[239]\ttrain-logloss:0.00607\teval-logloss:0.08634\n",
      "[240]\ttrain-logloss:0.00606\teval-logloss:0.08618\n",
      "[241]\ttrain-logloss:0.00605\teval-logloss:0.08620\n",
      "[242]\ttrain-logloss:0.00604\teval-logloss:0.08625\n",
      "[243]\ttrain-logloss:0.00602\teval-logloss:0.08626\n",
      "[244]\ttrain-logloss:0.00601\teval-logloss:0.08629\n",
      "[245]\ttrain-logloss:0.00600\teval-logloss:0.08622\n",
      "[246]\ttrain-logloss:0.00599\teval-logloss:0.08640\n",
      "[247]\ttrain-logloss:0.00598\teval-logloss:0.08635\n",
      "[248]\ttrain-logloss:0.00597\teval-logloss:0.08628\n",
      "[249]\ttrain-logloss:0.00596\teval-logloss:0.08645\n",
      "[250]\ttrain-logloss:0.00595\teval-logloss:0.08629\n",
      "[251]\ttrain-logloss:0.00594\teval-logloss:0.08631\n",
      "[252]\ttrain-logloss:0.00593\teval-logloss:0.08636\n",
      "[253]\ttrain-logloss:0.00592\teval-logloss:0.08639\n",
      "[254]\ttrain-logloss:0.00591\teval-logloss:0.08649\n",
      "[255]\ttrain-logloss:0.00590\teval-logloss:0.08644\n",
      "[256]\ttrain-logloss:0.00589\teval-logloss:0.08629\n",
      "[257]\ttrain-logloss:0.00588\teval-logloss:0.08646\n",
      "[258]\ttrain-logloss:0.00587\teval-logloss:0.08639\n",
      "[259]\ttrain-logloss:0.00586\teval-logloss:0.08644\n",
      "[260]\ttrain-logloss:0.00585\teval-logloss:0.08646\n",
      "[261]\ttrain-logloss:0.00585\teval-logloss:0.08649\n",
      "[262]\ttrain-logloss:0.00584\teval-logloss:0.08645\n",
      "[263]\ttrain-logloss:0.00583\teval-logloss:0.08647\n",
      "[264]\ttrain-logloss:0.00582\teval-logloss:0.08632\n",
      "[265]\ttrain-logloss:0.00581\teval-logloss:0.08649\n",
      "[266]\ttrain-logloss:0.00580\teval-logloss:0.08654\n",
      "[267]\ttrain-logloss:0.00579\teval-logloss:0.08647\n",
      "[268]\ttrain-logloss:0.00578\teval-logloss:0.08650\n",
      "[269]\ttrain-logloss:0.00577\teval-logloss:0.08652\n",
      "[270]\ttrain-logloss:0.00576\teval-logloss:0.08669\n",
      "[271]\ttrain-logloss:0.00576\teval-logloss:0.08674\n",
      "[272]\ttrain-logloss:0.00575\teval-logloss:0.08683\n",
      "[273]\ttrain-logloss:0.00574\teval-logloss:0.08668\n",
      "[274]\ttrain-logloss:0.00573\teval-logloss:0.08664\n",
      "[275]\ttrain-logloss:0.00572\teval-logloss:0.08650\n",
      "[276]\ttrain-logloss:0.00571\teval-logloss:0.08635\n",
      "[277]\ttrain-logloss:0.00570\teval-logloss:0.08652\n",
      "[278]\ttrain-logloss:0.00570\teval-logloss:0.08657\n",
      "[279]\ttrain-logloss:0.00569\teval-logloss:0.08659\n",
      "[280]\ttrain-logloss:0.00568\teval-logloss:0.08668\n",
      "[281]\ttrain-logloss:0.00567\teval-logloss:0.08664\n",
      "[282]\ttrain-logloss:0.00566\teval-logloss:0.08650\n",
      "[283]\ttrain-logloss:0.00565\teval-logloss:0.08636\n",
      "[284]\ttrain-logloss:0.00565\teval-logloss:0.08640\n",
      "[285]\ttrain-logloss:0.00564\teval-logloss:0.08643\n",
      "[286]\ttrain-logloss:0.00563\teval-logloss:0.08646\n",
      "[287]\ttrain-logloss:0.00562\teval-logloss:0.08650\n",
      "[288]\ttrain-logloss:0.00562\teval-logloss:0.08637\n",
      "[289]\ttrain-logloss:0.00561\teval-logloss:0.08646\n",
      "[290]\ttrain-logloss:0.00560\teval-logloss:0.08645\n",
      "[291]\ttrain-logloss:0.00559\teval-logloss:0.08632\n",
      "[292]\ttrain-logloss:0.00558\teval-logloss:0.08628\n",
      "[293]\ttrain-logloss:0.00558\teval-logloss:0.08615\n",
      "[294]\ttrain-logloss:0.00557\teval-logloss:0.08620\n",
      "[295]\ttrain-logloss:0.00556\teval-logloss:0.08622\n",
      "[296]\ttrain-logloss:0.00556\teval-logloss:0.08631\n",
      "[297]\ttrain-logloss:0.00555\teval-logloss:0.08618\n",
      "[298]\ttrain-logloss:0.00554\teval-logloss:0.08626\n",
      "[299]\ttrain-logloss:0.00553\teval-logloss:0.08613\n",
      "[300]\ttrain-logloss:0.00553\teval-logloss:0.08618\n",
      "[301]\ttrain-logloss:0.00552\teval-logloss:0.08605\n",
      "[302]\ttrain-logloss:0.00551\teval-logloss:0.08602\n",
      "[303]\ttrain-logloss:0.00551\teval-logloss:0.08610\n",
      "[304]\ttrain-logloss:0.00550\teval-logloss:0.08598\n",
      "[305]\ttrain-logloss:0.00549\teval-logloss:0.08606\n",
      "[306]\ttrain-logloss:0.00548\teval-logloss:0.08597\n",
      "[307]\ttrain-logloss:0.00548\teval-logloss:0.08600\n",
      "[308]\ttrain-logloss:0.00547\teval-logloss:0.08600\n",
      "[309]\ttrain-logloss:0.00546\teval-logloss:0.08588\n",
      "[310]\ttrain-logloss:0.00546\teval-logloss:0.08592\n"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.train(params = params, dtrain = dtrain, num_boost_round = num_rounds, \n",
    "                      early_stopping_rounds = 100, evals= eval_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "5UFWSwQp8yA8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict( ) 수행 결과값을 10개만 표시\n",
      "[0.934 0.003 0.91  0.094 0.993 1.    1.    0.999 0.997 0.   ]\n",
      "예측값 10개만 표시: [1, 0, 1, 0, 1, 1, 1, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "pred_probs = xgb_model.predict(dtest)\n",
    "print('predict( ) 수행 결과값을 10개만 표시')\n",
    "print(np.round(pred_probs[:10],3))\n",
    "\n",
    "# 예측 확률이 0.5 보다 크면 1 , 그렇지 않으면 0 으로 예측값 결정하여 List 객체인 preds에 저장\n",
    "preds = [ 1 if x > 0.5 else 0 for x in pred_probs ]\n",
    "print('예측값 10개만 표시:',preds[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mxk9DN5383sp"
   },
   "source": [
    "##**2-e. `get_eval_clf()` 을 통해 예측 평가를 진행해주세요**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "xS27kc1780cD"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "def get_clf_eval(y_test, pred=None, pred_proba=None):\n",
    "    confusion = confusion_matrix( y_test, pred)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    precision = precision_score(y_test , pred)\n",
    "    recall = recall_score(y_test , pred)\n",
    "    f1 = f1_score(y_test,pred)\n",
    "    # ROC-AUC 추가\n",
    "    roc_auc = roc_auc_score(y_test, pred_proba)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    # ROC-AUC print 추가\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\\\n",
    "    F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v-foPK_M82hT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uvg4b6ap9lXg"
   },
   "source": [
    "# **3. LightGBM, HyperOpt**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f8SBYxBJ-vhb"
   },
   "source": [
    "## **3-1. LightGBM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SnRlTMVaIdU6"
   },
   "source": [
    "### **3-1-a. ```water_potability.csv```를 불러와 df에 저장해 주세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "3cg-dfFE-nOx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm==3.3.2\n",
      "  Downloading lightgbm-3.3.2-py3-none-macosx_10_14_x86_64.macosx_10_15_x86_64.macosx_11_0_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 2.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from lightgbm==3.3.2) (0.36.2)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from lightgbm==3.3.2) (1.26.0)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from lightgbm==3.3.2) (1.3.1)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from lightgbm==3.3.2) (1.11.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from scikit-learn!=0.22.0->lightgbm==3.3.2) (3.2.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from scikit-learn!=0.22.0->lightgbm==3.3.2) (1.3.2)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-3.3.2\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.9/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'lightgbm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 3.3.2 버전으로 LightGBM을 설치합니다(일부 파라미터가 4.0.0에선 작동하지 않아서 넣었습니다.)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install lightgbm==3.3.2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(lightgbm\u001b[38;5;241m.\u001b[39m__version__)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lightgbm' is not defined"
     ]
    }
   ],
   "source": [
    "# 3.3.2 버전으로 LightGBM을 설치합니다(일부 파라미터가 4.0.0에선 작동하지 않아서 넣었습니다.)\n",
    "\n",
    "!pip install lightgbm==3.3.2\n",
    "print(lightgbm.__version__) # 버전 확인용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "ZcpuDJ8GIoBD"
   },
   "outputs": [],
   "source": [
    "import lightgbm\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "z3XVGeXr-_kt"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ph</th>\n",
       "      <th>Hardness</th>\n",
       "      <th>Solids</th>\n",
       "      <th>Chloramines</th>\n",
       "      <th>Sulfate</th>\n",
       "      <th>Conductivity</th>\n",
       "      <th>Organic_carbon</th>\n",
       "      <th>Trihalomethanes</th>\n",
       "      <th>Turbidity</th>\n",
       "      <th>Potability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>204.890455</td>\n",
       "      <td>20791.318981</td>\n",
       "      <td>7.300212</td>\n",
       "      <td>368.516441</td>\n",
       "      <td>564.308654</td>\n",
       "      <td>10.379783</td>\n",
       "      <td>86.990970</td>\n",
       "      <td>2.963135</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.716080</td>\n",
       "      <td>129.422921</td>\n",
       "      <td>18630.057858</td>\n",
       "      <td>6.635246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>592.885359</td>\n",
       "      <td>15.180013</td>\n",
       "      <td>56.329076</td>\n",
       "      <td>4.500656</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.099124</td>\n",
       "      <td>224.236259</td>\n",
       "      <td>19909.541732</td>\n",
       "      <td>9.275884</td>\n",
       "      <td>NaN</td>\n",
       "      <td>418.606213</td>\n",
       "      <td>16.868637</td>\n",
       "      <td>66.420093</td>\n",
       "      <td>3.055934</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.316766</td>\n",
       "      <td>214.373394</td>\n",
       "      <td>22018.417441</td>\n",
       "      <td>8.059332</td>\n",
       "      <td>356.886136</td>\n",
       "      <td>363.266516</td>\n",
       "      <td>18.436524</td>\n",
       "      <td>100.341674</td>\n",
       "      <td>4.628771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.092223</td>\n",
       "      <td>181.101509</td>\n",
       "      <td>17978.986339</td>\n",
       "      <td>6.546600</td>\n",
       "      <td>310.135738</td>\n",
       "      <td>398.410813</td>\n",
       "      <td>11.558279</td>\n",
       "      <td>31.997993</td>\n",
       "      <td>4.075075</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ph    Hardness        Solids  Chloramines     Sulfate  Conductivity  \\\n",
       "0       NaN  204.890455  20791.318981     7.300212  368.516441    564.308654   \n",
       "1  3.716080  129.422921  18630.057858     6.635246         NaN    592.885359   \n",
       "2  8.099124  224.236259  19909.541732     9.275884         NaN    418.606213   \n",
       "3  8.316766  214.373394  22018.417441     8.059332  356.886136    363.266516   \n",
       "4  9.092223  181.101509  17978.986339     6.546600  310.135738    398.410813   \n",
       "\n",
       "   Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
       "0       10.379783        86.990970   2.963135           0  \n",
       "1       15.180013        56.329076   4.500656           0  \n",
       "2       16.868637        66.420093   3.055934           0  \n",
       "3       18.436524       100.341674   4.628771           0  \n",
       "4       11.558279        31.997993   4.075075           0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =pd.read_csv(\"./water_potability.csv\")\n",
    "\n",
    "# 데이터 확인\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cXSVbYeI_DGz"
   },
   "source": [
    "### **3-1-b. 이럴수가! 결측값이 있는 것 같네요! 아래의 코드를 실행시켜 어느 변수에 결측값이 있는지 확인하고, 결측값들은 모두 해당하는 변수의 평균으로 바꿔주세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "r4nKg2mF_FHE"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ph                 491\n",
       "Hardness             0\n",
       "Solids               0\n",
       "Chloramines          0\n",
       "Sulfate            781\n",
       "Conductivity         0\n",
       "Organic_carbon       0\n",
       "Trihalomethanes    162\n",
       "Turbidity            0\n",
       "Potability           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "I3Iq_aHA_XUi"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ph</th>\n",
       "      <th>Hardness</th>\n",
       "      <th>Solids</th>\n",
       "      <th>Chloramines</th>\n",
       "      <th>Sulfate</th>\n",
       "      <th>Conductivity</th>\n",
       "      <th>Organic_carbon</th>\n",
       "      <th>Trihalomethanes</th>\n",
       "      <th>Turbidity</th>\n",
       "      <th>Potability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.080795</td>\n",
       "      <td>204.890455</td>\n",
       "      <td>20791.318981</td>\n",
       "      <td>7.300212</td>\n",
       "      <td>368.516441</td>\n",
       "      <td>564.308654</td>\n",
       "      <td>10.379783</td>\n",
       "      <td>86.990970</td>\n",
       "      <td>2.963135</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.716080</td>\n",
       "      <td>129.422921</td>\n",
       "      <td>18630.057858</td>\n",
       "      <td>6.635246</td>\n",
       "      <td>333.775777</td>\n",
       "      <td>592.885359</td>\n",
       "      <td>15.180013</td>\n",
       "      <td>56.329076</td>\n",
       "      <td>4.500656</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.099124</td>\n",
       "      <td>224.236259</td>\n",
       "      <td>19909.541732</td>\n",
       "      <td>9.275884</td>\n",
       "      <td>333.775777</td>\n",
       "      <td>418.606213</td>\n",
       "      <td>16.868637</td>\n",
       "      <td>66.420093</td>\n",
       "      <td>3.055934</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.316766</td>\n",
       "      <td>214.373394</td>\n",
       "      <td>22018.417441</td>\n",
       "      <td>8.059332</td>\n",
       "      <td>356.886136</td>\n",
       "      <td>363.266516</td>\n",
       "      <td>18.436524</td>\n",
       "      <td>100.341674</td>\n",
       "      <td>4.628771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.092223</td>\n",
       "      <td>181.101509</td>\n",
       "      <td>17978.986339</td>\n",
       "      <td>6.546600</td>\n",
       "      <td>310.135738</td>\n",
       "      <td>398.410813</td>\n",
       "      <td>11.558279</td>\n",
       "      <td>31.997993</td>\n",
       "      <td>4.075075</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ph    Hardness        Solids  Chloramines     Sulfate  Conductivity  \\\n",
       "0  7.080795  204.890455  20791.318981     7.300212  368.516441    564.308654   \n",
       "1  3.716080  129.422921  18630.057858     6.635246  333.775777    592.885359   \n",
       "2  8.099124  224.236259  19909.541732     9.275884  333.775777    418.606213   \n",
       "3  8.316766  214.373394  22018.417441     8.059332  356.886136    363.266516   \n",
       "4  9.092223  181.101509  17978.986339     6.546600  310.135738    398.410813   \n",
       "\n",
       "   Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
       "0       10.379783        86.990970   2.963135           0  \n",
       "1       15.180013        56.329076   4.500656           0  \n",
       "2       16.868637        66.420093   3.055934           0  \n",
       "3       18.436524       100.341674   4.628771           0  \n",
       "4       11.558279        31.997993   4.075075           0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 결측값을 해당 칼럼의 평균값으로 대체해 주세요.\n",
    "# 힌트: 파머완 138페이지\n",
    "df['ph'].fillna(df['ph'].mean(), inplace=True)\n",
    "df['Sulfate'].fillna(df['Sulfate'].mean(), inplace=True)\n",
    "df['Trihalomethanes'].fillna(df['Trihalomethanes'].mean(), inplace=True)\n",
    "\n",
    "# 데이터 확인\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OyXaOw0X_aXZ"
   },
   "source": [
    "### **3-1-c. df를 학습용 데이터와 테스트용 데이터로 분리해 주세요.**  \n",
    "(random_state = 42, 학습용 데이터가 전체의 **80%**를 차지하도록 설정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "oWbfGB4c_Znx"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hW1x8hQI_krM"
   },
   "source": [
    "### **3-1-d. 위에서 만든 X_train, y_train을 다시 나누어 90%는 학습용으로, 10%는 검증용 데이터로 분리해 주세요.**  \n",
    "(random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "QPuPw7bb_qF8"
   },
   "outputs": [],
   "source": [
    "X_tr, X_val, y_tr, y_val =train_test_split(X, y, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hEyCPkHZ_tYC"
   },
   "source": [
    "### **3-1-e. 다음 조건에 따라 LGBMClassifier을 생성한 후 ```lgbm_wrapper```에 저장해 주세요.**\n",
    "- 반복 수행할 트리 개수: 800개\n",
    "- 학습률: 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "4gPkmQo3_zlS"
   },
   "outputs": [],
   "source": [
    "lgbm_wrapper =LGBMClassifier(n_estimators = 800, learning_rate = 0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "unGn5aOi_2LG"
   },
   "source": [
    "### **3-1-f. `lgbm_wrapper`가 100번 학습을 반복해도 성능이 향상되지 않으면 수행을 멈추도록 설정해서 학습시키세요.**\n",
    "- 평가 지표: logloss  \n",
    "\n",
    "(❓❓❓❓❓로 표시된 빈칸을 채워주세요!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "89l5qcaB_6QV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.66618\tvalid_1's binary_logloss: 0.661381\n",
      "[2]\ttraining's binary_logloss: 0.663092\tvalid_1's binary_logloss: 0.65973\n",
      "[3]\ttraining's binary_logloss: 0.660144\tvalid_1's binary_logloss: 0.657942\n",
      "[4]\ttraining's binary_logloss: 0.657235\tvalid_1's binary_logloss: 0.656411\n",
      "[5]\ttraining's binary_logloss: 0.654502\tvalid_1's binary_logloss: 0.654895\n",
      "[6]\ttraining's binary_logloss: 0.651832\tvalid_1's binary_logloss: 0.653202\n",
      "[7]\ttraining's binary_logloss: 0.649611\tvalid_1's binary_logloss: 0.652132\n",
      "[8]\ttraining's binary_logloss: 0.647115\tvalid_1's binary_logloss: 0.650527\n",
      "[9]\ttraining's binary_logloss: 0.645024\tvalid_1's binary_logloss: 0.649433\n",
      "[10]\ttraining's binary_logloss: 0.642518\tvalid_1's binary_logloss: 0.648178\n",
      "[11]\ttraining's binary_logloss: 0.640507\tvalid_1's binary_logloss: 0.646932\n",
      "[12]\ttraining's binary_logloss: 0.638489\tvalid_1's binary_logloss: 0.645678\n",
      "[13]\ttraining's binary_logloss: 0.636443\tvalid_1's binary_logloss: 0.644394\n",
      "[14]\ttraining's binary_logloss: 0.634248\tvalid_1's binary_logloss: 0.643383\n",
      "[15]\ttraining's binary_logloss: 0.632346\tvalid_1's binary_logloss: 0.642087\n",
      "[16]\ttraining's binary_logloss: 0.630409\tvalid_1's binary_logloss: 0.640677\n",
      "[17]\ttraining's binary_logloss: 0.628557\tvalid_1's binary_logloss: 0.639492\n",
      "[18]\ttraining's binary_logloss: 0.626769\tvalid_1's binary_logloss: 0.638225\n",
      "[19]\ttraining's binary_logloss: 0.624727\tvalid_1's binary_logloss: 0.63686\n",
      "[20]\ttraining's binary_logloss: 0.623031\tvalid_1's binary_logloss: 0.635852\n",
      "[21]\ttraining's binary_logloss: 0.621202\tvalid_1's binary_logloss: 0.634884\n",
      "[22]\ttraining's binary_logloss: 0.619388\tvalid_1's binary_logloss: 0.633848\n",
      "[23]\ttraining's binary_logloss: 0.617576\tvalid_1's binary_logloss: 0.633005\n",
      "[24]\ttraining's binary_logloss: 0.615937\tvalid_1's binary_logloss: 0.632044\n",
      "[25]\ttraining's binary_logloss: 0.614034\tvalid_1's binary_logloss: 0.631032\n",
      "[26]\ttraining's binary_logloss: 0.612497\tvalid_1's binary_logloss: 0.630171\n",
      "[27]\ttraining's binary_logloss: 0.610882\tvalid_1's binary_logloss: 0.629261\n",
      "[28]\ttraining's binary_logloss: 0.608915\tvalid_1's binary_logloss: 0.628426\n",
      "[29]\ttraining's binary_logloss: 0.607143\tvalid_1's binary_logloss: 0.627556\n",
      "[30]\ttraining's binary_logloss: 0.605468\tvalid_1's binary_logloss: 0.627224\n",
      "[31]\ttraining's binary_logloss: 0.603792\tvalid_1's binary_logloss: 0.626769\n",
      "[32]\ttraining's binary_logloss: 0.601686\tvalid_1's binary_logloss: 0.625882\n",
      "[33]\ttraining's binary_logloss: 0.600013\tvalid_1's binary_logloss: 0.625236\n",
      "[34]\ttraining's binary_logloss: 0.598572\tvalid_1's binary_logloss: 0.625056\n",
      "[35]\ttraining's binary_logloss: 0.596457\tvalid_1's binary_logloss: 0.624237\n",
      "[36]\ttraining's binary_logloss: 0.594642\tvalid_1's binary_logloss: 0.623493\n",
      "[37]\ttraining's binary_logloss: 0.592675\tvalid_1's binary_logloss: 0.622736\n",
      "[38]\ttraining's binary_logloss: 0.590934\tvalid_1's binary_logloss: 0.622324\n",
      "[39]\ttraining's binary_logloss: 0.589086\tvalid_1's binary_logloss: 0.621773\n",
      "[40]\ttraining's binary_logloss: 0.58747\tvalid_1's binary_logloss: 0.62123\n",
      "[41]\ttraining's binary_logloss: 0.585739\tvalid_1's binary_logloss: 0.620769\n",
      "[42]\ttraining's binary_logloss: 0.584144\tvalid_1's binary_logloss: 0.62048\n",
      "[43]\ttraining's binary_logloss: 0.58235\tvalid_1's binary_logloss: 0.619555\n",
      "[44]\ttraining's binary_logloss: 0.581004\tvalid_1's binary_logloss: 0.61909\n",
      "[45]\ttraining's binary_logloss: 0.579737\tvalid_1's binary_logloss: 0.618235\n",
      "[46]\ttraining's binary_logloss: 0.578166\tvalid_1's binary_logloss: 0.617707\n",
      "[47]\ttraining's binary_logloss: 0.576878\tvalid_1's binary_logloss: 0.61749\n",
      "[48]\ttraining's binary_logloss: 0.575664\tvalid_1's binary_logloss: 0.616786\n",
      "[49]\ttraining's binary_logloss: 0.574137\tvalid_1's binary_logloss: 0.616391\n",
      "[50]\ttraining's binary_logloss: 0.572903\tvalid_1's binary_logloss: 0.616014\n",
      "[51]\ttraining's binary_logloss: 0.571291\tvalid_1's binary_logloss: 0.615476\n",
      "[52]\ttraining's binary_logloss: 0.570064\tvalid_1's binary_logloss: 0.615075\n",
      "[53]\ttraining's binary_logloss: 0.568843\tvalid_1's binary_logloss: 0.614496\n",
      "[54]\ttraining's binary_logloss: 0.567757\tvalid_1's binary_logloss: 0.614097\n",
      "[55]\ttraining's binary_logloss: 0.56665\tvalid_1's binary_logloss: 0.613706\n",
      "[56]\ttraining's binary_logloss: 0.565629\tvalid_1's binary_logloss: 0.613209\n",
      "[57]\ttraining's binary_logloss: 0.564479\tvalid_1's binary_logloss: 0.612633\n",
      "[58]\ttraining's binary_logloss: 0.563106\tvalid_1's binary_logloss: 0.612302\n",
      "[59]\ttraining's binary_logloss: 0.561998\tvalid_1's binary_logloss: 0.611882\n",
      "[60]\ttraining's binary_logloss: 0.560945\tvalid_1's binary_logloss: 0.611219\n",
      "[61]\ttraining's binary_logloss: 0.559948\tvalid_1's binary_logloss: 0.611091\n",
      "[62]\ttraining's binary_logloss: 0.558766\tvalid_1's binary_logloss: 0.611086\n",
      "[63]\ttraining's binary_logloss: 0.557695\tvalid_1's binary_logloss: 0.610436\n",
      "[64]\ttraining's binary_logloss: 0.556779\tvalid_1's binary_logloss: 0.61034\n",
      "[65]\ttraining's binary_logloss: 0.555654\tvalid_1's binary_logloss: 0.610336\n",
      "[66]\ttraining's binary_logloss: 0.5543\tvalid_1's binary_logloss: 0.609461\n",
      "[67]\ttraining's binary_logloss: 0.553044\tvalid_1's binary_logloss: 0.609246\n",
      "[68]\ttraining's binary_logloss: 0.552082\tvalid_1's binary_logloss: 0.609103\n",
      "[69]\ttraining's binary_logloss: 0.551055\tvalid_1's binary_logloss: 0.60886\n",
      "[70]\ttraining's binary_logloss: 0.549776\tvalid_1's binary_logloss: 0.608309\n",
      "[71]\ttraining's binary_logloss: 0.548754\tvalid_1's binary_logloss: 0.608036\n",
      "[72]\ttraining's binary_logloss: 0.547758\tvalid_1's binary_logloss: 0.607537\n",
      "[73]\ttraining's binary_logloss: 0.5467\tvalid_1's binary_logloss: 0.607188\n",
      "[74]\ttraining's binary_logloss: 0.545732\tvalid_1's binary_logloss: 0.606564\n",
      "[75]\ttraining's binary_logloss: 0.544702\tvalid_1's binary_logloss: 0.605776\n",
      "[76]\ttraining's binary_logloss: 0.543667\tvalid_1's binary_logloss: 0.605134\n",
      "[77]\ttraining's binary_logloss: 0.542712\tvalid_1's binary_logloss: 0.604834\n",
      "[78]\ttraining's binary_logloss: 0.541738\tvalid_1's binary_logloss: 0.60454\n",
      "[79]\ttraining's binary_logloss: 0.540827\tvalid_1's binary_logloss: 0.604382\n",
      "[80]\ttraining's binary_logloss: 0.539689\tvalid_1's binary_logloss: 0.604047\n",
      "[81]\ttraining's binary_logloss: 0.538579\tvalid_1's binary_logloss: 0.603737\n",
      "[82]\ttraining's binary_logloss: 0.53768\tvalid_1's binary_logloss: 0.603356\n",
      "[83]\ttraining's binary_logloss: 0.536292\tvalid_1's binary_logloss: 0.602488\n",
      "[84]\ttraining's binary_logloss: 0.535147\tvalid_1's binary_logloss: 0.602382\n",
      "[85]\ttraining's binary_logloss: 0.534022\tvalid_1's binary_logloss: 0.601446\n",
      "[86]\ttraining's binary_logloss: 0.532877\tvalid_1's binary_logloss: 0.601217\n",
      "[87]\ttraining's binary_logloss: 0.531791\tvalid_1's binary_logloss: 0.601159\n",
      "[88]\ttraining's binary_logloss: 0.530675\tvalid_1's binary_logloss: 0.600532\n",
      "[89]\ttraining's binary_logloss: 0.529744\tvalid_1's binary_logloss: 0.600371\n",
      "[90]\ttraining's binary_logloss: 0.528706\tvalid_1's binary_logloss: 0.600165\n",
      "[91]\ttraining's binary_logloss: 0.527708\tvalid_1's binary_logloss: 0.600116\n",
      "[92]\ttraining's binary_logloss: 0.526536\tvalid_1's binary_logloss: 0.599396\n",
      "[93]\ttraining's binary_logloss: 0.525628\tvalid_1's binary_logloss: 0.599294\n",
      "[94]\ttraining's binary_logloss: 0.524652\tvalid_1's binary_logloss: 0.599321\n",
      "[95]\ttraining's binary_logloss: 0.523756\tvalid_1's binary_logloss: 0.599068\n",
      "[96]\ttraining's binary_logloss: 0.52276\tvalid_1's binary_logloss: 0.599166\n",
      "[97]\ttraining's binary_logloss: 0.52201\tvalid_1's binary_logloss: 0.599054\n",
      "[98]\ttraining's binary_logloss: 0.521043\tvalid_1's binary_logloss: 0.599028\n",
      "[99]\ttraining's binary_logloss: 0.520054\tvalid_1's binary_logloss: 0.598732\n",
      "[100]\ttraining's binary_logloss: 0.519283\tvalid_1's binary_logloss: 0.598239\n",
      "[101]\ttraining's binary_logloss: 0.518235\tvalid_1's binary_logloss: 0.597904\n",
      "[102]\ttraining's binary_logloss: 0.517286\tvalid_1's binary_logloss: 0.597845\n",
      "[103]\ttraining's binary_logloss: 0.516486\tvalid_1's binary_logloss: 0.597957\n",
      "[104]\ttraining's binary_logloss: 0.515519\tvalid_1's binary_logloss: 0.597941\n",
      "[105]\ttraining's binary_logloss: 0.514626\tvalid_1's binary_logloss: 0.597985\n",
      "[106]\ttraining's binary_logloss: 0.513866\tvalid_1's binary_logloss: 0.598116\n",
      "[107]\ttraining's binary_logloss: 0.512577\tvalid_1's binary_logloss: 0.597536\n",
      "[108]\ttraining's binary_logloss: 0.511655\tvalid_1's binary_logloss: 0.59754\n",
      "[109]\ttraining's binary_logloss: 0.510863\tvalid_1's binary_logloss: 0.597664\n",
      "[110]\ttraining's binary_logloss: 0.509824\tvalid_1's binary_logloss: 0.597453\n",
      "[111]\ttraining's binary_logloss: 0.508981\tvalid_1's binary_logloss: 0.597604\n",
      "[112]\ttraining's binary_logloss: 0.508118\tvalid_1's binary_logloss: 0.597558\n",
      "[113]\ttraining's binary_logloss: 0.507088\tvalid_1's binary_logloss: 0.597326\n",
      "[114]\ttraining's binary_logloss: 0.506154\tvalid_1's binary_logloss: 0.596932\n",
      "[115]\ttraining's binary_logloss: 0.50542\tvalid_1's binary_logloss: 0.596594\n",
      "[116]\ttraining's binary_logloss: 0.504716\tvalid_1's binary_logloss: 0.596109\n",
      "[117]\ttraining's binary_logloss: 0.503963\tvalid_1's binary_logloss: 0.59609\n",
      "[118]\ttraining's binary_logloss: 0.503119\tvalid_1's binary_logloss: 0.596019\n",
      "[119]\ttraining's binary_logloss: 0.502361\tvalid_1's binary_logloss: 0.595794\n",
      "[120]\ttraining's binary_logloss: 0.501662\tvalid_1's binary_logloss: 0.596115\n",
      "[121]\ttraining's binary_logloss: 0.501001\tvalid_1's binary_logloss: 0.595862\n",
      "[122]\ttraining's binary_logloss: 0.500314\tvalid_1's binary_logloss: 0.595817\n",
      "[123]\ttraining's binary_logloss: 0.499575\tvalid_1's binary_logloss: 0.59562\n",
      "[124]\ttraining's binary_logloss: 0.498912\tvalid_1's binary_logloss: 0.595166\n",
      "[125]\ttraining's binary_logloss: 0.498175\tvalid_1's binary_logloss: 0.594874\n",
      "[126]\ttraining's binary_logloss: 0.497341\tvalid_1's binary_logloss: 0.594509\n",
      "[127]\ttraining's binary_logloss: 0.496701\tvalid_1's binary_logloss: 0.594396\n",
      "[128]\ttraining's binary_logloss: 0.495858\tvalid_1's binary_logloss: 0.594573\n",
      "[129]\ttraining's binary_logloss: 0.494725\tvalid_1's binary_logloss: 0.59426\n",
      "[130]\ttraining's binary_logloss: 0.493974\tvalid_1's binary_logloss: 0.594008\n",
      "[131]\ttraining's binary_logloss: 0.493311\tvalid_1's binary_logloss: 0.594042\n",
      "[132]\ttraining's binary_logloss: 0.4925\tvalid_1's binary_logloss: 0.59422\n",
      "[133]\ttraining's binary_logloss: 0.491798\tvalid_1's binary_logloss: 0.593912\n",
      "[134]\ttraining's binary_logloss: 0.491136\tvalid_1's binary_logloss: 0.593738\n",
      "[135]\ttraining's binary_logloss: 0.490445\tvalid_1's binary_logloss: 0.593893\n",
      "[136]\ttraining's binary_logloss: 0.48969\tvalid_1's binary_logloss: 0.593945\n",
      "[137]\ttraining's binary_logloss: 0.488727\tvalid_1's binary_logloss: 0.593778\n",
      "[138]\ttraining's binary_logloss: 0.488106\tvalid_1's binary_logloss: 0.59368\n",
      "[139]\ttraining's binary_logloss: 0.487301\tvalid_1's binary_logloss: 0.593453\n",
      "[140]\ttraining's binary_logloss: 0.486726\tvalid_1's binary_logloss: 0.59309\n",
      "[141]\ttraining's binary_logloss: 0.485859\tvalid_1's binary_logloss: 0.592637\n",
      "[142]\ttraining's binary_logloss: 0.485186\tvalid_1's binary_logloss: 0.592375\n",
      "[143]\ttraining's binary_logloss: 0.484216\tvalid_1's binary_logloss: 0.592063\n",
      "[144]\ttraining's binary_logloss: 0.483504\tvalid_1's binary_logloss: 0.592049\n",
      "[145]\ttraining's binary_logloss: 0.482854\tvalid_1's binary_logloss: 0.591802\n",
      "[146]\ttraining's binary_logloss: 0.48217\tvalid_1's binary_logloss: 0.592011\n",
      "[147]\ttraining's binary_logloss: 0.481441\tvalid_1's binary_logloss: 0.591837\n",
      "[148]\ttraining's binary_logloss: 0.480814\tvalid_1's binary_logloss: 0.591476\n",
      "[149]\ttraining's binary_logloss: 0.48019\tvalid_1's binary_logloss: 0.59161\n",
      "[150]\ttraining's binary_logloss: 0.479578\tvalid_1's binary_logloss: 0.591688\n",
      "[151]\ttraining's binary_logloss: 0.478887\tvalid_1's binary_logloss: 0.591459\n",
      "[152]\ttraining's binary_logloss: 0.478174\tvalid_1's binary_logloss: 0.591411\n",
      "[153]\ttraining's binary_logloss: 0.477506\tvalid_1's binary_logloss: 0.591743\n",
      "[154]\ttraining's binary_logloss: 0.476833\tvalid_1's binary_logloss: 0.591652\n",
      "[155]\ttraining's binary_logloss: 0.476219\tvalid_1's binary_logloss: 0.591798\n",
      "[156]\ttraining's binary_logloss: 0.475582\tvalid_1's binary_logloss: 0.59184\n",
      "[157]\ttraining's binary_logloss: 0.474976\tvalid_1's binary_logloss: 0.591779\n",
      "[158]\ttraining's binary_logloss: 0.474463\tvalid_1's binary_logloss: 0.591801\n",
      "[159]\ttraining's binary_logloss: 0.473686\tvalid_1's binary_logloss: 0.591627\n",
      "[160]\ttraining's binary_logloss: 0.473059\tvalid_1's binary_logloss: 0.591746\n",
      "[161]\ttraining's binary_logloss: 0.472451\tvalid_1's binary_logloss: 0.591803\n",
      "[162]\ttraining's binary_logloss: 0.471862\tvalid_1's binary_logloss: 0.591902\n",
      "[163]\ttraining's binary_logloss: 0.471235\tvalid_1's binary_logloss: 0.592017\n",
      "[164]\ttraining's binary_logloss: 0.470571\tvalid_1's binary_logloss: 0.591658\n",
      "[165]\ttraining's binary_logloss: 0.469732\tvalid_1's binary_logloss: 0.591713\n",
      "[166]\ttraining's binary_logloss: 0.469027\tvalid_1's binary_logloss: 0.591213\n",
      "[167]\ttraining's binary_logloss: 0.468081\tvalid_1's binary_logloss: 0.590823\n",
      "[168]\ttraining's binary_logloss: 0.467296\tvalid_1's binary_logloss: 0.59074\n",
      "[169]\ttraining's binary_logloss: 0.466708\tvalid_1's binary_logloss: 0.590814\n",
      "[170]\ttraining's binary_logloss: 0.466078\tvalid_1's binary_logloss: 0.591031\n",
      "[171]\ttraining's binary_logloss: 0.46518\tvalid_1's binary_logloss: 0.590842\n",
      "[172]\ttraining's binary_logloss: 0.464364\tvalid_1's binary_logloss: 0.590985\n",
      "[173]\ttraining's binary_logloss: 0.463665\tvalid_1's binary_logloss: 0.590905\n",
      "[174]\ttraining's binary_logloss: 0.463085\tvalid_1's binary_logloss: 0.591107\n",
      "[175]\ttraining's binary_logloss: 0.462302\tvalid_1's binary_logloss: 0.591192\n",
      "[176]\ttraining's binary_logloss: 0.461661\tvalid_1's binary_logloss: 0.591\n",
      "[177]\ttraining's binary_logloss: 0.461129\tvalid_1's binary_logloss: 0.590755\n",
      "[178]\ttraining's binary_logloss: 0.460416\tvalid_1's binary_logloss: 0.590859\n",
      "[179]\ttraining's binary_logloss: 0.459825\tvalid_1's binary_logloss: 0.590818\n",
      "[180]\ttraining's binary_logloss: 0.458944\tvalid_1's binary_logloss: 0.590598\n",
      "[181]\ttraining's binary_logloss: 0.458389\tvalid_1's binary_logloss: 0.590796\n",
      "[182]\ttraining's binary_logloss: 0.457566\tvalid_1's binary_logloss: 0.590749\n",
      "[183]\ttraining's binary_logloss: 0.456859\tvalid_1's binary_logloss: 0.590683\n",
      "[184]\ttraining's binary_logloss: 0.456167\tvalid_1's binary_logloss: 0.590871\n",
      "[185]\ttraining's binary_logloss: 0.455604\tvalid_1's binary_logloss: 0.590923\n",
      "[186]\ttraining's binary_logloss: 0.455027\tvalid_1's binary_logloss: 0.590853\n",
      "[187]\ttraining's binary_logloss: 0.454427\tvalid_1's binary_logloss: 0.590725\n",
      "[188]\ttraining's binary_logloss: 0.453838\tvalid_1's binary_logloss: 0.590871\n",
      "[189]\ttraining's binary_logloss: 0.453154\tvalid_1's binary_logloss: 0.59085\n",
      "[190]\ttraining's binary_logloss: 0.452334\tvalid_1's binary_logloss: 0.590704\n",
      "[191]\ttraining's binary_logloss: 0.451795\tvalid_1's binary_logloss: 0.590909\n",
      "[192]\ttraining's binary_logloss: 0.451\tvalid_1's binary_logloss: 0.590956\n",
      "[193]\ttraining's binary_logloss: 0.450362\tvalid_1's binary_logloss: 0.591125\n",
      "[194]\ttraining's binary_logloss: 0.449796\tvalid_1's binary_logloss: 0.590968\n",
      "[195]\ttraining's binary_logloss: 0.449116\tvalid_1's binary_logloss: 0.590916\n",
      "[196]\ttraining's binary_logloss: 0.448397\tvalid_1's binary_logloss: 0.590761\n",
      "[197]\ttraining's binary_logloss: 0.447843\tvalid_1's binary_logloss: 0.59096\n",
      "[198]\ttraining's binary_logloss: 0.447278\tvalid_1's binary_logloss: 0.590454\n",
      "[199]\ttraining's binary_logloss: 0.446681\tvalid_1's binary_logloss: 0.590422\n",
      "[200]\ttraining's binary_logloss: 0.446119\tvalid_1's binary_logloss: 0.590526\n",
      "[201]\ttraining's binary_logloss: 0.445543\tvalid_1's binary_logloss: 0.590508\n",
      "[202]\ttraining's binary_logloss: 0.445011\tvalid_1's binary_logloss: 0.590442\n",
      "[203]\ttraining's binary_logloss: 0.444458\tvalid_1's binary_logloss: 0.590436\n",
      "[204]\ttraining's binary_logloss: 0.44387\tvalid_1's binary_logloss: 0.590591\n",
      "[205]\ttraining's binary_logloss: 0.443322\tvalid_1's binary_logloss: 0.590588\n",
      "[206]\ttraining's binary_logloss: 0.442654\tvalid_1's binary_logloss: 0.590489\n",
      "[207]\ttraining's binary_logloss: 0.442112\tvalid_1's binary_logloss: 0.590766\n",
      "[208]\ttraining's binary_logloss: 0.441565\tvalid_1's binary_logloss: 0.590603\n",
      "[209]\ttraining's binary_logloss: 0.440734\tvalid_1's binary_logloss: 0.590744\n",
      "[210]\ttraining's binary_logloss: 0.440232\tvalid_1's binary_logloss: 0.590524\n",
      "[211]\ttraining's binary_logloss: 0.439431\tvalid_1's binary_logloss: 0.590632\n",
      "[212]\ttraining's binary_logloss: 0.438915\tvalid_1's binary_logloss: 0.59069\n",
      "[213]\ttraining's binary_logloss: 0.43837\tvalid_1's binary_logloss: 0.590387\n",
      "[214]\ttraining's binary_logloss: 0.437774\tvalid_1's binary_logloss: 0.590296\n",
      "[215]\ttraining's binary_logloss: 0.43732\tvalid_1's binary_logloss: 0.590116\n",
      "[216]\ttraining's binary_logloss: 0.436481\tvalid_1's binary_logloss: 0.590281\n",
      "[217]\ttraining's binary_logloss: 0.43603\tvalid_1's binary_logloss: 0.589965\n",
      "[218]\ttraining's binary_logloss: 0.435538\tvalid_1's binary_logloss: 0.590033\n",
      "[219]\ttraining's binary_logloss: 0.435004\tvalid_1's binary_logloss: 0.58994\n",
      "[220]\ttraining's binary_logloss: 0.434208\tvalid_1's binary_logloss: 0.589634\n",
      "[221]\ttraining's binary_logloss: 0.433443\tvalid_1's binary_logloss: 0.589087\n",
      "[222]\ttraining's binary_logloss: 0.432926\tvalid_1's binary_logloss: 0.589396\n",
      "[223]\ttraining's binary_logloss: 0.432362\tvalid_1's binary_logloss: 0.589143\n",
      "[224]\ttraining's binary_logloss: 0.431896\tvalid_1's binary_logloss: 0.589187\n",
      "[225]\ttraining's binary_logloss: 0.431389\tvalid_1's binary_logloss: 0.589109\n",
      "[226]\ttraining's binary_logloss: 0.430622\tvalid_1's binary_logloss: 0.589109\n",
      "[227]\ttraining's binary_logloss: 0.430095\tvalid_1's binary_logloss: 0.589417\n",
      "[228]\ttraining's binary_logloss: 0.429515\tvalid_1's binary_logloss: 0.589314\n",
      "[229]\ttraining's binary_logloss: 0.428889\tvalid_1's binary_logloss: 0.589543\n",
      "[230]\ttraining's binary_logloss: 0.428369\tvalid_1's binary_logloss: 0.589202\n",
      "[231]\ttraining's binary_logloss: 0.427617\tvalid_1's binary_logloss: 0.589123\n",
      "[232]\ttraining's binary_logloss: 0.427098\tvalid_1's binary_logloss: 0.589138\n",
      "[233]\ttraining's binary_logloss: 0.426469\tvalid_1's binary_logloss: 0.588948\n",
      "[234]\ttraining's binary_logloss: 0.425874\tvalid_1's binary_logloss: 0.588734\n",
      "[235]\ttraining's binary_logloss: 0.42518\tvalid_1's binary_logloss: 0.58878\n",
      "[236]\ttraining's binary_logloss: 0.424334\tvalid_1's binary_logloss: 0.588444\n",
      "[237]\ttraining's binary_logloss: 0.423714\tvalid_1's binary_logloss: 0.58802\n",
      "[238]\ttraining's binary_logloss: 0.422938\tvalid_1's binary_logloss: 0.588124\n",
      "[239]\ttraining's binary_logloss: 0.422314\tvalid_1's binary_logloss: 0.58806\n",
      "[240]\ttraining's binary_logloss: 0.421496\tvalid_1's binary_logloss: 0.587837\n",
      "[241]\ttraining's binary_logloss: 0.420742\tvalid_1's binary_logloss: 0.588141\n",
      "[242]\ttraining's binary_logloss: 0.420122\tvalid_1's binary_logloss: 0.588393\n",
      "[243]\ttraining's binary_logloss: 0.419548\tvalid_1's binary_logloss: 0.587923\n",
      "[244]\ttraining's binary_logloss: 0.418973\tvalid_1's binary_logloss: 0.587919\n",
      "[245]\ttraining's binary_logloss: 0.418253\tvalid_1's binary_logloss: 0.58795\n",
      "[246]\ttraining's binary_logloss: 0.417783\tvalid_1's binary_logloss: 0.587786\n",
      "[247]\ttraining's binary_logloss: 0.417088\tvalid_1's binary_logloss: 0.587752\n",
      "[248]\ttraining's binary_logloss: 0.416435\tvalid_1's binary_logloss: 0.587444\n",
      "[249]\ttraining's binary_logloss: 0.415679\tvalid_1's binary_logloss: 0.587466\n",
      "[250]\ttraining's binary_logloss: 0.41501\tvalid_1's binary_logloss: 0.587253\n",
      "[251]\ttraining's binary_logloss: 0.414422\tvalid_1's binary_logloss: 0.586941\n",
      "[252]\ttraining's binary_logloss: 0.413832\tvalid_1's binary_logloss: 0.58663\n",
      "[253]\ttraining's binary_logloss: 0.413173\tvalid_1's binary_logloss: 0.586585\n",
      "[254]\ttraining's binary_logloss: 0.412595\tvalid_1's binary_logloss: 0.586567\n",
      "[255]\ttraining's binary_logloss: 0.411902\tvalid_1's binary_logloss: 0.586798\n",
      "[256]\ttraining's binary_logloss: 0.41135\tvalid_1's binary_logloss: 0.586998\n",
      "[257]\ttraining's binary_logloss: 0.410947\tvalid_1's binary_logloss: 0.586581\n",
      "[258]\ttraining's binary_logloss: 0.410299\tvalid_1's binary_logloss: 0.586524\n",
      "[259]\ttraining's binary_logloss: 0.409828\tvalid_1's binary_logloss: 0.58656\n",
      "[260]\ttraining's binary_logloss: 0.409324\tvalid_1's binary_logloss: 0.586581\n",
      "[261]\ttraining's binary_logloss: 0.408553\tvalid_1's binary_logloss: 0.586574\n",
      "[262]\ttraining's binary_logloss: 0.407894\tvalid_1's binary_logloss: 0.58651\n",
      "[263]\ttraining's binary_logloss: 0.40727\tvalid_1's binary_logloss: 0.586324\n",
      "[264]\ttraining's binary_logloss: 0.406674\tvalid_1's binary_logloss: 0.586486\n",
      "[265]\ttraining's binary_logloss: 0.406004\tvalid_1's binary_logloss: 0.586074\n",
      "[266]\ttraining's binary_logloss: 0.405405\tvalid_1's binary_logloss: 0.586139\n",
      "[267]\ttraining's binary_logloss: 0.40481\tvalid_1's binary_logloss: 0.586209\n",
      "[268]\ttraining's binary_logloss: 0.404137\tvalid_1's binary_logloss: 0.586421\n",
      "[269]\ttraining's binary_logloss: 0.403562\tvalid_1's binary_logloss: 0.586534\n",
      "[270]\ttraining's binary_logloss: 0.402879\tvalid_1's binary_logloss: 0.586678\n",
      "[271]\ttraining's binary_logloss: 0.402256\tvalid_1's binary_logloss: 0.586337\n",
      "[272]\ttraining's binary_logloss: 0.401562\tvalid_1's binary_logloss: 0.586305\n",
      "[273]\ttraining's binary_logloss: 0.40092\tvalid_1's binary_logloss: 0.586034\n",
      "[274]\ttraining's binary_logloss: 0.400514\tvalid_1's binary_logloss: 0.585916\n",
      "[275]\ttraining's binary_logloss: 0.399966\tvalid_1's binary_logloss: 0.585614\n",
      "[276]\ttraining's binary_logloss: 0.399505\tvalid_1's binary_logloss: 0.585823\n",
      "[277]\ttraining's binary_logloss: 0.398822\tvalid_1's binary_logloss: 0.586043\n",
      "[278]\ttraining's binary_logloss: 0.398278\tvalid_1's binary_logloss: 0.586271\n",
      "[279]\ttraining's binary_logloss: 0.397777\tvalid_1's binary_logloss: 0.586429\n",
      "[280]\ttraining's binary_logloss: 0.397173\tvalid_1's binary_logloss: 0.586447\n",
      "[281]\ttraining's binary_logloss: 0.396551\tvalid_1's binary_logloss: 0.586449\n",
      "[282]\ttraining's binary_logloss: 0.396004\tvalid_1's binary_logloss: 0.586523\n",
      "[283]\ttraining's binary_logloss: 0.395455\tvalid_1's binary_logloss: 0.586417\n",
      "[284]\ttraining's binary_logloss: 0.394902\tvalid_1's binary_logloss: 0.586608\n",
      "[285]\ttraining's binary_logloss: 0.394252\tvalid_1's binary_logloss: 0.58663\n",
      "[286]\ttraining's binary_logloss: 0.393718\tvalid_1's binary_logloss: 0.586853\n",
      "[287]\ttraining's binary_logloss: 0.393119\tvalid_1's binary_logloss: 0.586982\n",
      "[288]\ttraining's binary_logloss: 0.392515\tvalid_1's binary_logloss: 0.587165\n",
      "[289]\ttraining's binary_logloss: 0.392041\tvalid_1's binary_logloss: 0.587363\n",
      "[290]\ttraining's binary_logloss: 0.391522\tvalid_1's binary_logloss: 0.58738\n",
      "[291]\ttraining's binary_logloss: 0.390921\tvalid_1's binary_logloss: 0.587348\n",
      "[292]\ttraining's binary_logloss: 0.390459\tvalid_1's binary_logloss: 0.587558\n",
      "[293]\ttraining's binary_logloss: 0.389801\tvalid_1's binary_logloss: 0.587413\n",
      "[294]\ttraining's binary_logloss: 0.389258\tvalid_1's binary_logloss: 0.587598\n",
      "[295]\ttraining's binary_logloss: 0.388825\tvalid_1's binary_logloss: 0.587237\n",
      "[296]\ttraining's binary_logloss: 0.388292\tvalid_1's binary_logloss: 0.587289\n",
      "[297]\ttraining's binary_logloss: 0.387692\tvalid_1's binary_logloss: 0.587149\n",
      "[298]\ttraining's binary_logloss: 0.387265\tvalid_1's binary_logloss: 0.586911\n",
      "[299]\ttraining's binary_logloss: 0.386714\tvalid_1's binary_logloss: 0.586891\n",
      "[300]\ttraining's binary_logloss: 0.386179\tvalid_1's binary_logloss: 0.586709\n",
      "[301]\ttraining's binary_logloss: 0.385614\tvalid_1's binary_logloss: 0.586857\n",
      "[302]\ttraining's binary_logloss: 0.385226\tvalid_1's binary_logloss: 0.586913\n",
      "[303]\ttraining's binary_logloss: 0.384759\tvalid_1's binary_logloss: 0.586912\n",
      "[304]\ttraining's binary_logloss: 0.384316\tvalid_1's binary_logloss: 0.58688\n",
      "[305]\ttraining's binary_logloss: 0.383824\tvalid_1's binary_logloss: 0.586651\n",
      "[306]\ttraining's binary_logloss: 0.383322\tvalid_1's binary_logloss: 0.58654\n",
      "[307]\ttraining's binary_logloss: 0.382744\tvalid_1's binary_logloss: 0.586613\n",
      "[308]\ttraining's binary_logloss: 0.382137\tvalid_1's binary_logloss: 0.586455\n",
      "[309]\ttraining's binary_logloss: 0.381735\tvalid_1's binary_logloss: 0.586248\n",
      "[310]\ttraining's binary_logloss: 0.381136\tvalid_1's binary_logloss: 0.585955\n",
      "[311]\ttraining's binary_logloss: 0.380626\tvalid_1's binary_logloss: 0.585898\n",
      "[312]\ttraining's binary_logloss: 0.380077\tvalid_1's binary_logloss: 0.585759\n",
      "[313]\ttraining's binary_logloss: 0.379496\tvalid_1's binary_logloss: 0.58563\n",
      "[314]\ttraining's binary_logloss: 0.379045\tvalid_1's binary_logloss: 0.585685\n",
      "[315]\ttraining's binary_logloss: 0.378535\tvalid_1's binary_logloss: 0.585383\n",
      "[316]\ttraining's binary_logloss: 0.377986\tvalid_1's binary_logloss: 0.585352\n",
      "[317]\ttraining's binary_logloss: 0.377505\tvalid_1's binary_logloss: 0.585311\n",
      "[318]\ttraining's binary_logloss: 0.37691\tvalid_1's binary_logloss: 0.585146\n",
      "[319]\ttraining's binary_logloss: 0.376269\tvalid_1's binary_logloss: 0.584763\n",
      "[320]\ttraining's binary_logloss: 0.375674\tvalid_1's binary_logloss: 0.58481\n",
      "[321]\ttraining's binary_logloss: 0.375212\tvalid_1's binary_logloss: 0.584805\n",
      "[322]\ttraining's binary_logloss: 0.3747\tvalid_1's binary_logloss: 0.58488\n",
      "[323]\ttraining's binary_logloss: 0.374209\tvalid_1's binary_logloss: 0.584817\n",
      "[324]\ttraining's binary_logloss: 0.373724\tvalid_1's binary_logloss: 0.584723\n",
      "[325]\ttraining's binary_logloss: 0.373297\tvalid_1's binary_logloss: 0.584611\n",
      "[326]\ttraining's binary_logloss: 0.372903\tvalid_1's binary_logloss: 0.584419\n",
      "[327]\ttraining's binary_logloss: 0.37253\tvalid_1's binary_logloss: 0.584187\n",
      "[328]\ttraining's binary_logloss: 0.37215\tvalid_1's binary_logloss: 0.583873\n",
      "[329]\ttraining's binary_logloss: 0.371732\tvalid_1's binary_logloss: 0.583796\n",
      "[330]\ttraining's binary_logloss: 0.371347\tvalid_1's binary_logloss: 0.583794\n",
      "[331]\ttraining's binary_logloss: 0.370962\tvalid_1's binary_logloss: 0.583617\n",
      "[332]\ttraining's binary_logloss: 0.370606\tvalid_1's binary_logloss: 0.58348\n",
      "[333]\ttraining's binary_logloss: 0.370108\tvalid_1's binary_logloss: 0.583374\n",
      "[334]\ttraining's binary_logloss: 0.3696\tvalid_1's binary_logloss: 0.583489\n",
      "[335]\ttraining's binary_logloss: 0.36903\tvalid_1's binary_logloss: 0.583224\n",
      "[336]\ttraining's binary_logloss: 0.36864\tvalid_1's binary_logloss: 0.583198\n",
      "[337]\ttraining's binary_logloss: 0.368158\tvalid_1's binary_logloss: 0.58345\n",
      "[338]\ttraining's binary_logloss: 0.367534\tvalid_1's binary_logloss: 0.583344\n",
      "[339]\ttraining's binary_logloss: 0.367112\tvalid_1's binary_logloss: 0.583368\n",
      "[340]\ttraining's binary_logloss: 0.366551\tvalid_1's binary_logloss: 0.583687\n",
      "[341]\ttraining's binary_logloss: 0.366167\tvalid_1's binary_logloss: 0.583656\n",
      "[342]\ttraining's binary_logloss: 0.365642\tvalid_1's binary_logloss: 0.583989\n",
      "[343]\ttraining's binary_logloss: 0.365243\tvalid_1's binary_logloss: 0.583659\n",
      "[344]\ttraining's binary_logloss: 0.364687\tvalid_1's binary_logloss: 0.583846\n",
      "[345]\ttraining's binary_logloss: 0.364211\tvalid_1's binary_logloss: 0.58399\n",
      "[346]\ttraining's binary_logloss: 0.363752\tvalid_1's binary_logloss: 0.58416\n",
      "[347]\ttraining's binary_logloss: 0.363367\tvalid_1's binary_logloss: 0.584156\n",
      "[348]\ttraining's binary_logloss: 0.362981\tvalid_1's binary_logloss: 0.584038\n",
      "[349]\ttraining's binary_logloss: 0.362695\tvalid_1's binary_logloss: 0.58402\n",
      "[350]\ttraining's binary_logloss: 0.362257\tvalid_1's binary_logloss: 0.584142\n",
      "[351]\ttraining's binary_logloss: 0.361681\tvalid_1's binary_logloss: 0.583953\n",
      "[352]\ttraining's binary_logloss: 0.361083\tvalid_1's binary_logloss: 0.584128\n",
      "[353]\ttraining's binary_logloss: 0.360673\tvalid_1's binary_logloss: 0.584337\n",
      "[354]\ttraining's binary_logloss: 0.360128\tvalid_1's binary_logloss: 0.58456\n",
      "[355]\ttraining's binary_logloss: 0.359631\tvalid_1's binary_logloss: 0.584699\n",
      "[356]\ttraining's binary_logloss: 0.359146\tvalid_1's binary_logloss: 0.584708\n",
      "[357]\ttraining's binary_logloss: 0.358814\tvalid_1's binary_logloss: 0.58473\n",
      "[358]\ttraining's binary_logloss: 0.358451\tvalid_1's binary_logloss: 0.584744\n",
      "[359]\ttraining's binary_logloss: 0.357996\tvalid_1's binary_logloss: 0.58498\n",
      "[360]\ttraining's binary_logloss: 0.357496\tvalid_1's binary_logloss: 0.58501\n",
      "[361]\ttraining's binary_logloss: 0.357046\tvalid_1's binary_logloss: 0.58534\n",
      "[362]\ttraining's binary_logloss: 0.356592\tvalid_1's binary_logloss: 0.585312\n",
      "[363]\ttraining's binary_logloss: 0.356224\tvalid_1's binary_logloss: 0.585541\n",
      "[364]\ttraining's binary_logloss: 0.355691\tvalid_1's binary_logloss: 0.585453\n",
      "[365]\ttraining's binary_logloss: 0.355134\tvalid_1's binary_logloss: 0.585675\n",
      "[366]\ttraining's binary_logloss: 0.354652\tvalid_1's binary_logloss: 0.585815\n",
      "[367]\ttraining's binary_logloss: 0.354179\tvalid_1's binary_logloss: 0.585952\n",
      "[368]\ttraining's binary_logloss: 0.353601\tvalid_1's binary_logloss: 0.585798\n",
      "[369]\ttraining's binary_logloss: 0.353156\tvalid_1's binary_logloss: 0.585554\n",
      "[370]\ttraining's binary_logloss: 0.352706\tvalid_1's binary_logloss: 0.585631\n",
      "[371]\ttraining's binary_logloss: 0.352251\tvalid_1's binary_logloss: 0.585781\n",
      "[372]\ttraining's binary_logloss: 0.351754\tvalid_1's binary_logloss: 0.585918\n",
      "[373]\ttraining's binary_logloss: 0.351272\tvalid_1's binary_logloss: 0.58581\n",
      "[374]\ttraining's binary_logloss: 0.350839\tvalid_1's binary_logloss: 0.586419\n",
      "[375]\ttraining's binary_logloss: 0.350426\tvalid_1's binary_logloss: 0.586709\n",
      "[376]\ttraining's binary_logloss: 0.349913\tvalid_1's binary_logloss: 0.58663\n",
      "[377]\ttraining's binary_logloss: 0.34936\tvalid_1's binary_logloss: 0.586584\n",
      "[378]\ttraining's binary_logloss: 0.3489\tvalid_1's binary_logloss: 0.586571\n",
      "[379]\ttraining's binary_logloss: 0.34855\tvalid_1's binary_logloss: 0.586716\n",
      "[380]\ttraining's binary_logloss: 0.348137\tvalid_1's binary_logloss: 0.587203\n",
      "[381]\ttraining's binary_logloss: 0.347685\tvalid_1's binary_logloss: 0.587343\n",
      "[382]\ttraining's binary_logloss: 0.347241\tvalid_1's binary_logloss: 0.587538\n",
      "[383]\ttraining's binary_logloss: 0.346702\tvalid_1's binary_logloss: 0.587404\n",
      "[384]\ttraining's binary_logloss: 0.346235\tvalid_1's binary_logloss: 0.587505\n",
      "[385]\ttraining's binary_logloss: 0.345711\tvalid_1's binary_logloss: 0.587463\n",
      "[386]\ttraining's binary_logloss: 0.345092\tvalid_1's binary_logloss: 0.587191\n",
      "[387]\ttraining's binary_logloss: 0.344664\tvalid_1's binary_logloss: 0.587048\n",
      "[388]\ttraining's binary_logloss: 0.344064\tvalid_1's binary_logloss: 0.586828\n",
      "[389]\ttraining's binary_logloss: 0.343559\tvalid_1's binary_logloss: 0.586946\n",
      "[390]\ttraining's binary_logloss: 0.343129\tvalid_1's binary_logloss: 0.586914\n",
      "[391]\ttraining's binary_logloss: 0.342727\tvalid_1's binary_logloss: 0.587057\n",
      "[392]\ttraining's binary_logloss: 0.342332\tvalid_1's binary_logloss: 0.587036\n",
      "[393]\ttraining's binary_logloss: 0.34169\tvalid_1's binary_logloss: 0.586741\n",
      "[394]\ttraining's binary_logloss: 0.341221\tvalid_1's binary_logloss: 0.586645\n",
      "[395]\ttraining's binary_logloss: 0.340805\tvalid_1's binary_logloss: 0.586561\n",
      "[396]\ttraining's binary_logloss: 0.340404\tvalid_1's binary_logloss: 0.58661\n",
      "[397]\ttraining's binary_logloss: 0.339967\tvalid_1's binary_logloss: 0.586677\n",
      "[398]\ttraining's binary_logloss: 0.339597\tvalid_1's binary_logloss: 0.586712\n",
      "[399]\ttraining's binary_logloss: 0.339188\tvalid_1's binary_logloss: 0.586711\n",
      "[400]\ttraining's binary_logloss: 0.338622\tvalid_1's binary_logloss: 0.586664\n",
      "[401]\ttraining's binary_logloss: 0.338197\tvalid_1's binary_logloss: 0.586374\n",
      "[402]\ttraining's binary_logloss: 0.337848\tvalid_1's binary_logloss: 0.586492\n",
      "[403]\ttraining's binary_logloss: 0.337448\tvalid_1's binary_logloss: 0.58643\n",
      "[404]\ttraining's binary_logloss: 0.337107\tvalid_1's binary_logloss: 0.586631\n",
      "[405]\ttraining's binary_logloss: 0.336687\tvalid_1's binary_logloss: 0.586663\n",
      "[406]\ttraining's binary_logloss: 0.33631\tvalid_1's binary_logloss: 0.586658\n",
      "[407]\ttraining's binary_logloss: 0.33588\tvalid_1's binary_logloss: 0.586588\n",
      "[408]\ttraining's binary_logloss: 0.335453\tvalid_1's binary_logloss: 0.586561\n",
      "[409]\ttraining's binary_logloss: 0.335025\tvalid_1's binary_logloss: 0.58682\n",
      "[410]\ttraining's binary_logloss: 0.334574\tvalid_1's binary_logloss: 0.586733\n",
      "[411]\ttraining's binary_logloss: 0.33416\tvalid_1's binary_logloss: 0.586252\n",
      "[412]\ttraining's binary_logloss: 0.333758\tvalid_1's binary_logloss: 0.586337\n",
      "[413]\ttraining's binary_logloss: 0.333339\tvalid_1's binary_logloss: 0.58639\n",
      "[414]\ttraining's binary_logloss: 0.332905\tvalid_1's binary_logloss: 0.586599\n",
      "[415]\ttraining's binary_logloss: 0.332481\tvalid_1's binary_logloss: 0.586695\n",
      "[416]\ttraining's binary_logloss: 0.33209\tvalid_1's binary_logloss: 0.586572\n",
      "[417]\ttraining's binary_logloss: 0.331596\tvalid_1's binary_logloss: 0.586708\n",
      "[418]\ttraining's binary_logloss: 0.331282\tvalid_1's binary_logloss: 0.586455\n",
      "[419]\ttraining's binary_logloss: 0.330953\tvalid_1's binary_logloss: 0.586159\n",
      "[420]\ttraining's binary_logloss: 0.330501\tvalid_1's binary_logloss: 0.586082\n",
      "[421]\ttraining's binary_logloss: 0.330064\tvalid_1's binary_logloss: 0.586141\n",
      "[422]\ttraining's binary_logloss: 0.329717\tvalid_1's binary_logloss: 0.586026\n",
      "[423]\ttraining's binary_logloss: 0.329294\tvalid_1's binary_logloss: 0.586101\n",
      "[424]\ttraining's binary_logloss: 0.328937\tvalid_1's binary_logloss: 0.586242\n",
      "[425]\ttraining's binary_logloss: 0.328502\tvalid_1's binary_logloss: 0.586179\n",
      "[426]\ttraining's binary_logloss: 0.328046\tvalid_1's binary_logloss: 0.586297\n",
      "[427]\ttraining's binary_logloss: 0.327635\tvalid_1's binary_logloss: 0.586143\n",
      "[428]\ttraining's binary_logloss: 0.32711\tvalid_1's binary_logloss: 0.586232\n",
      "[429]\ttraining's binary_logloss: 0.326801\tvalid_1's binary_logloss: 0.585947\n",
      "[430]\ttraining's binary_logloss: 0.326419\tvalid_1's binary_logloss: 0.586037\n",
      "[431]\ttraining's binary_logloss: 0.326036\tvalid_1's binary_logloss: 0.586306\n",
      "[432]\ttraining's binary_logloss: 0.325522\tvalid_1's binary_logloss: 0.586517\n",
      "[433]\ttraining's binary_logloss: 0.325167\tvalid_1's binary_logloss: 0.586915\n",
      "[434]\ttraining's binary_logloss: 0.324639\tvalid_1's binary_logloss: 0.587299\n",
      "[435]\ttraining's binary_logloss: 0.324233\tvalid_1's binary_logloss: 0.587387\n",
      "[436]\ttraining's binary_logloss: 0.323787\tvalid_1's binary_logloss: 0.587272\n",
      "[437]\ttraining's binary_logloss: 0.323408\tvalid_1's binary_logloss: 0.587308\n",
      "[438]\ttraining's binary_logloss: 0.322965\tvalid_1's binary_logloss: 0.587231\n",
      "[439]\ttraining's binary_logloss: 0.322536\tvalid_1's binary_logloss: 0.58739\n",
      "[440]\ttraining's binary_logloss: 0.322168\tvalid_1's binary_logloss: 0.587384\n",
      "[441]\ttraining's binary_logloss: 0.321814\tvalid_1's binary_logloss: 0.587323\n",
      "[442]\ttraining's binary_logloss: 0.32152\tvalid_1's binary_logloss: 0.587176\n",
      "[443]\ttraining's binary_logloss: 0.321212\tvalid_1's binary_logloss: 0.58706\n",
      "[444]\ttraining's binary_logloss: 0.320796\tvalid_1's binary_logloss: 0.586968\n",
      "[445]\ttraining's binary_logloss: 0.320305\tvalid_1's binary_logloss: 0.587054\n",
      "[446]\ttraining's binary_logloss: 0.319886\tvalid_1's binary_logloss: 0.587216\n",
      "[447]\ttraining's binary_logloss: 0.319556\tvalid_1's binary_logloss: 0.587282\n",
      "[448]\ttraining's binary_logloss: 0.319212\tvalid_1's binary_logloss: 0.587384\n",
      "[449]\ttraining's binary_logloss: 0.318877\tvalid_1's binary_logloss: 0.587613\n",
      "[450]\ttraining's binary_logloss: 0.318504\tvalid_1's binary_logloss: 0.58773\n",
      "[451]\ttraining's binary_logloss: 0.318175\tvalid_1's binary_logloss: 0.58806\n",
      "[452]\ttraining's binary_logloss: 0.317707\tvalid_1's binary_logloss: 0.588344\n",
      "[453]\ttraining's binary_logloss: 0.31734\tvalid_1's binary_logloss: 0.58855\n",
      "[454]\ttraining's binary_logloss: 0.316915\tvalid_1's binary_logloss: 0.588541\n",
      "[455]\ttraining's binary_logloss: 0.316584\tvalid_1's binary_logloss: 0.588453\n",
      "[456]\ttraining's binary_logloss: 0.316291\tvalid_1's binary_logloss: 0.588162\n",
      "[457]\ttraining's binary_logloss: 0.315827\tvalid_1's binary_logloss: 0.588234\n",
      "[458]\ttraining's binary_logloss: 0.315445\tvalid_1's binary_logloss: 0.588254\n",
      "[459]\ttraining's binary_logloss: 0.315005\tvalid_1's binary_logloss: 0.588609\n",
      "[460]\ttraining's binary_logloss: 0.314596\tvalid_1's binary_logloss: 0.588637\n",
      "[461]\ttraining's binary_logloss: 0.3142\tvalid_1's binary_logloss: 0.588617\n",
      "[462]\ttraining's binary_logloss: 0.313908\tvalid_1's binary_logloss: 0.588621\n",
      "[463]\ttraining's binary_logloss: 0.313459\tvalid_1's binary_logloss: 0.588714\n",
      "[464]\ttraining's binary_logloss: 0.313144\tvalid_1's binary_logloss: 0.588622\n",
      "[465]\ttraining's binary_logloss: 0.312682\tvalid_1's binary_logloss: 0.588429\n",
      "[466]\ttraining's binary_logloss: 0.31232\tvalid_1's binary_logloss: 0.588596\n",
      "[467]\ttraining's binary_logloss: 0.312008\tvalid_1's binary_logloss: 0.588588\n",
      "[468]\ttraining's binary_logloss: 0.311651\tvalid_1's binary_logloss: 0.588683\n",
      "[469]\ttraining's binary_logloss: 0.31124\tvalid_1's binary_logloss: 0.588529\n",
      "[470]\ttraining's binary_logloss: 0.310836\tvalid_1's binary_logloss: 0.588709\n",
      "[471]\ttraining's binary_logloss: 0.310452\tvalid_1's binary_logloss: 0.588762\n",
      "[472]\ttraining's binary_logloss: 0.310139\tvalid_1's binary_logloss: 0.588722\n",
      "[473]\ttraining's binary_logloss: 0.309796\tvalid_1's binary_logloss: 0.588463\n",
      "[474]\ttraining's binary_logloss: 0.309279\tvalid_1's binary_logloss: 0.588189\n",
      "[475]\ttraining's binary_logloss: 0.308908\tvalid_1's binary_logloss: 0.588308\n",
      "[476]\ttraining's binary_logloss: 0.308523\tvalid_1's binary_logloss: 0.588417\n",
      "[477]\ttraining's binary_logloss: 0.307972\tvalid_1's binary_logloss: 0.588358\n",
      "[478]\ttraining's binary_logloss: 0.307616\tvalid_1's binary_logloss: 0.58839\n",
      "[479]\ttraining's binary_logloss: 0.307244\tvalid_1's binary_logloss: 0.588166\n",
      "[480]\ttraining's binary_logloss: 0.306823\tvalid_1's binary_logloss: 0.58827\n",
      "[481]\ttraining's binary_logloss: 0.306441\tvalid_1's binary_logloss: 0.58827\n",
      "[482]\ttraining's binary_logloss: 0.306108\tvalid_1's binary_logloss: 0.588399\n",
      "[483]\ttraining's binary_logloss: 0.305669\tvalid_1's binary_logloss: 0.588399\n",
      "[484]\ttraining's binary_logloss: 0.30528\tvalid_1's binary_logloss: 0.588202\n",
      "[485]\ttraining's binary_logloss: 0.304831\tvalid_1's binary_logloss: 0.588457\n",
      "[486]\ttraining's binary_logloss: 0.304245\tvalid_1's binary_logloss: 0.588304\n",
      "[487]\ttraining's binary_logloss: 0.303829\tvalid_1's binary_logloss: 0.588464\n",
      "[488]\ttraining's binary_logloss: 0.303509\tvalid_1's binary_logloss: 0.588814\n",
      "[489]\ttraining's binary_logloss: 0.30315\tvalid_1's binary_logloss: 0.588907\n",
      "[490]\ttraining's binary_logloss: 0.302758\tvalid_1's binary_logloss: 0.589119\n",
      "[491]\ttraining's binary_logloss: 0.302279\tvalid_1's binary_logloss: 0.589074\n",
      "[492]\ttraining's binary_logloss: 0.301921\tvalid_1's binary_logloss: 0.589264\n",
      "[493]\ttraining's binary_logloss: 0.301488\tvalid_1's binary_logloss: 0.589108\n",
      "[494]\ttraining's binary_logloss: 0.301086\tvalid_1's binary_logloss: 0.589184\n",
      "[495]\ttraining's binary_logloss: 0.300713\tvalid_1's binary_logloss: 0.58934\n",
      "[496]\ttraining's binary_logloss: 0.300382\tvalid_1's binary_logloss: 0.589615\n",
      "[497]\ttraining's binary_logloss: 0.299938\tvalid_1's binary_logloss: 0.589759\n",
      "[498]\ttraining's binary_logloss: 0.29953\tvalid_1's binary_logloss: 0.589845\n",
      "[499]\ttraining's binary_logloss: 0.299234\tvalid_1's binary_logloss: 0.589688\n",
      "[500]\ttraining's binary_logloss: 0.2988\tvalid_1's binary_logloss: 0.589652\n",
      "[501]\ttraining's binary_logloss: 0.298438\tvalid_1's binary_logloss: 0.589784\n",
      "[502]\ttraining's binary_logloss: 0.298136\tvalid_1's binary_logloss: 0.589783\n",
      "[503]\ttraining's binary_logloss: 0.297747\tvalid_1's binary_logloss: 0.589852\n",
      "[504]\ttraining's binary_logloss: 0.297363\tvalid_1's binary_logloss: 0.590134\n",
      "[505]\ttraining's binary_logloss: 0.296904\tvalid_1's binary_logloss: 0.589963\n",
      "[506]\ttraining's binary_logloss: 0.296454\tvalid_1's binary_logloss: 0.59021\n",
      "[507]\ttraining's binary_logloss: 0.295985\tvalid_1's binary_logloss: 0.590207\n",
      "[508]\ttraining's binary_logloss: 0.295597\tvalid_1's binary_logloss: 0.590362\n",
      "[509]\ttraining's binary_logloss: 0.295137\tvalid_1's binary_logloss: 0.590804\n",
      "[510]\ttraining's binary_logloss: 0.294726\tvalid_1's binary_logloss: 0.590735\n",
      "[511]\ttraining's binary_logloss: 0.294452\tvalid_1's binary_logloss: 0.590735\n",
      "[512]\ttraining's binary_logloss: 0.294159\tvalid_1's binary_logloss: 0.590662\n",
      "[513]\ttraining's binary_logloss: 0.293775\tvalid_1's binary_logloss: 0.590786\n",
      "[514]\ttraining's binary_logloss: 0.293369\tvalid_1's binary_logloss: 0.590915\n",
      "[515]\ttraining's binary_logloss: 0.292973\tvalid_1's binary_logloss: 0.590935\n",
      "[516]\ttraining's binary_logloss: 0.292595\tvalid_1's binary_logloss: 0.591002\n",
      "[517]\ttraining's binary_logloss: 0.292245\tvalid_1's binary_logloss: 0.591108\n",
      "[518]\ttraining's binary_logloss: 0.291924\tvalid_1's binary_logloss: 0.591321\n",
      "[519]\ttraining's binary_logloss: 0.291527\tvalid_1's binary_logloss: 0.59126\n",
      "[520]\ttraining's binary_logloss: 0.291254\tvalid_1's binary_logloss: 0.591372\n",
      "[521]\ttraining's binary_logloss: 0.290944\tvalid_1's binary_logloss: 0.591575\n",
      "[522]\ttraining's binary_logloss: 0.290503\tvalid_1's binary_logloss: 0.591991\n",
      "[523]\ttraining's binary_logloss: 0.29023\tvalid_1's binary_logloss: 0.592046\n",
      "[524]\ttraining's binary_logloss: 0.289968\tvalid_1's binary_logloss: 0.592116\n",
      "[525]\ttraining's binary_logloss: 0.289526\tvalid_1's binary_logloss: 0.592199\n",
      "[526]\ttraining's binary_logloss: 0.28924\tvalid_1's binary_logloss: 0.592468\n",
      "[527]\ttraining's binary_logloss: 0.288897\tvalid_1's binary_logloss: 0.592448\n",
      "[528]\ttraining's binary_logloss: 0.288547\tvalid_1's binary_logloss: 0.592301\n",
      "[529]\ttraining's binary_logloss: 0.288234\tvalid_1's binary_logloss: 0.592409\n",
      "[530]\ttraining's binary_logloss: 0.28787\tvalid_1's binary_logloss: 0.592423\n",
      "[531]\ttraining's binary_logloss: 0.287543\tvalid_1's binary_logloss: 0.592627\n",
      "[532]\ttraining's binary_logloss: 0.287137\tvalid_1's binary_logloss: 0.592994\n",
      "[533]\ttraining's binary_logloss: 0.286809\tvalid_1's binary_logloss: 0.593019\n",
      "[534]\ttraining's binary_logloss: 0.286444\tvalid_1's binary_logloss: 0.59309\n",
      "[535]\ttraining's binary_logloss: 0.286118\tvalid_1's binary_logloss: 0.593133\n",
      "[536]\ttraining's binary_logloss: 0.285804\tvalid_1's binary_logloss: 0.593191\n",
      "[537]\ttraining's binary_logloss: 0.285561\tvalid_1's binary_logloss: 0.593386\n",
      "[538]\ttraining's binary_logloss: 0.28514\tvalid_1's binary_logloss: 0.593312\n",
      "[539]\ttraining's binary_logloss: 0.284766\tvalid_1's binary_logloss: 0.59332\n",
      "[540]\ttraining's binary_logloss: 0.284362\tvalid_1's binary_logloss: 0.593219\n",
      "[541]\ttraining's binary_logloss: 0.283969\tvalid_1's binary_logloss: 0.593009\n",
      "[542]\ttraining's binary_logloss: 0.283576\tvalid_1's binary_logloss: 0.593049\n",
      "[543]\ttraining's binary_logloss: 0.283245\tvalid_1's binary_logloss: 0.592883\n",
      "[544]\ttraining's binary_logloss: 0.282907\tvalid_1's binary_logloss: 0.592854\n",
      "[545]\ttraining's binary_logloss: 0.282544\tvalid_1's binary_logloss: 0.593327\n",
      "[546]\ttraining's binary_logloss: 0.2823\tvalid_1's binary_logloss: 0.59338\n",
      "[547]\ttraining's binary_logloss: 0.281963\tvalid_1's binary_logloss: 0.59351\n",
      "[548]\ttraining's binary_logloss: 0.281522\tvalid_1's binary_logloss: 0.593364\n",
      "[549]\ttraining's binary_logloss: 0.281212\tvalid_1's binary_logloss: 0.593594\n",
      "[550]\ttraining's binary_logloss: 0.280772\tvalid_1's binary_logloss: 0.593544\n",
      "[551]\ttraining's binary_logloss: 0.280461\tvalid_1's binary_logloss: 0.593472\n",
      "[552]\ttraining's binary_logloss: 0.28014\tvalid_1's binary_logloss: 0.593762\n",
      "[553]\ttraining's binary_logloss: 0.279784\tvalid_1's binary_logloss: 0.593605\n",
      "[554]\ttraining's binary_logloss: 0.279508\tvalid_1's binary_logloss: 0.593955\n",
      "[555]\ttraining's binary_logloss: 0.279169\tvalid_1's binary_logloss: 0.594142\n",
      "[556]\ttraining's binary_logloss: 0.278871\tvalid_1's binary_logloss: 0.59433\n",
      "[557]\ttraining's binary_logloss: 0.278632\tvalid_1's binary_logloss: 0.594436\n",
      "[558]\ttraining's binary_logloss: 0.278337\tvalid_1's binary_logloss: 0.594642\n",
      "[559]\ttraining's binary_logloss: 0.27801\tvalid_1's binary_logloss: 0.594697\n",
      "[560]\ttraining's binary_logloss: 0.277719\tvalid_1's binary_logloss: 0.594956\n",
      "[561]\ttraining's binary_logloss: 0.27738\tvalid_1's binary_logloss: 0.595017\n",
      "[562]\ttraining's binary_logloss: 0.277058\tvalid_1's binary_logloss: 0.594883\n",
      "[563]\ttraining's binary_logloss: 0.276807\tvalid_1's binary_logloss: 0.595003\n",
      "[564]\ttraining's binary_logloss: 0.276448\tvalid_1's binary_logloss: 0.595229\n",
      "[565]\ttraining's binary_logloss: 0.276174\tvalid_1's binary_logloss: 0.595417\n",
      "[566]\ttraining's binary_logloss: 0.27584\tvalid_1's binary_logloss: 0.595246\n",
      "[567]\ttraining's binary_logloss: 0.275597\tvalid_1's binary_logloss: 0.595345\n",
      "[568]\ttraining's binary_logloss: 0.275302\tvalid_1's binary_logloss: 0.595283\n",
      "[569]\ttraining's binary_logloss: 0.275018\tvalid_1's binary_logloss: 0.59532\n",
      "[570]\ttraining's binary_logloss: 0.274697\tvalid_1's binary_logloss: 0.595151\n",
      "[571]\ttraining's binary_logloss: 0.274419\tvalid_1's binary_logloss: 0.595326\n",
      "[572]\ttraining's binary_logloss: 0.274099\tvalid_1's binary_logloss: 0.59532\n",
      "[573]\ttraining's binary_logloss: 0.273712\tvalid_1's binary_logloss: 0.595337\n",
      "[574]\ttraining's binary_logloss: 0.273389\tvalid_1's binary_logloss: 0.595403\n",
      "[575]\ttraining's binary_logloss: 0.273091\tvalid_1's binary_logloss: 0.595336\n",
      "[576]\ttraining's binary_logloss: 0.272801\tvalid_1's binary_logloss: 0.595505\n",
      "[577]\ttraining's binary_logloss: 0.272485\tvalid_1's binary_logloss: 0.59542\n",
      "[578]\ttraining's binary_logloss: 0.272063\tvalid_1's binary_logloss: 0.595043\n",
      "[579]\ttraining's binary_logloss: 0.271724\tvalid_1's binary_logloss: 0.595052\n",
      "[580]\ttraining's binary_logloss: 0.271505\tvalid_1's binary_logloss: 0.595297\n",
      "[581]\ttraining's binary_logloss: 0.271047\tvalid_1's binary_logloss: 0.595376\n",
      "[582]\ttraining's binary_logloss: 0.270807\tvalid_1's binary_logloss: 0.595549\n",
      "[583]\ttraining's binary_logloss: 0.270455\tvalid_1's binary_logloss: 0.595392\n",
      "[584]\ttraining's binary_logloss: 0.27019\tvalid_1's binary_logloss: 0.595725\n",
      "[585]\ttraining's binary_logloss: 0.269928\tvalid_1's binary_logloss: 0.595895\n",
      "[586]\ttraining's binary_logloss: 0.269523\tvalid_1's binary_logloss: 0.596106\n",
      "[587]\ttraining's binary_logloss: 0.269232\tvalid_1's binary_logloss: 0.596229\n",
      "[588]\ttraining's binary_logloss: 0.268917\tvalid_1's binary_logloss: 0.596332\n",
      "[589]\ttraining's binary_logloss: 0.268596\tvalid_1's binary_logloss: 0.596575\n",
      "[590]\ttraining's binary_logloss: 0.268369\tvalid_1's binary_logloss: 0.596524\n",
      "[591]\ttraining's binary_logloss: 0.268065\tvalid_1's binary_logloss: 0.596714\n",
      "[592]\ttraining's binary_logloss: 0.267806\tvalid_1's binary_logloss: 0.596894\n",
      "[593]\ttraining's binary_logloss: 0.267465\tvalid_1's binary_logloss: 0.596808\n",
      "[594]\ttraining's binary_logloss: 0.267145\tvalid_1's binary_logloss: 0.596749\n",
      "[595]\ttraining's binary_logloss: 0.266907\tvalid_1's binary_logloss: 0.597042\n",
      "[596]\ttraining's binary_logloss: 0.266592\tvalid_1's binary_logloss: 0.597291\n",
      "[597]\ttraining's binary_logloss: 0.266302\tvalid_1's binary_logloss: 0.597277\n",
      "[598]\ttraining's binary_logloss: 0.265952\tvalid_1's binary_logloss: 0.597366\n",
      "[599]\ttraining's binary_logloss: 0.265639\tvalid_1's binary_logloss: 0.597377\n",
      "[600]\ttraining's binary_logloss: 0.265365\tvalid_1's binary_logloss: 0.597504\n",
      "[601]\ttraining's binary_logloss: 0.265012\tvalid_1's binary_logloss: 0.597775\n",
      "[602]\ttraining's binary_logloss: 0.264668\tvalid_1's binary_logloss: 0.597683\n",
      "[603]\ttraining's binary_logloss: 0.264385\tvalid_1's binary_logloss: 0.597808\n",
      "[604]\ttraining's binary_logloss: 0.264091\tvalid_1's binary_logloss: 0.597954\n",
      "[605]\ttraining's binary_logloss: 0.263779\tvalid_1's binary_logloss: 0.598069\n",
      "[606]\ttraining's binary_logloss: 0.263439\tvalid_1's binary_logloss: 0.598214\n",
      "[607]\ttraining's binary_logloss: 0.263142\tvalid_1's binary_logloss: 0.598287\n",
      "[608]\ttraining's binary_logloss: 0.262821\tvalid_1's binary_logloss: 0.598382\n",
      "[609]\ttraining's binary_logloss: 0.262531\tvalid_1's binary_logloss: 0.598401\n",
      "[610]\ttraining's binary_logloss: 0.262275\tvalid_1's binary_logloss: 0.598626\n",
      "[611]\ttraining's binary_logloss: 0.262016\tvalid_1's binary_logloss: 0.598741\n",
      "[612]\ttraining's binary_logloss: 0.261716\tvalid_1's binary_logloss: 0.598837\n",
      "[613]\ttraining's binary_logloss: 0.261382\tvalid_1's binary_logloss: 0.59894\n",
      "[614]\ttraining's binary_logloss: 0.261093\tvalid_1's binary_logloss: 0.598995\n",
      "[615]\ttraining's binary_logloss: 0.260835\tvalid_1's binary_logloss: 0.599151\n",
      "[616]\ttraining's binary_logloss: 0.260512\tvalid_1's binary_logloss: 0.599279\n",
      "[617]\ttraining's binary_logloss: 0.260291\tvalid_1's binary_logloss: 0.599217\n",
      "[618]\ttraining's binary_logloss: 0.259997\tvalid_1's binary_logloss: 0.59933\n",
      "[619]\ttraining's binary_logloss: 0.259707\tvalid_1's binary_logloss: 0.599514\n",
      "[620]\ttraining's binary_logloss: 0.259448\tvalid_1's binary_logloss: 0.599434\n",
      "[621]\ttraining's binary_logloss: 0.259172\tvalid_1's binary_logloss: 0.59957\n",
      "[622]\ttraining's binary_logloss: 0.258893\tvalid_1's binary_logloss: 0.59978\n",
      "[623]\ttraining's binary_logloss: 0.258614\tvalid_1's binary_logloss: 0.600006\n",
      "[624]\ttraining's binary_logloss: 0.258362\tvalid_1's binary_logloss: 0.600045\n",
      "[625]\ttraining's binary_logloss: 0.25808\tvalid_1's binary_logloss: 0.600081\n",
      "[626]\ttraining's binary_logloss: 0.257789\tvalid_1's binary_logloss: 0.600133\n",
      "[627]\ttraining's binary_logloss: 0.257517\tvalid_1's binary_logloss: 0.600243\n",
      "[628]\ttraining's binary_logloss: 0.257273\tvalid_1's binary_logloss: 0.600203\n",
      "[629]\ttraining's binary_logloss: 0.256958\tvalid_1's binary_logloss: 0.60031\n",
      "[630]\ttraining's binary_logloss: 0.256647\tvalid_1's binary_logloss: 0.600267\n",
      "[631]\ttraining's binary_logloss: 0.256324\tvalid_1's binary_logloss: 0.600252\n",
      "[632]\ttraining's binary_logloss: 0.256056\tvalid_1's binary_logloss: 0.600475\n",
      "[633]\ttraining's binary_logloss: 0.255807\tvalid_1's binary_logloss: 0.600499\n",
      "[634]\ttraining's binary_logloss: 0.255581\tvalid_1's binary_logloss: 0.600749\n",
      "[635]\ttraining's binary_logloss: 0.255312\tvalid_1's binary_logloss: 0.600897\n",
      "[636]\ttraining's binary_logloss: 0.255048\tvalid_1's binary_logloss: 0.600905\n",
      "[637]\ttraining's binary_logloss: 0.254729\tvalid_1's binary_logloss: 0.601205\n",
      "[638]\ttraining's binary_logloss: 0.254422\tvalid_1's binary_logloss: 0.601228\n",
      "[639]\ttraining's binary_logloss: 0.254165\tvalid_1's binary_logloss: 0.601451\n",
      "[640]\ttraining's binary_logloss: 0.253805\tvalid_1's binary_logloss: 0.601758\n",
      "[641]\ttraining's binary_logloss: 0.253552\tvalid_1's binary_logloss: 0.601772\n",
      "[642]\ttraining's binary_logloss: 0.253244\tvalid_1's binary_logloss: 0.602073\n",
      "[643]\ttraining's binary_logloss: 0.252883\tvalid_1's binary_logloss: 0.602056\n",
      "[644]\ttraining's binary_logloss: 0.252623\tvalid_1's binary_logloss: 0.602007\n",
      "[645]\ttraining's binary_logloss: 0.252408\tvalid_1's binary_logloss: 0.602116\n",
      "[646]\ttraining's binary_logloss: 0.252103\tvalid_1's binary_logloss: 0.602285\n",
      "[647]\ttraining's binary_logloss: 0.25177\tvalid_1's binary_logloss: 0.602261\n",
      "[648]\ttraining's binary_logloss: 0.251441\tvalid_1's binary_logloss: 0.602571\n",
      "[649]\ttraining's binary_logloss: 0.251152\tvalid_1's binary_logloss: 0.602678\n",
      "[650]\ttraining's binary_logloss: 0.250813\tvalid_1's binary_logloss: 0.602579\n",
      "[651]\ttraining's binary_logloss: 0.250481\tvalid_1's binary_logloss: 0.602859\n",
      "[652]\ttraining's binary_logloss: 0.250065\tvalid_1's binary_logloss: 0.6027\n",
      "[653]\ttraining's binary_logloss: 0.24974\tvalid_1's binary_logloss: 0.602545\n",
      "[654]\ttraining's binary_logloss: 0.249531\tvalid_1's binary_logloss: 0.602717\n",
      "[655]\ttraining's binary_logloss: 0.249116\tvalid_1's binary_logloss: 0.602905\n",
      "[656]\ttraining's binary_logloss: 0.248919\tvalid_1's binary_logloss: 0.602994\n",
      "[657]\ttraining's binary_logloss: 0.248702\tvalid_1's binary_logloss: 0.603194\n",
      "[658]\ttraining's binary_logloss: 0.24849\tvalid_1's binary_logloss: 0.603245\n",
      "[659]\ttraining's binary_logloss: 0.248227\tvalid_1's binary_logloss: 0.603248\n",
      "[660]\ttraining's binary_logloss: 0.247908\tvalid_1's binary_logloss: 0.603398\n",
      "[661]\ttraining's binary_logloss: 0.24763\tvalid_1's binary_logloss: 0.603434\n",
      "[662]\ttraining's binary_logloss: 0.247341\tvalid_1's binary_logloss: 0.603601\n",
      "[663]\ttraining's binary_logloss: 0.247081\tvalid_1's binary_logloss: 0.603565\n",
      "[664]\ttraining's binary_logloss: 0.246775\tvalid_1's binary_logloss: 0.60371\n",
      "[665]\ttraining's binary_logloss: 0.246527\tvalid_1's binary_logloss: 0.603731\n",
      "[666]\ttraining's binary_logloss: 0.246326\tvalid_1's binary_logloss: 0.603909\n",
      "[667]\ttraining's binary_logloss: 0.24611\tvalid_1's binary_logloss: 0.603932\n",
      "[668]\ttraining's binary_logloss: 0.245779\tvalid_1's binary_logloss: 0.603876\n",
      "[669]\ttraining's binary_logloss: 0.245514\tvalid_1's binary_logloss: 0.603996\n",
      "[670]\ttraining's binary_logloss: 0.245322\tvalid_1's binary_logloss: 0.603923\n",
      "[671]\ttraining's binary_logloss: 0.244966\tvalid_1's binary_logloss: 0.603832\n",
      "[672]\ttraining's binary_logloss: 0.244647\tvalid_1's binary_logloss: 0.603744\n",
      "[673]\ttraining's binary_logloss: 0.244426\tvalid_1's binary_logloss: 0.603473\n",
      "[674]\ttraining's binary_logloss: 0.244166\tvalid_1's binary_logloss: 0.603448\n",
      "[675]\ttraining's binary_logloss: 0.243806\tvalid_1's binary_logloss: 0.603659\n",
      "[676]\ttraining's binary_logloss: 0.243493\tvalid_1's binary_logloss: 0.603825\n",
      "[677]\ttraining's binary_logloss: 0.243199\tvalid_1's binary_logloss: 0.60386\n",
      "[678]\ttraining's binary_logloss: 0.242853\tvalid_1's binary_logloss: 0.604076\n",
      "[679]\ttraining's binary_logloss: 0.242622\tvalid_1's binary_logloss: 0.60426\n",
      "[680]\ttraining's binary_logloss: 0.242333\tvalid_1's binary_logloss: 0.60442\n",
      "[681]\ttraining's binary_logloss: 0.241989\tvalid_1's binary_logloss: 0.604443\n",
      "[682]\ttraining's binary_logloss: 0.241745\tvalid_1's binary_logloss: 0.604652\n",
      "[683]\ttraining's binary_logloss: 0.241465\tvalid_1's binary_logloss: 0.604694\n",
      "[684]\ttraining's binary_logloss: 0.241144\tvalid_1's binary_logloss: 0.604559\n",
      "[685]\ttraining's binary_logloss: 0.240925\tvalid_1's binary_logloss: 0.604734\n",
      "[686]\ttraining's binary_logloss: 0.240601\tvalid_1's binary_logloss: 0.604757\n",
      "[687]\ttraining's binary_logloss: 0.240257\tvalid_1's binary_logloss: 0.604632\n",
      "[688]\ttraining's binary_logloss: 0.240023\tvalid_1's binary_logloss: 0.604691\n",
      "[689]\ttraining's binary_logloss: 0.239712\tvalid_1's binary_logloss: 0.604659\n",
      "[690]\ttraining's binary_logloss: 0.239431\tvalid_1's binary_logloss: 0.604708\n",
      "[691]\ttraining's binary_logloss: 0.239173\tvalid_1's binary_logloss: 0.604754\n",
      "[692]\ttraining's binary_logloss: 0.23888\tvalid_1's binary_logloss: 0.604745\n",
      "[693]\ttraining's binary_logloss: 0.238634\tvalid_1's binary_logloss: 0.604838\n",
      "[694]\ttraining's binary_logloss: 0.238334\tvalid_1's binary_logloss: 0.60498\n",
      "[695]\ttraining's binary_logloss: 0.238069\tvalid_1's binary_logloss: 0.605119\n",
      "[696]\ttraining's binary_logloss: 0.23778\tvalid_1's binary_logloss: 0.605249\n",
      "[697]\ttraining's binary_logloss: 0.237468\tvalid_1's binary_logloss: 0.605358\n",
      "[698]\ttraining's binary_logloss: 0.23725\tvalid_1's binary_logloss: 0.605414\n",
      "[699]\ttraining's binary_logloss: 0.237043\tvalid_1's binary_logloss: 0.605546\n",
      "[700]\ttraining's binary_logloss: 0.236754\tvalid_1's binary_logloss: 0.605428\n",
      "[701]\ttraining's binary_logloss: 0.236541\tvalid_1's binary_logloss: 0.605466\n",
      "[702]\ttraining's binary_logloss: 0.236312\tvalid_1's binary_logloss: 0.605561\n",
      "[703]\ttraining's binary_logloss: 0.236019\tvalid_1's binary_logloss: 0.605534\n",
      "[704]\ttraining's binary_logloss: 0.235826\tvalid_1's binary_logloss: 0.605689\n",
      "[705]\ttraining's binary_logloss: 0.235494\tvalid_1's binary_logloss: 0.60585\n",
      "[706]\ttraining's binary_logloss: 0.235238\tvalid_1's binary_logloss: 0.605736\n",
      "[707]\ttraining's binary_logloss: 0.234968\tvalid_1's binary_logloss: 0.606003\n",
      "[708]\ttraining's binary_logloss: 0.234726\tvalid_1's binary_logloss: 0.606183\n",
      "[709]\ttraining's binary_logloss: 0.234464\tvalid_1's binary_logloss: 0.606189\n",
      "[710]\ttraining's binary_logloss: 0.234284\tvalid_1's binary_logloss: 0.606106\n",
      "[711]\ttraining's binary_logloss: 0.234098\tvalid_1's binary_logloss: 0.606186\n",
      "[712]\ttraining's binary_logloss: 0.233832\tvalid_1's binary_logloss: 0.606274\n",
      "[713]\ttraining's binary_logloss: 0.233513\tvalid_1's binary_logloss: 0.606377\n",
      "[714]\ttraining's binary_logloss: 0.233222\tvalid_1's binary_logloss: 0.606496\n",
      "[715]\ttraining's binary_logloss: 0.23291\tvalid_1's binary_logloss: 0.606746\n",
      "[716]\ttraining's binary_logloss: 0.232586\tvalid_1's binary_logloss: 0.60674\n",
      "[717]\ttraining's binary_logloss: 0.232293\tvalid_1's binary_logloss: 0.606505\n",
      "[718]\ttraining's binary_logloss: 0.231993\tvalid_1's binary_logloss: 0.606443\n",
      "[719]\ttraining's binary_logloss: 0.231645\tvalid_1's binary_logloss: 0.606465\n",
      "[720]\ttraining's binary_logloss: 0.231381\tvalid_1's binary_logloss: 0.606527\n",
      "[721]\ttraining's binary_logloss: 0.231116\tvalid_1's binary_logloss: 0.606447\n",
      "[722]\ttraining's binary_logloss: 0.230769\tvalid_1's binary_logloss: 0.606352\n",
      "[723]\ttraining's binary_logloss: 0.230515\tvalid_1's binary_logloss: 0.606344\n",
      "[724]\ttraining's binary_logloss: 0.230259\tvalid_1's binary_logloss: 0.60635\n",
      "[725]\ttraining's binary_logloss: 0.230007\tvalid_1's binary_logloss: 0.606238\n",
      "[726]\ttraining's binary_logloss: 0.229748\tvalid_1's binary_logloss: 0.606188\n",
      "[727]\ttraining's binary_logloss: 0.22946\tvalid_1's binary_logloss: 0.606347\n",
      "[728]\ttraining's binary_logloss: 0.229206\tvalid_1's binary_logloss: 0.606341\n",
      "[729]\ttraining's binary_logloss: 0.228866\tvalid_1's binary_logloss: 0.606409\n",
      "[730]\ttraining's binary_logloss: 0.228615\tvalid_1's binary_logloss: 0.606347\n",
      "[731]\ttraining's binary_logloss: 0.22835\tvalid_1's binary_logloss: 0.606366\n",
      "[732]\ttraining's binary_logloss: 0.228063\tvalid_1's binary_logloss: 0.606451\n",
      "[733]\ttraining's binary_logloss: 0.227835\tvalid_1's binary_logloss: 0.606458\n",
      "[734]\ttraining's binary_logloss: 0.227592\tvalid_1's binary_logloss: 0.606465\n",
      "[735]\ttraining's binary_logloss: 0.22736\tvalid_1's binary_logloss: 0.606535\n",
      "[736]\ttraining's binary_logloss: 0.227028\tvalid_1's binary_logloss: 0.606789\n",
      "[737]\ttraining's binary_logloss: 0.226728\tvalid_1's binary_logloss: 0.607025\n",
      "[738]\ttraining's binary_logloss: 0.226532\tvalid_1's binary_logloss: 0.607183\n",
      "[739]\ttraining's binary_logloss: 0.226307\tvalid_1's binary_logloss: 0.607214\n",
      "[740]\ttraining's binary_logloss: 0.226021\tvalid_1's binary_logloss: 0.60706\n",
      "[741]\ttraining's binary_logloss: 0.225727\tvalid_1's binary_logloss: 0.607184\n",
      "[742]\ttraining's binary_logloss: 0.225405\tvalid_1's binary_logloss: 0.607259\n",
      "[743]\ttraining's binary_logloss: 0.225205\tvalid_1's binary_logloss: 0.607239\n",
      "[744]\ttraining's binary_logloss: 0.224917\tvalid_1's binary_logloss: 0.607165\n",
      "[745]\ttraining's binary_logloss: 0.224726\tvalid_1's binary_logloss: 0.607174\n",
      "[746]\ttraining's binary_logloss: 0.224515\tvalid_1's binary_logloss: 0.60761\n",
      "[747]\ttraining's binary_logloss: 0.224219\tvalid_1's binary_logloss: 0.607663\n",
      "[748]\ttraining's binary_logloss: 0.223921\tvalid_1's binary_logloss: 0.607765\n",
      "[749]\ttraining's binary_logloss: 0.223651\tvalid_1's binary_logloss: 0.60786\n",
      "[750]\ttraining's binary_logloss: 0.223364\tvalid_1's binary_logloss: 0.607949\n",
      "[751]\ttraining's binary_logloss: 0.223109\tvalid_1's binary_logloss: 0.608107\n",
      "[752]\ttraining's binary_logloss: 0.222872\tvalid_1's binary_logloss: 0.607941\n",
      "[753]\ttraining's binary_logloss: 0.222662\tvalid_1's binary_logloss: 0.608255\n",
      "[754]\ttraining's binary_logloss: 0.222398\tvalid_1's binary_logloss: 0.608305\n",
      "[755]\ttraining's binary_logloss: 0.22217\tvalid_1's binary_logloss: 0.608574\n",
      "[756]\ttraining's binary_logloss: 0.221941\tvalid_1's binary_logloss: 0.608694\n",
      "[757]\ttraining's binary_logloss: 0.221681\tvalid_1's binary_logloss: 0.608729\n",
      "[758]\ttraining's binary_logloss: 0.221445\tvalid_1's binary_logloss: 0.608971\n",
      "[759]\ttraining's binary_logloss: 0.221274\tvalid_1's binary_logloss: 0.609067\n",
      "[760]\ttraining's binary_logloss: 0.221012\tvalid_1's binary_logloss: 0.609236\n",
      "[761]\ttraining's binary_logloss: 0.220795\tvalid_1's binary_logloss: 0.609599\n",
      "[762]\ttraining's binary_logloss: 0.2206\tvalid_1's binary_logloss: 0.609927\n",
      "[763]\ttraining's binary_logloss: 0.220349\tvalid_1's binary_logloss: 0.609986\n",
      "[764]\ttraining's binary_logloss: 0.220163\tvalid_1's binary_logloss: 0.610296\n",
      "[765]\ttraining's binary_logloss: 0.219929\tvalid_1's binary_logloss: 0.610365\n",
      "[766]\ttraining's binary_logloss: 0.219642\tvalid_1's binary_logloss: 0.610054\n",
      "[767]\ttraining's binary_logloss: 0.219466\tvalid_1's binary_logloss: 0.61025\n",
      "[768]\ttraining's binary_logloss: 0.219221\tvalid_1's binary_logloss: 0.610195\n",
      "[769]\ttraining's binary_logloss: 0.218976\tvalid_1's binary_logloss: 0.610208\n",
      "[770]\ttraining's binary_logloss: 0.218699\tvalid_1's binary_logloss: 0.609913\n",
      "[771]\ttraining's binary_logloss: 0.218434\tvalid_1's binary_logloss: 0.609669\n",
      "[772]\ttraining's binary_logloss: 0.218159\tvalid_1's binary_logloss: 0.609811\n",
      "[773]\ttraining's binary_logloss: 0.217903\tvalid_1's binary_logloss: 0.609921\n",
      "[774]\ttraining's binary_logloss: 0.217595\tvalid_1's binary_logloss: 0.609959\n",
      "[775]\ttraining's binary_logloss: 0.217334\tvalid_1's binary_logloss: 0.610154\n",
      "[776]\ttraining's binary_logloss: 0.217119\tvalid_1's binary_logloss: 0.610212\n",
      "[777]\ttraining's binary_logloss: 0.216831\tvalid_1's binary_logloss: 0.610102\n",
      "[778]\ttraining's binary_logloss: 0.216559\tvalid_1's binary_logloss: 0.610004\n",
      "[779]\ttraining's binary_logloss: 0.216374\tvalid_1's binary_logloss: 0.609797\n",
      "[780]\ttraining's binary_logloss: 0.216204\tvalid_1's binary_logloss: 0.609743\n",
      "[781]\ttraining's binary_logloss: 0.215936\tvalid_1's binary_logloss: 0.609707\n",
      "[782]\ttraining's binary_logloss: 0.215682\tvalid_1's binary_logloss: 0.609872\n",
      "[783]\ttraining's binary_logloss: 0.215432\tvalid_1's binary_logloss: 0.609872\n",
      "[784]\ttraining's binary_logloss: 0.215259\tvalid_1's binary_logloss: 0.609783\n",
      "[785]\ttraining's binary_logloss: 0.215009\tvalid_1's binary_logloss: 0.609831\n",
      "[786]\ttraining's binary_logloss: 0.214752\tvalid_1's binary_logloss: 0.610209\n",
      "[787]\ttraining's binary_logloss: 0.214529\tvalid_1's binary_logloss: 0.610404\n",
      "[788]\ttraining's binary_logloss: 0.21428\tvalid_1's binary_logloss: 0.610467\n",
      "[789]\ttraining's binary_logloss: 0.213968\tvalid_1's binary_logloss: 0.610645\n",
      "[790]\ttraining's binary_logloss: 0.213747\tvalid_1's binary_logloss: 0.610421\n",
      "[791]\ttraining's binary_logloss: 0.213496\tvalid_1's binary_logloss: 0.61025\n",
      "[792]\ttraining's binary_logloss: 0.213206\tvalid_1's binary_logloss: 0.610479\n",
      "[793]\ttraining's binary_logloss: 0.213038\tvalid_1's binary_logloss: 0.610527\n",
      "[794]\ttraining's binary_logloss: 0.212825\tvalid_1's binary_logloss: 0.610543\n",
      "[795]\ttraining's binary_logloss: 0.212533\tvalid_1's binary_logloss: 0.610924\n",
      "[796]\ttraining's binary_logloss: 0.212351\tvalid_1's binary_logloss: 0.611094\n",
      "[797]\ttraining's binary_logloss: 0.21208\tvalid_1's binary_logloss: 0.61103\n",
      "[798]\ttraining's binary_logloss: 0.211885\tvalid_1's binary_logloss: 0.611266\n",
      "[799]\ttraining's binary_logloss: 0.211634\tvalid_1's binary_logloss: 0.611289\n",
      "[800]\ttraining's binary_logloss: 0.211388\tvalid_1's binary_logloss: 0.611298\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(learning_rate=0.02, n_estimators=800)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(learning_rate=0.02, n_estimators=800)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(learning_rate=0.02, n_estimators=800)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evals = [(X_tr, y_tr), (X_val, y_val)]\n",
    "lgbm_wrapper.fit(X_tr, y_tr, eval_metric='logloss', eval_set=evals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z3YiAxdOAhqh"
   },
   "source": [
    "### **3-1-g. 위에서 학습시킨 `lgbm_wrapper`의 정확도를 출력하세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "yrG3MF-JAom3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도:0.6768\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "preds= lgbm_wrapper.predict(X_val)\n",
    "lgbm_accuracy = accuracy_score(y_val, preds)\n",
    "\n",
    "print('정확도:{0:.4f}'.format(lgbm_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s5_joSurAjHs"
   },
   "source": [
    "### **3-1-i. 피처 중요도를 중요한 순서대로 시각화 해주세요.**\n",
    "(힌트: 파머완 252 페이지)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "5PG_98tJBfB9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Feature importance'}, xlabel='Feature importance', ylabel='Features'>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6sAAAPvCAYAAAAlK1j/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACbMklEQVR4nOzdeZxO9f//8ec1i2v2GYYxlhlj30XZ11EYRrIVRbIlu48UQjSSbUr0qQ8qshWpSCUGxci+lfKJ9CETWZJthhmNWa7fH35zfV3NYIxh3i6P++02N84573PO61wvTfOc877OZbHZbDYBAAAAAGAQl7wuAAAAAACAfyKsAgAAAACMQ1gFAAAAABiHsAoAAAAAMA5hFQAAAABgHMIqAAAAAMA4hFUAAAAAgHEIqwAAAAAA4xBWAQAAAADGIawCAJBN8+fPl8ViyfLrxRdfvCPn3L9/v6KiohQXF3dHjn874uLiZLFYNH/+/LwuJcdWrVqlqKiovC4DAJAFt7wuAACAe828efNUoUIFh3VFixa9I+fav3+/xo8fr/DwcIWFhd2Rc+RUkSJFtG3bNpUuXTqvS8mxVatW6T//+Q+BFQAMRFgFAOAWValSRTVr1szrMm5LSkqKLBaL3Nxy/qOA1WpV3bp1c7GquycpKUleXl55XQYA4AaYBgwAQC5bunSp6tWrJ29vb/n4+CgiIkI//PCDw5jdu3frySefVFhYmDw9PRUWFqannnpKv//+u33M/Pnz9cQTT0iSmjZtap9ynDHtNiwsTD169Mh0/vDwcIWHh9uXY2NjZbFYtGjRIr3wwgsqVqyYrFarDh06JEn65ptv9Mgjj8jPz09eXl5q0KCBvv3225teZ1bTgKOiomSxWPTTTz/piSeekL+/vwoUKKBhw4YpNTVVBw8eVMuWLeXr66uwsDBFR0c7HDOj1g8//FDDhg1TcHCwPD091aRJk0yvoSR9+eWXqlevnry8vOTr66vmzZtr27ZtDmMyavr+++/1+OOPK3/+/CpdurR69Oih//znP5LkMKU7Y8r1f/7zHzVu3FhBQUHy9vZW1apVFR0drZSUlEyvd5UqVbRr1y41atRIXl5eKlWqlKZMmaL09HSHsRcuXNALL7ygUqVKyWq1KigoSJGRkfrll1/sY65cuaLXXntNFSpUkNVqVaFChdSzZ0/99ddfN+0JADgTwioAALcoLS1NqampDl8ZJk2apKeeekqVKlXSJ598okWLFunixYtq1KiR9u/fbx8XFxen8uXLa8aMGVqzZo2mTp2qkydPqlatWjpz5owkqXXr1po0aZKkq8Fp27Zt2rZtm1q3bp2jukeNGqWjR49q9uzZ+uqrrxQUFKQPP/xQLVq0kJ+fnxYsWKBPPvlEBQoUUERERLYC6/V06tRJDzzwgJYtW6Y+ffpo+vTpev7559WuXTu1bt1an3/+uR5++GGNHDlSy5cvz7T/6NGj9dtvv2nOnDmaM2eOTpw4ofDwcP3222/2MYsXL1bbtm3l5+enJUuWaO7cuTp//rzCw8O1efPmTMfs0KGDypQpo08//VSzZ8/W2LFj9fjjj0uS/bXdtm2bihQpIkk6fPiwunTpokWLFmnlypXq3bu3Xn/9dfXt2zfTsU+dOqWuXbvq6aef1pdffqlWrVpp1KhR+vDDD+1jLl68qIYNG+rdd99Vz5499dVXX2n27NkqV66cTp48KUlKT09X27ZtNWXKFHXp0kVff/21pkyZonXr1ik8PFyXL1/OcU8A4J5jAwAA2TJv3jybpCy/UlJSbEePHrW5ubnZBg8e7LDfxYsXbcHBwbZOnTpd99ipqam2S5cu2by9vW1vvfWWff2nn35qk2TbsGFDpn1KlChh6969e6b1TZo0sTVp0sS+vGHDBpskW+PGjR3GJSYm2goUKGBr06aNw/q0tDTbAw88YKtdu/YNXg2b7ciRIzZJtnnz5tnXvfLKKzZJtmnTpjmMrV69uk2Sbfny5fZ1KSkptkKFCtk6dOiQqdYHH3zQlp6ebl8fFxdnc3d3tz377LP2GosWLWqrWrWqLS0tzT7u4sWLtqCgIFv9+vUz1TRu3LhM1zBw4EBbdn4cSktLs6WkpNgWLlxoc3V1tZ07d86+rUmTJjZJth07djjsU6lSJVtERIR9+dVXX7VJsq1bt+6651myZIlNkm3ZsmUO63ft2mWTZJs5c+ZNawUAZ8GdVQAAbtHChQu1a9cuhy83NzetWbNGqampeuaZZxzuunp4eKhJkyaKjY21H+PSpUsaOXKkypQpIzc3N7m5ucnHx0eJiYk6cODAHam7Y8eODstbt27VuXPn1L17d4d609PT1bJlS+3atUuJiYk5Otejjz7qsFyxYkVZLBa1atXKvs7NzU1lypRxmPqcoUuXLrJYLPblEiVKqH79+tqwYYMk6eDBgzpx4oS6desmF5f/+3HGx8dHHTt21Pbt25WUlHTD67+ZH374QY899pgCAwPl6uoqd3d3PfPMM0pLS9Ovv/7qMDY4OFi1a9d2WFetWjWHa1u9erXKlSunZs2aXfecK1euVEBAgNq0aePQk+rVqys4ONjh3xAAODsesAQAwC2qWLFilg9Y+vPPPyVJtWrVynK/a0NVly5d9O2332rs2LGqVauW/Pz8ZLFYFBkZecememZMb/1nvRlTYbNy7tw5eXt73/K5ChQo4LCcL18+eXl5ycPDI9P6hISETPsHBwdnue7HH3+UJJ09e1ZS5muSrj6ZOT09XefPn3d4iFJWY6/n6NGjatSokcqXL6+33npLYWFh8vDw0M6dOzVw4MBMPQoMDMx0DKvV6jDur7/+Umho6A3P++eff+rChQvKly9fltszpogDwP2AsAoAQC4pWLCgJOmzzz5TiRIlrjsuPj5eK1eu1CuvvKKXXnrJvj45OVnnzp3L9vk8PDyUnJycaf2ZM2fstVzr2juV19b79ttvX/epvoULF852Pbnp1KlTWa7LCIUZf2a81/NaJ06ckIuLi/Lnz++w/p/XfyMrVqxQYmKili9f7tDLvXv3ZvsY/1SoUCH98ccfNxxTsGBBBQYGKiYmJsvtvr6+OT4/ANxrCKsAAOSSiIgIubm56fDhwzeccmqxWGSz2WS1Wh3Wz5kzR2lpaQ7rMsZkdbc1LCxMP/30k8O6X3/9VQcPHswyrP5TgwYNFBAQoP3792vQoEE3HX83LVmyRMOGDbMHzN9//11bt27VM888I0kqX768ihUrpsWLF+vFF1+0j0tMTNSyZcvsTwi+mWtfX09PT/v6jONd2yObzab3338/x9fUqlUrjRs3TuvXr9fDDz+c5ZhHH31UH3/8sdLS0lSnTp0cnwsAnAFhFQCAXBIWFqZXX31VY8aM0W+//aaWLVsqf/78+vPPP7Vz5055e3tr/Pjx8vPzU+PGjfX666+rYMGCCgsL08aNGzV37lwFBAQ4HLNKlSqSpPfee0++vr7y8PBQyZIlFRgYqG7duunpp5/WgAED1LFjR/3++++Kjo5WoUKFslWvj4+P3n77bXXv3l3nzp3T448/rqCgIP3111/68ccf9ddff2nWrFm5/TJly+nTp9W+fXv16dNH8fHxeuWVV+Th4aFRo0ZJujqlOjo6Wl27dtWjjz6qvn37Kjk5Wa+//rouXLigKVOmZOs8VatWlSRNnTpVrVq1kqurq6pVq6bmzZsrX758euqppzRixAj9/fffmjVrls6fP5/jaxo6dKiWLl2qtm3b6qWXXlLt2rV1+fJlbdy4UY8++qiaNm2qJ598Uh999JEiIyP1r3/9S7Vr15a7u7v++OMPbdiwQW3btlX79u1zXAMA3Et4wBIAALlo1KhR+uyzz/Trr7+qe/fuioiI0IgRI/T777+rcePG9nGLFy9W06ZNNWLECHXo0EG7d+/WunXr5O/v73C8kiVLasaMGfrxxx8VHh6uWrVq6auvvpJ09X2v0dHRWrNmjR599FHNmjVLs2bNUrly5bJd79NPP60NGzbo0qVL6tu3r5o1a6Z//etf+v777/XII4/kzouSA5MmTVKJEiXUs2dP9erVS0WKFNGGDRtUunRp+5guXbpoxYoVOnv2rDp37qyePXvKz89PGzZsUMOGDbN1ni5duujZZ5/VzJkzVa9ePdWqVUsnTpxQhQoVtGzZMp0/f14dOnTQ4MGDVb16df373//O8TX5+vpq8+bN6t27t9577z21bt1affr00cGDB1W0aFFJkqurq7788kuNHj1ay5cvV/v27dWuXTtNmTJFHh4e9nANAPcDi81ms+V1EQAAAJIUGxurpk2b6tNPP73hg58AAM6PO6sAAAAAAOMQVgEAAAAAxmEaMAAAAADAONxZBQAAAAAYh7AKAAAAADAOYRUAAAAAYBy3vC4A94f09HSdOHFCvr6+slgseV0OAAAAgDxis9l08eJFFS1aVC4u179/SljFXXHixAmFhITkdRkAAAAADHHs2DEVL178utsJq7grfH19JUlHjhxRgQIF8rga3K6UlBStXbtWLVq0kLu7e16Xg1xAT50L/XQu9NP50FPnQj9vXUJCgkJCQuwZ4XoIq7grMqb++vr6ys/PL4+rwe1KSUmRl5eX/Pz8+KbsJOipc6GfzoV+Oh966lzoZ87d7O2BPGAJAAAAAGAcwioAAAAAwDiEVQAAAACAcQirAAAAAADjEFYBAAAAAMYhrAIAAAAAjENYBQAAAAAYh7AKAAAAADAOYRUAAAAAYBzCKgAAAADAOIRVAAAAAIBxCKsAAAAAAOMQVgEAAAAAxiGsAgAAAACMQ1gFAAAAABiHsAoAAAAAMA5hFQAAAABgHMIqAAAAAMA4hFUAAAAAgHEIqwAAAAAA4xBWAQAAAADGIawCAAAAAIxDWAUAAAAAGIewCgAAAAAwDmEVAAAAAGAcwioAAAAAwDiEVQAAAACAcQirAAAAAADjEFYBAAAAAMYhrAIAAAAAjENYBQAAAAAYh7AKAAAAADAOYRUAAAAAYBzCKgAAAADAOIRVAAAAAIBxCKsAAAAAAOMQVgEAAAAAxiGsAgAAAACMQ1gFAAAAABiHsAoAAAAAMA5hFQAAAABgHMIqAAAAAMA4hFUAAAAAgHEIqwAAAAAA4xBWAQAAAADGIawCAAAAAIxDWAUAAAAAGIewCgAAAAAwDmEVAAAAAGAcwioAAAAAwDiEVQAAAACAcQirAAAAAADjEFYBAAAAAMYhrAIAAAAAjENYBQAAAAAYh7AKAAAAADAOYRUAAAAAYBzCKgAAAADAOIRVAAAAAIBxCKsAAAAAAOMQVgEAAAAAxiGsAgAAAACMQ1gFAAAAABiHsAoAAAAAMA5hFQAAAABgHMIqAAAAAMA4hFUAAAAAgHEIqwAAAAAA4xBWAQAAAADGIawCAAAAAIxDWAUAAAAAGIewCgAAAAAwDmEVAAAAAGAcwioAAAAAwDiEVQAAAACAcQirAAAAAADjEFYBAAAAAMYhrAIAAAAAjENYBQAAAAAYh7AKAAAAADCOxWaz2fK6CDi/hIQE+fv7q/QLS5Xq5p3X5eA2WV1tiq6dphE7XZWcZsnrcpAL6KlzoZ/OhX46H3rqXG7Uz7gprfOoKrNlZIP4+Hj5+flddxx3VgEAAAAAxiGsAgAAAACMQ1gFAAAAABiHsHqfiIqKUvXq1e3LPXr0ULt27W64T3h4uIYOHXpH6wIAAACc2axZs1StWjX5+fnJz89P9erV0+rVq+3bbTaboqKiVLRoUXl6eio8PFw///yzffu5c+c0ePBglS9fXl5eXgoNDdWQIUMUHx+f5fmSk5NVvXp1WSwW7d27905f3h1FWL1HnD59Wn379lVoaKisVquCg4MVERGhbdu25eh4b731lubPn5+7RQIAAABwULx4cU2ZMkW7d+/W7t279fDDD6tt27b2QBodHa0333xT77zzjnbt2qXg4GA1b95cFy9elCSdOHFCJ06c0BtvvKF9+/Zp/vz5iomJUe/evbM834gRI1S0aNG7dn13klteF4Ds6dixo1JSUrRgwQKVKlVKf/75p7799ludO3cuR8fz9/fP5QoBAAAA/FObNm0clidOnKhZs2Zp+/btqlSpkmbMmKExY8aoQ4cOkqQFCxaocOHCWrx4sfr27asqVapo2bJl9v1Lly6tiRMn6umnn1Zqaqrc3P4v0q1evVpr167VsmXLHO7e3qu4s3oPuHDhgjZv3qypU6eqadOmKlGihGrXrq1Ro0apdeurj8M+evSo2rZtKx8fH/n5+alTp076888/r3vMf04DTkxM1DPPPCMfHx8VKVJE06ZNy7TPzJkzVbZsWXl4eKhw4cJ6/PHHc/1aAQAAAGeVlpamjz/+WImJiapXr56OHDmiU6dOqUWLFvYxVqtVTZo00datW697nIyPfLk2qP7555/q06ePFi1aJC8vrzt6HXcLd1bvAT4+PvLx8dGKFStUt25dWa1Wh+02m03t2rWTt7e3Nm7cqNTUVA0YMECdO3dWbGxsts4xfPhwbdiwQZ9//rmCg4M1evRo7dmzx/4+1927d2vIkCFatGiR6tevr3PnzmnTpk3XPV5ycrKSk5PtywkJCZIkq4tNrq58tO+9zupic/gT9z566lzop3Ohn86HnjqXG/UzJSVFkrRv3z41btxYf//9t3x8fPTpp5+qbNmy9rf0FShQwD5WkgoVKqSjR486rMtw9uxZTZgwQc8++6x9u81mU/fu3dWnTx898MADiouLs58/q2PktezWRFi9B7i5uWn+/Pnq06ePZs+erQcffFBNmjTRk08+qWrVqumbb77RTz/9pCNHjigkJESStGjRIlWuXFm7du1SrVq1bnj8S5cuae7cuVq4cKGaN28u6er0g+LFi9vHHD16VN7e3nr00Ufl6+urEiVKqEaNGtc95uTJkzV+/PhM61+ukS4vr7ScvAww0ISa6XldAnIZPXUu9NO50E/nQ0+dS1b9XLVqlaSr4eyNN95QYmKitm3bpm7dumnixIlKTEyUJK1fv14FChSw73f06FGdOXPGvn+GpKQkRUVFqWDBgqpZs6Z9+8qVK/X777/rueee06pVq+wzLDdv3qwTJ07ckeu9HUlJSdkaR1i9R3Ts2FGtW7fWpk2btG3bNsXExCg6Olpz5sxRQkKCQkJC7EFVkipVqqSAgAAdOHDgpmH18OHDunLliurVq2dfV6BAAZUvX96+3Lx5c5UoUUKlSpVSy5Yt1bJlS7Vv3/66UwxGjRqlYcOG2ZczanztBxelurvm9GWAIawuNk2oma6xu12UnG7J63KQC+ipc6GfzoV+Oh966lxu1M//RkVkGj9kyBC1bNlSP/74o1588UW99NJLqly5ssONoDlz5qhy5cqKjIy0r7t48aJat26t4sWLa8WKFfLw8LBvmzt3rn799Vd16tTJ4VzDhw/XU089pQ8++CC3LjdXZMy6vBnC6j3Ew8NDzZs3V/PmzTVu3Dg9++yzeuWVVzRs2DBZLJm/0dlstizXZzXuZnx9ffX9998rNjZWa9eu1bhx4xQVFaVdu3YpICAg03ir1ZppurIkJadblJrGN2VnkZxuUTL9dCr01LnQT+dCP50PPXUuWfXT3d39uuNTUlJUrlw5BQcHKzY2VrVr15YkXblyRZs2bdLUqVPt+yckJKh169ayWq366quvMt0weueddzRp0iT78okTJxQREaGlS5eqTp06N6wjL2S3Hh6wdA+rVKmSEhMTValSJR09elTHjh2zb9u/f7/i4+NVsWLFmx6nTJkycnd31/bt2+3rzp8/r19//dVhnJubm5o1a6bo6Gj99NNPiouL0/r163PvggAAAAAnM3r0aG3atElxcXHat2+fxowZo9jYWHXt2lUWi0VDhw7VpEmT9Pnnn+u///2vevToIS8vL3Xp0kXS1TuqLVq0UGJioubOnauEhASdOnVKp06dUlra1bfXhYaGqkqVKvavcuXKSbr65OBr39p3r+HO6j3g7NmzeuKJJ9SrVy9Vq1ZNvr6+2r17t6Kjo9W2bVs1a9ZM1apVU9euXTVjxgz7A5aaNGmimjVr3vT4Pj4+6t27t4YPH67AwEAVLlxYY8aMkYvL//0uY+XKlfrtt9/UuHFj5c+fX6tWrVJ6errDVGEAAAAAjv78809169ZNJ0+elL+/v6pVq6aYmBj7s2JGjBihy5cva8CAATp//rzq1KmjtWvXytfXV5K0Z88e7dixQ9LVm0zXOnLkiMLCwu7q9dxNhNV7gI+Pj+rUqaPp06fr8OHDSklJUUhIiPr06aPRo0fLYrFoxYoVGjx4sBo3biwXFxe1bNlSb7/9drbP8frrr+vSpUt67LHH5OvrqxdeeEHx8fH27QEBAVq+fLmioqL0999/q2zZslqyZIkqV658Jy4ZAAAAcApz58694XaLxaKoqChFRUVluT08PDxbb9u7VlhY2C3vYyKLzRmuAsZLSEiQv7+/Sr+wVKlu3nldDm6T1dWm6NppGrHTlffaOAl66lzop3Ohn86HnjqXG/UzbkrrPKrKbBnZIOPzYq+H96wCAAAAAIxDWAUAAAAAGIdpwLgrMm71nzlzRoGBgXldDm5TSkqKVq1apcjISOMehY6coafOhX46F/rpfOipc6Gft45pwAAAAACAexZhFQAAAABgHMIqAAAAAMA4hFUAAAAAgHEIqwAAAAAA4xBWAQAAAADGIawCAAAAAIxDWAUAAAAAGIewCgAAAAAwDmEVAAAAAGAcwioAAAAAwDiEVQAAAACAcQirAAAAAADjEFYBAAAAAMYhrAIAAAAAjENYBQAAAAAYh7AKAAAAADAOYRUAAAAAYBzCKgAAAADAOIRVAAAAAIBxCKsAAAAAAOMQVgEAAAAAxiGsAgAAAACMQ1gFAAAAABiHsAoAAAAAMA5hFQAAAABgHMIqAAAAAMA4hFUAAAAAgHEIqwAAAAAA4xBWAQAAAADGIawCAAAAAIxDWAUAAAAAGIewCgAAAAAwDmEVAAAAAGAcwioAAAAAwDiEVQAAAACAcQirAAAAAADjEFYBAAAAAMYhrAIAAAAAjENYBQAAAAAYh7AKAAAAADAOYRUAAAAAYBzCKgAAAADAOIRVAAAAAIBxCKsAAAAAAOMQVgEAAAAAxiGsAgAAAACMQ1gFAAAAABiHsAoAAAAAMA5hFQAAAABgHMIqAAAAAMA4hFUAAAAAgHEIqwAAAAAA4xBWAQAAAADGIawCAAAAAIxDWAUAAAAAGIewCgAAAAAwDmEVAAAAAGAcwioAAAAAwDiEVQAAAACAcQirAAAAAADjEFYBAAAAAMYhrAIAAAAAjENYBQAAAAAYh7AKAAAAADAOYRUAAAAAYBzCKgAAAADAOIRVAAAAAIBxCKsAAAAAAOMQVgEAAAAAxiGsAgAAAACMQ1gFAAAAABiHsAoAAAAAMI7FZrPZ8roIOL+EhAT5+/ur9AtLlermndfl4DZZXW2Krp2mETtdlZxmyetykAvoqXOhn86Ffjofeupcsupn3JTWeVyV2TKyQXx8vPz8/K47jjurAAAAAADjEFYBAAAAAMYhrAIAAAAAjENYBQAAAIBcNmvWLFWrVk1+fn7y8/NTvXr1tHr1avt2m82mqKgoFS1aVJ6engoPD9fPP//scIz33ntP4eHh8vPzk8Vi0YULFzKd57HHHlNoaKg8PDxUpEgRdevWTSdOnLjTl3dXEFbvQbGxsdf9xwoAAAAg7xUvXlxTpkzR7t27tXv3bj388MNq27atPZBGR0frzTff1DvvvKNdu3YpODhYzZs318WLF+3HSEpKUsuWLTV69Ojrnqdp06b65JNPdPDgQS1btkyHDx/W448/fsev725wy+sCnEGPHj104cIFrVixwmF9bGysmjZtqvPnzysgICBPagMAAABw97Vp08ZheeLEiZo1a5a2b9+uSpUqacaMGRozZow6dOggSVqwYIEKFy6sxYsXq2/fvpKkoUOHSrqaK67n+eeft/+9RIkSeumll9SuXTulpKTI3d09dy/qLuPOqsGuXLmS1yUAAAAAuE1paWn6+OOPlZiYqHr16unIkSM6deqUWrRoYR9jtVrVpEkTbd26NcfnOXfunD766CPVr1//ng+qEmH1rjl79qyeeuopFS9eXF5eXqpataqWLFniMCY8PFyDBg3SsGHDVLBgQTVv3lyStGrVKpUrV06enp5q2rSp4uLiHPabP3++AgICtGbNGlWsWFE+Pj5q2bKlTp486TBu3rx5qlixojw8PFShQgXNnDnTvu3KlSsaNGiQihQpIg8PD4WFhWny5Mn27VFRUQoNDZXValXRokU1ZMiQXH6FAAAAAOeyb98++fj4yGq1ql+/fvr8889VqVIlnTp1SpJUuHBhh/GFCxe2b7sVI0eOlLe3twIDA3X06FF98cUXuVJ/XmMa8F3y999/66GHHtLIkSPl5+enr7/+Wt26dVOpUqVUp04d+7gFCxaof//+2rJli2w2m44dO6YOHTqoX79+6t+/v3bv3q0XXngh0/GTkpL0xhtvaNGiRXJxcdHTTz+tF198UR999JEk6f3339crr7yid955RzVq1NAPP/ygPn36yNvbW927d9e///1vffnll/rkk08UGhqqY8eO6dixY5Kkzz77TNOnT9fHH3+sypUr69SpU/rxxx9veL3JyclKTk62LyckJEiSrC42ubrabvv1RN6yutgc/sS9j546F/rpXOin86GnziWrfqakpEiSSpUqpV27dik+Pl7Lly9X9+7d9c033yg1NVWSlJqaah8rXb0De+3+GTLGp6SkZNomXZ0u/Mwzz+jo0aN67bXX1K1bN61YsUIWiyUXrzT3ZHUNWSGs5pKVK1fKx8fHYV3GPzZJKlasmF588UX78uDBgxUTE6NPP/3UIayWKVNG0dHR9uXRo0erVKlSmj59uiwWi8qXL699+/Zp6tSpDudKSUnR7NmzVbp0aUnSoEGD9Oqrr9q3T5gwQdOmTbPPiS9ZsqT279+vd999V927d9fRo0dVtmxZNWzYUBaLRSVKlLDve/ToUQUHB6tZs2Zyd3dXaGioateufcPXY/LkyRo/fnym9S/XSJeXV1oWe+BeNKFmel6XgFxGT50L/XQu9NP50FPncm0/V61alWl7gwYNtGbNGo0YMcL+M/myZctUqlQp+5j//ve/8vb2zrT/vn37JElr167NlDn+qVevXnr22Wc1ffp0VahQIcfXcyclJSVlaxxhNZc0bdpUs2bNcli3Y8cOPf3005KuBtcpU6Zo6dKlOn78uP3Oo7e3t8M+NWvWdFg+cOCA6tat6/BbkXr16mU6v5eXlz2oSlKRIkV0+vRpSdJff/2lY8eOqXfv3urTp499TGpqqvz9/SVdfUhU8+bNVb58ebVs2VKPPvqofQ79E088oRkzZqhUqVJq2bKlIiMj1aZNG7m5Xf+fz6hRozRs2DD7ckJCgkJCQvTaDy5KdXe97n64N1hdbJpQM11jd7soOd3M39jh1tBT50I/nQv9dD701Llk1c//RkVkOfatt95S4cKF1bNnT0VFRenvv/9WZGSkpKtvy+vevbsmTZpkX5chIzO0aNHipg9uzZgd+dBDD6lJkya3c2l3TMasy5shrOYSb29vlSlTxmHdH3/8Yf/7tGnTNH36dM2YMUNVq1aVt7e3hg4dmukhSv8MrzZb9qaH/PMN1BaLxb5vevrV3/K8//77DndxJcnV9WpwfPDBB3XkyBGtXr1a33zzjTp16qRmzZrps88+U0hIiA4ePKh169bpm2++0YABA/T6669r48aN133jttVqldVqzbQ+Od2i1DS+KTuL5HSLkumnU6GnzoV+Ohf66XzoqXO5tp/u7u4aPXq0WrVqpZCQEF28eFEff/yxNm7cqJiYGOXLl09Dhw7V5MmTVaFCBZUtW1aTJk2Sl5eXunXrZv8Z+9SpUzp16pT9mTW//PKLfH19FRoaqgIFCmjnzp3auXOnGjZsqPz58+u3337TuHHjVLp0aTVq1MjYhyxlty7C6l2yadMmtW3b1n6nNT09Xf/73/9UsWLFG+5XqVKlTB+Js3379ls6d+HChVWsWDH99ttv6tq163XH+fn5qXPnzurcubMef/xxtWzZUufOnVOBAgXk6empxx57TI899pgGDhyoChUqaN++fXrwwQdvqRYAAADgfvDnn3+qW7duOnnypPz9/VWtWjXFxMTYH6I6YsQIXb58WQMGDND58+dVp04drV27Vr6+vvZjzJ492+GtdY0bN5Z09cGpPXr0kKenp5YvX65XXnlFiYmJKlKkiFq2bKmPP/44yxtH9xrC6l1SpkwZLVu2TFu3blX+/Pn15ptv6tSpUzcNq/369dO0adM0bNgw9e3bV3v27NH8+fNv+fxRUVEaMmSI/Pz81KpVKyUnJ2v37t06f/68hg0bpunTp6tIkSKqXr26XFxc9Omnnyo4OFgBAQGaP3++0tLSVKdOHXl5eWnRokXy9PR0eF8rAAAAgP8zd+7cG263WCyKiopSVFTUdcfcbHvVqlW1fv36HFZoPj665i4ZO3asHnzwQUVERCg8PFzBwcFq167dTfcLDQ3VsmXL9NVXX+mBBx7Q7NmzNWnSpFs+/7PPPqs5c+Zo/vz5qlq1qpo0aaL58+erZMmSkiQfHx9NnTpVNWvWVK1atRQXF6dVq1bJxcVFAQEBev/999WgQQNVq1ZN3377rb766isFBgbech0AAAAAkB0WW3bfFAnchoSEBPn7+6v0C0uV6uZ98x1gNKurTdG10zRipyvvtXES9NS50E/nQj+dDz11Lln1M25K6zyuymwZ2SA+Pl5+fn7XHcedVQAAAACAcQirAAAAAADjMA0Yd0XGrf4zZ87wXlcnkJKSolWrVikyMtLYR6Lj1tBT50I/nQv9dD701LnQz1vHNGAAAAAAwD2LsAoAAAAAMA5hFQAAAABgHMIqAAAAAMA4hFUAAAAAgHEIqwAAAAAA4xBWAQAAAADGIawCAAAAAIxDWAUAAAAAGIewCgAAAAAwDmEVAAAAAGAcwioAAAAAwDiEVQAAAACAcQirAAAAAADjEFYBAAAAAMYhrAIAAAAAjENYBQAAAAAYh7AKAAAAADAOYRUAAAAAYBzCKgAAAADAOIRVAAAAAIBxCKsAAAAAAOMQVgEAAAAAxiGsAgAAAACMQ1gFAAAAABiHsAoAAAAAMA5hFQAAAABgHMIqAAAAAMA4hFUAAAAAgHEIqwAAAAAA4xBWAQAAAADGIawCAAAAAIxDWAUAAAAAGIewCgAAAAAwDmEVAAAAAGAcwioAAAAAwDiEVQAAAACAcQirAAAAAADjEFYBAAAAAMYhrAIAAAAAjENYBQAAAAAYh7AKAAAAADAOYRUAAAAAYBzCKgAAAADAOIRVAAAAAIBxCKsAAAAAAOMQVgEAAAAAxiGsAgAAAACMQ1gFAAAAABiHsAoAAAAAMA5hFQAAAABgHMIqAAAAAMA4hFUAAAAAgHEIqwAAAAAA4xBWAQAAAADGIawCAAAAAIxDWAUAAAAAGIewCgAAAAAwDmEVAAAAAGAcwioAAAAAwDiEVQAAAACAcQirAAAAAADjEFYBAAAAAMYhrAIAAAAAjENYBQAAAAAYh7AKAAAAADAOYRUAAAAAYBzCKgAAAADAOIRVAAAAAIBxCKsAAAAAAOMQVgEAAAAAxiGsAgAAAACMQ1gFAAAAABjHYrPZbHldBJxfQkKC/P39VfqFpUp1887rcnCbrK42RddO04idrkpOs+R1OcgF9NS50E/nQj+dDz11Lv/sZ9yU1nldkvEyskF8fLz8/PyuO447qwAAAAAA4xBWAQAAAADGIawCAAAAAIxDWM2CxWLRihUrrrs9NjZWFotFFy5cuGs13aqbXQMAAACAO2PWrFmqVq2a/Pz85Ofnp3r16mn16tX27TabTVFRUSpatKg8PT0VHh6un3/+2eEY7733nsLDw+Xn53fd7DFx4kTVr19fXl5eCggIuMNXdffdl2H11KlTGjx4sEqVKiWr1aqQkBC1adNG3377bV6XlmtOnjypVq1a5XUZAAAAwH2nePHimjJlinbv3q3du3fr4YcfVtu2be2BNDo6Wm+++abeeecd7dq1S8HBwWrevLkuXrxoP0ZSUpJatmyp0aNHX/c8V65c0RNPPKH+/fvf8WvKC255XcDdFhcXpwYNGiggIEDR0dGqVq2aUlJStGbNGg0cOFC//PLLXanjypUrypcv3x07fnBw8B07NgAAAIDra9OmjcPyxIkTNWvWLG3fvl2VKlXSjBkzNGbMGHXo0EGStGDBAhUuXFiLFy9W3759JUlDhw6VdHVW5/WMHz9ekjR//vxcvwYT3Hd3VgcMGCCLxaKdO3fq8ccfV7ly5VS5cmUNGzZM27dvt487c+aM2rdvLy8vL5UtW1ZffvnlDY+7bNkyVa5cWVarVWFhYZo2bZrD9rCwML322mvq0aOH/P391adPH0nSyJEjVa5cOXl5ealUqVIaO3asUlJS7PtFRUWpevXq+uCDDxQaGiofHx/1799faWlpio6OVnBwsIKCgjRx4kSH8107DTguLk4Wi0XLly9X06ZN5eXlpQceeEDbtm1z2Gfr1q1q3LixPD09FRISoiFDhigxMdG+febMmSpbtqw8PDxUuHBhPf7449l/4QEAAID7UFpamj7++GMlJiaqXr16OnLkiE6dOqUWLVrYx1itVjVp0kRbt27Nw0rNc1/dWT137pxiYmI0ceJEeXtn/qzPa+d5jx8/XtHR0Xr99df19ttvq2vXrvr9999VoECBTPvt2bNHnTp1UlRUlDp37qytW7dqwIABCgwMVI8ePezjXn/9dY0dO1Yvv/yyfZ2vr6/mz5+vokWLat++ferTp498fX01YsQI+5jDhw9r9erViomJ0eHDh/X444/ryJEjKleunDZu3KitW7eqV69eeuSRR1S3bt3rXv+YMWP0xhtvqGzZshozZoyeeuopHTp0SG5ubtq3b58iIiI0YcIEzZ07V3/99ZcGDRqkQYMGad68edq9e7eGDBmiRYsWqX79+jp37pw2bdp03XMlJycrOTnZvpyQkCBJsrrY5OrKR/ve66wuNoc/ce+jp86FfjoX+ul86Klz+Wc/M2487du3T40bN9bff/8tHx8fffrppypbtqz9hlGBAgUcblIVKlRIR48edVgnSampqfbj/nNbhrS0NIdzmy67dVpsNtt981/Jzp07VadOHS1fvlzt27e/7jiLxaKXX35ZEyZMkCQlJibK19dXq1atUsuWLRUbG6umTZvq/PnzCggIUNeuXfXXX39p7dq19mOMGDFCX3/9tX1eelhYmGrUqKHPP//8hjW+/vrrWrp0qXbv3i3p6p3V119/XadOnZKvr68kqWXLljp48KAOHz4sF5erN8crVKigHj166KWXXrJfw+eff6527dopLi5OJUuW1Jw5c9S7d29J0v79+1W5cmUdOHBAFSpU0DPPPCNPT0+9++679lo2b96sJk2aKDExUatWrVLPnj31xx9/2Ou4kaioKPu0hGstXrxYXl5eN90fAAAAuJelpKTozJkzSkxM1LZt27Ru3TpNnDhRiYmJeumll/TBBx843Aj7z3/+ozNnzuiVV15xOM6+ffs0duxYffjhh/Lx8cnyXN9++63mzp2rxYsX39Fryi1JSUnq0qWL4uPj5efnd91x99Wd1YxcbrFYbjq2WrVq9r97e3vL19dXp0+fznLsgQMH1LZtW4d1DRo00IwZM5SWliZXV1dJUs2aNTPt+9lnn2nGjBk6dOiQLl26pNTU1EwNCwsLcwiIhQsXlqurqz2oZqy7Xn1ZXVORIkUkSadPn1aFChW0Z88eHTp0SB999JF9jM1mU3p6uo4cOaLmzZurRIkSKlWqlFq2bKmWLVvap0lnZdSoURo2bJh9OSEhQSEhIXrtBxelurvesE6Yz+pi04Sa6Rq720XJ6Tf/7wnmo6fOhX46F/rpfOipc/lnP/8bFZFpzJAhQ9SyZUv9+OOPevHFF/XSSy+pcuXKqlGjhn3MnDlzVLlyZUVGRjrsmzEjtEWLFtd94u+ZM2fk7u6eaV9TZcy6vJn7KqyWLVtWFotFBw4cULt27W441t3d3WHZYrEoPT09y7E2my1TAM7qhvU/px5v375dTz75pMaPH6+IiAj5+/vr448/zvR+16xquZX6sjpORr0Z+6Snp6tv374aMmRIpv1CQ0OVL18+ff/994qNjdXatWs1btw4RUVFadeuXVn+R2O1WmW1WjOtT063KDWNb8rOIjndomT66VToqXOhn86FfjofeupcMvr5z5/Tr5WSkqJy5copODhYsbGxql27tqSrD1/dtGmTpk6dmml/N7erkc3d3f26x864OXajc5sku3XeV2G1QIECioiI0H/+8x8NGTIkU3i8cOFCjj6fqFKlStq8ebPDuq1bt6pcuXL2fzhZ2bJli0qUKKExY8bY1/3++++3fP7c8OCDD+rnn39WmTJlrjvGzc1NzZo1U7NmzfTKK68oICBA69evtz/FDAAAAIA0evRotWrVSiEhIbp48aI+/vhjxcbGKiYmRhaLRUOHDtWkSZNUtmxZlS1bVpMmTZKXl5e6dOliP8apU6d06tQpHTp0SNLV6cC+vr4KDQ21Tx8+evSozp07p6NHjyotLU179+6VJJUpU+a6U4bvJfdVWJWuPtG2fv36ql27tl599VVVq1ZNqampWrdunWbNmqUDBw7c8jFfeOEF1apVSxMmTFDnzp21bds2vfPOO5o5c+YN9ytTpoyOHj2qjz/+WLVq1dLXX3990/e03ikjR45U3bp1NXDgQPXp00fe3t46cOCA1q1bp7ffflsrV67Ub7/9psaNGyt//vxatWqV0tPTVb58+TypFwAAADDVn3/+qW7duunkyZPy9/dXtWrVFBMTo+bNm0u6+nyby5cva8CAATp//rzq1KmjtWvXOrz1b/bs2Q7PgGncuLEkad68efaHuI4bN04LFiywj8mYVrxhwwaFh4ff4au88+67sFqyZEl9//33mjhxol544QWdPHlShQoV0kMPPaRZs2bl6JgPPvigPvnkE40bN04TJkxQkSJF9Oqrrzo8CTgrbdu21fPPP69BgwYpOTlZrVu31tixYxUVFZWjOm5HtWrVtHHjRo0ZM0aNGjWSzWZT6dKl1blzZ0lXn5S8fPlyRUVF6e+//1bZsmW1ZMkSVa5c+a7XCgAAAJhs7ty5N9xusVgUFRV1w5/7b7Zduvr5qs76GavSffY0YOSdhIQE+fv7q/QLS5Xqlvljg3BvsbraFF07TSN2uvJeGydBT50L/XQu9NP50FPn8s9+xk1pndclGS8jG9zsacAu190CAAAAAEAeIawCAAAAAIzDNGDcFRm3+s+cOaPAwMC8Lge3KSUlRatWrVJkZOQ984h03Bg9dS7007nQT+dDT50L/bx1TAMGAAAAANyzCKsAAAAAAOMQVgEAAAAAxiGsAgAAAACMQ1gFAAAAABiHsAoAAAAAMA5hFQAAAABgHMIqAAAAAMA4hFUAAAAAgHEIqwAAAAAA4xBWAQAAAADGIawCAAAAAIxDWAUAAAAAGIewCgAAAAAwDmEVAAAAAGAcwioAAAAAwDiEVQAAAACAcQirAAAAAADjEFYBAAAAAMYhrAIAAAAAjENYBQAAAAAYh7AKAAAAADAOYRUAAAAAYBzCKgAAAADAOIRVAAAAAIBxCKsAAAAAAOMQVgEAAAAAxiGsAgAAAACMQ1gFAAAAABiHsAoAAAAAMA5hFQAAAABgHMIqAAAAAMA4hFUAAAAAgHEIqwAAAAAA4xBWAQAAAADGIawCAAAAAIxDWAUAAAAAGIewCgAAAAAwDmEVAAAAAGAcwioAAAAAwDiEVQAAAACAcQirAAAAAADjEFYBAAAAAMYhrAIAAAAAjENYBQAAAAAYh7AKAAAAADAOYRUAAAAAYBzCKgAAAADAOIRVAAAAAIBxCKsAAAAAAOMQVgEAAAAAxiGsAgAAAACMQ1gFAAAAABiHsAoAAAAAMA5hFQAAAABgHMIqAAAAAMA4hFUAAAAAgHEIqwAAAAAA4xBWAQAAAADGIawCAAAAAIxDWAUAAAAAGIewCgAAAAAwDmEVAAAAAGAcwioAAAAAwDiEVQAAAACAcQirAAAAAADjEFYBAAAAAMYhrAIAAAAAjENYBQAAAAAYh7AKAAAAADAOYRUAAAAAYBzCKgAAAADAOIRVAAAAAIBx3PK6ANxf6kz+Vqlu3nldBm6T1dWm6NpSlag1Sk6z5HU5yAX01LnQT+dCP50PPb1z4qa0zusSkIu4swoAAAAAMA5hFQAAAABgHMIqAAAAAMA4hFXcUFhYmGbMmJHXZQAAAADZMnnyZNWqVUu+vr4KCgpSu3btdPDgQYcxly5d0qBBg1S8eHF5enqqYsWKmjVrln17XFycLBZLll+ffvqpfdz58+fVo0cPdenSRQULFlS3bt104cKFu3WpTo+wCgAAAMBpbNy4UQMHDtT27du1bt06paamqkWLFkpMTLSPef755xUTE6MPP/xQBw4c0PPPP6/Bgwfriy++kCSFhITo5MmTDl/jx4+Xt7e3WrVqZT9Oly5d9OOPP2rcuHFauXKl9u7dq27dut31a3ZWPA0YAAAAgNOIiYlxWJ43b56CgoK0Z88eNW7cWJK0bds2de/eXeHh4ZKk5557Tu+++652796ttm3bytXVVcHBwQ7H+fzzz9W5c2f5+PhIkg4cOKCYmBht3rxZZ86cUd26dfX++++rXr16OnjwoMqXL3/nL9bJcWf1PhceHq5BgwZp0KBBCggIUGBgoF5++WXZbDb7mKSkJPXq1Uu+vr4KDQ3Ve++9l4cVAwAAANkXHx8vSSpQoIB9XcOGDfXll1/q+PHjstls2rBhg3799VdFRERkeYw9e/Zo79696t27t33dtm3b5O/vr9q1a9vX1a1bV/7+/tq6desdupr7C3dWoQULFqh3797asWOHdu/ereeee04lSpRQnz59JEnTpk3ThAkTNHr0aH322Wfq37+/GjdurAoVKlz3mMnJyUpOTrYvJyQkSJKsLja5utqutxvuEVYXm8OfuPfRU+dCP50L/XQ+9PTOSUlJcVi22WwaOnSoGjRooPLly9u3T5s2Tf369VPx4sXl5uYmFxcXzZ49W3Xq1Ml0DEl6//33VaFCBdWqVcu+/fjx4ypUqJB9OePPQoUK6fjx41keB1dl97Wx2K69hYb7Tnh4uE6fPq2ff/5ZFsvVD6V+6aWX9OWXX2r//v0KCwtTo0aNtGjRIklX/4MPDg7W+PHj1a9fv+seNyoqSuPHj8+0fvHixfLy8rozFwMAAABcI2Nq7+TJk1WwYEH7+hUrVmjt2rXq0aOHgoKC9PPPP2vRokUaNWqUHnjgAYdjJCcnq2fPnurUqZPatWtnX//pp59qw4YNmjlzpsP4/v37q1mzZurYseMdvbZ7WVJSkrp06aL4+Hj5+flddxx3VqG6devag6ok1atXT9OmTVNaWpokqVq1avZtFotFwcHBOn369A2POWrUKA0bNsy+nJCQoJCQEL32g4tS3V1z+Qpwt1ldbJpQM11jd7soOd1y8x1gPHrqXOinc6Gfzoee3jn/jfq/abxDhw7Vvn37tHnzZpUsWdK+/vLly3riiSf06aefKjIy0r4+NTVVW7Zs0ahRoxyO+eGHHyolJUUTJ05UoUKF7OtPnz6tlStXqnnz5lq3bp2aN28ud3d3JSUlqXHjxg7HhqOMWZc3Q1jFTbm7uzssWywWpaen33Afq9Uqq9WaaX1yukWpaXxTdhbJ6RYl00+nQk+dC/10LvTT+dDT3Ofu7i6bzabBgwdrxYoVio2NVdmyZR3GXL58WSkpKcqXL5/Dz7kZ+/7zZ98FCxboscceU9GiRR3WN2zYUPHx8dq7d699/++//17x8fFq1KhRpuPg/2T3tSGsQtu3b8+0XLZsWbm6cgcUAAAA95aBAwdq8eLF+uKLL+Tr66tTp05Jkvz9/eXp6Sk/Pz81adJEw4cPl6enp0qUKKGNGzdq4cKFevPNNx2OdejQIX333XdatWpVpvNUrFhRLVu2VL9+/fT0008rMDBQAwYM0KOPPsqTgHMJTwOGjh07pmHDhungwYNasmSJ3n77bf3rX//K67IAAACAWzZr1izFx8crPDxcRYoUsX8tXbrUPubjjz9WrVq11LVrV1WqVElTpkzRxIkTMz2T5YMPPlCxYsXUokWLLM/10UcfqUqVKoqKilJkZKSqVatmf9YLbh93VqFnnnlGly9fVu3ateXq6qrBgwfrueeey+uyAAAAgFuWnefHBgcHa968eTcdN2nSJE2aNOm62wsUKKAFCxZo1apVioyMZOpvLiOsQu7u7poxY4ZmzZqVaVtcXFymdRnz8gEAAADgTmEaMAAAAADAOIRVAAAAAIBxmAZ8n4uNjc3rEgAAAAAgE8Iq7qodox5RYGBgXpeB25SSkqJVq1bpv1ERPEjASdBT50I/nQv9dD70FMgepgEDAAAAAIxDWAUAAAAAGIewCgAAAAAwDmEVAAAAAGAcwioAAAAAwDiEVQAAAACAcQirAAAAAADjEFYBAAAAAMYhrAIAAAAAjENYBQAAAAAYh7AKAAAAADAOYRUAAAAAYBzCKgAAAADAOIRVAAAAAIBxCKsAAAAAAOMQVgEAAAAAxiGsAgAAAACMQ1gFAAAAABiHsAoAAAAAMA5hFQAAAABgHMIqAAAAAMA4hFUAAAAAgHEIqwAAAAAA4xBWAQAAAADGIawCAAAAAIxDWAUAAAAAGIewCgAAAAAwDmEVAAAAAGAcwioAAAAAwDiEVQAAAACAcQirAAAAAADjEFYBAAAAAMYhrAIAAAAAjENYBQAAAAAYh7AKAAAAADAOYRUAAAAAYBzCKgAAAADAOIRVAAAAAIBxCKsAAAAAAOMQVgEAAAAAxiGsAgAAAACMQ1gFAAAAABiHsAoAAAAAMA5hFQAAAABgHMIqAAAAAMA4hFUAAAAAgHEIqwAAAAAA4xBWAQAAAADGIawCAAAAAIxDWAUAAAAAGIewCgAAAAAwDmEVAAAAAGAcwioAAAAAwDiEVQAAAACAcQirAAAAAADj5FpYvXDhQm4dCgAAAABwn8tRWJ06daqWLl1qX+7UqZMCAwNVrFgx/fjjj7lWHAAAAADg/pSjsPruu+8qJCREkrRu3TqtW7dOq1evVqtWrTR8+PBcLRAAAAAAcP9xy8lOJ0+etIfVlStXqlOnTmrRooXCwsJUp06dXC0QAAAAAHD/ydGd1fz58+vYsWOSpJiYGDVr1kySZLPZlJaWlnvVAQAAAADuSzm6s9qhQwd16dJFZcuW1dmzZ9WqVStJ0t69e1WmTJlcLRAAAAAAcP/JUVidPn26wsLCdOzYMUVHR8vHx0fS1enBAwYMyNUCAQAAAAD3nxyFVXd3d7344ouZ1g8dOvR26wEAAAAAIOefs7po0SI1bNhQRYsW1e+//y5JmjFjhr744otcKw4AAAAAcH/KUVidNWuWhg0bplatWunChQv2hyoFBARoxowZuVkfAAAAAOA+lKOw+vbbb+v999/XmDFj5Orqal9fs2ZN7du3L9eKAwAAAADcn3IUVo8cOaIaNWpkWm+1WpWYmHjbRQEAAAAA7m85CqslS5bU3r17M61fvXq1KlWqdLs1AQAAAADuczl6GvDw4cM1cOBA/f3337LZbNq5c6eWLFmiyZMna86cObldIwAAAADgPpOjsNqzZ0+lpqZqxIgRSkpKUpcuXVSsWDG99dZbevLJJ3O7RgAAAADAfeaWw2pqaqo++ugjtWnTRn369NGZM2eUnp6uoKCgO1EfAAAAAOA+dMvvWXVzc1P//v2VnJwsSSpYsCBBFQAAAACQq3I0DbhOnTr64YcfVKJEidyuB06uzuRvlermnddl4DZZXW2Kri1ViVqj5DRLXpeDXEBPnQv9dC700/mY2tO4Ka3zugTAQY7C6oABA/TCCy/ojz/+0EMPPSRvb8fwUa1atVwpDgAAAABwf8pRWO3cubMkaciQIfZ1FotFNptNFotFaWlpuVMdAAAAAOC+lKOweuTIkdyuAwAAAAAAu1t+wJIklShR4oZfAAAAAO49kydPVq1ateTr66ugoCC1a9dOBw8ezDTuwIEDeuyxx+Tv7y9fX1/VrVtXR48etW8PDw+XxWJx+PrnR1z++uuvatu2rQoWLCg/Pz81aNBAGzZsuOPXiHtHju6sLly48Ibbn3nmmRwVcy+Ji4tTyZIl9cMPP6h69ep5XU6WevTooQsXLmjFihV5XQoAAADuARs3btTAgQNVq1YtpaamasyYMWrRooX2799vf07N4cOH1bBhQ/Xu3Vvjx4+Xv7+/Dhw4IA8PD4dj9enTR6+++qp92dPT02F769atVa5cOa1fv16enp6aMWOGHn30UR0+fFjBwcF3/mJhvByF1X/9618OyykpKUpKSlK+fPnk5eWVK2H12LFjioqK0urVq3XmzBkVKVJE7dq107hx4xQYGHjbx79dISEhOnnypAoWLJjXpQAAAAC5IiYmxmF53rx5CgoK0p49e9S4cWNJ0pgxYxQZGano6Gj7uFKlSmU6lpeX13VD55kzZ3To0CF98MEH9oezTpkyRTNnztTPP/9MWIWkHE4DPn/+vMPXpUuXdPDgQTVs2FBLliy57aJ+++031axZU7/++quWLFmiQ4cOafbs2fr2229Vr149nTt3Lsv9rly5ctvnzi5XV1cFBwfLzS1Hef+OSktLU3p6el6XAQAAgHtcfHy8JKlAgQKSpPT0dH399dcqV66cIiIiFBQUpDp16mQ5k++jjz5SwYIFVblyZb344ou6ePGifVtgYKAqVqyohQsXKjExUampqXr33XdVuHBhPfTQQ3fl2mC+HIXVrJQtW1ZTpkzJdNc1JwYOHKh8+fJp7dq1atKkiUJDQ9WqVSt98803On78uMaMGSNJCgsL02uvvaYePXrI399fffr0kSS9//77CgkJkZeXl9q3b68333xTAQEB9uMfPnxYbdu2VeHCheXj46NatWrpm2++caghLCxMkyZNUq9eveTr66vQ0FC999579u1xcXGyWCzau3evfd3PP/+s1q1by8/PT76+vmrUqJEOHz6crWv+4IMPVLlyZVmtVhUpUkSDBg2yb3vzzTdVtWpVeXt7KyQkRAMGDNClS5fs2+fPn6+AgACtXLlSlSpVktVq1e+//27fPn78eAUFBcnPz099+/Z1CPXJyckaMmSIgoKC5OHhoYYNG2rXrl327bGxsbJYLPr2229Vs2ZNeXl5qX79+lm+dwEAAADOw2azadiwYWrYsKGqVKkiSTp9+rQuXbqkKVOmqGXLllq7dq3at2+vDh06aOPGjfZ9u3btqiVLlig2NlZjx47VsmXL1KFDB/t2i8WidevW6YcffpCvr688PDw0ffp0xcTEOPzcjvtbrt4WdHV11YkTJ27rGOfOndOaNWs0ceLETPPag4OD1bVrVy1dulQzZ86UJL3++usaO3asXn75ZUnSli1b1K9fP02dOlWPPfaYvvnmG40dO9bhOJcuXVJkZKRee+01eXh4aMGCBWrTpo0OHjyo0NBQ+7hp06ZpwoQJGj16tD777DP1799fjRs3VoUKFTLVffz4cTVu3Fjh4eFav369/Pz8tGXLFqWmpt70mmfNmqVhw4ZpypQpatWqleLj47Vlyxb7dhcXF/373/9WWFiYjhw5ogEDBmjEiBH210CSkpKSNHnyZM2ZM0eBgYEKCgqSJH377bfy8PDQhg0bFBcXp549e6pgwYKaOHGiJGnEiBFatmyZFixYoBIlSig6OloRERE6dOiQ/Tdo0tXpHtOmTVOhQoXUr18/9erVy6HGf0pOTlZycrJ9OSEhQZJkdbHJ1dV209cEZrO62Bz+xL2PnjoX+ulc6KfzMbWnKSkpDstDhgzRTz/9pA0bNti3Zfx816ZNG/vNlcqVK2vz5s2aOXOm6tevL+nqs1MylC9fXiVLllTdunW1c+dO1ahRQzabTf369VOhQoW0YcMGeXp66oMPPtCjjz6qrVu3qkiRInfhinNHxmvzz9cP15fd18pis9lu+b+SL7/80mHZZrPp5MmTeueddxQSEqLVq1ff6iHtduzYobp16+rzzz9Xu3btMm2fPn26hg0bpj///FO1a9dWjRo19Pnnn9u3P/nkk7p06ZJWrlxpX/f0009r5cqVunDhwnXPW7lyZfXv39/+H11YWJgaNWqkRYsW2a8xODhY48ePV79+/TI9YGn06NH6+OOPdfDgQbm7u9/SNRcrVkw9e/bUa6+9lq3xn376qfr3768zZ85IunpntWfPntq7d68eeOAB+7gePXroq6++0rFjx+Tl5SVJmj17toYPH674+HhdvnxZ+fPn1/z589WlSxdJV//hhIWFaejQoRo+fLhiY2PVtGlTffPNN3rkkUckSatWrVLr1q11+fLlTG+kzxAVFaXx48dnWr948WJ7LQAAADDTe++9px07dmjSpEkqXLiwfX1KSoqefPJJde7cWZ06dbKvX7BggQ4cOKApU6ZkeTybzaYnnnhCQ4cOVcOGDfXjjz9q/Pjx+vDDDx1+Nuzfv7+aNWumjh073rmLQ55LSkpSly5dFB8fLz8/v+uOy9Gd1X+GSIvFokKFCunhhx/WtGnTcnLIbMvI1haLRZJUs2ZNh+0HDx5U+/btHdbVrl3bIbwmJiZq/PjxWrlypU6cOKHU1FRdvnzZ4XHbkuxv9s44X3BwsE6fPp1lXXv37lWjRo1uOaiePn1aJ06csAfBrGzYsEGTJk3S/v37lZCQoNTUVP39999KTEy0P5UtX758DvVmeOCBBxy+AdSrV0+XLl3SsWPHFB8fr5SUFDVo0MC+3d3dXbVr19aBAwccjnPtsTN+03X69GmHO9HXGjVqlIYNG2ZfTkhIUEhIiF77wUWp7q43eklwD7C62DShZrrG7nZRcrolr8tBLqCnzoV+Ohf66XxM7el/oyJks9k0dOhQ7d27V999953Kli2baVytWrUkSZGRkfZ1H3zwgR544AGHdQ7H/u9/lZqaqlatWqlRo0b256u0bNlSPj4+9nE+Pj4qW7bsdY9jopSUFK1bt07Nmze/5Sxwv8qYdXkzOQqrd/LhPWXKlJHFYtH+/fuzvLP6yy+/KH/+/Pan8GaEtQw2m80eZK9dd63hw4drzZo1euONN1SmTBl5enrq8ccfz/SApn/+Y7NYLNe99n9OWc6um+33+++/KzIyUv369dOECRNUoEABbd68Wb1793a4fe7p6Znpum/EYrFkCv4ZsnoNr30tMrbd6N+B1WqV1WrNtD453aLUNHO+KeP2JKdblEw/nQo9dS7007nQT+djWk/d3d01YMAALV68WF988YUKFCigs2fPSpL8/f3tP7eOGDFCnTt3Vnh4uJo2baqYmBh9/fXXio2Nlbu7uw4fPqyPPvpIkZGRKliwoPbv368XXnhBNWrUUJMmTeTq6qpGjRopf/78evbZZzVu3Dh5enrq/fffV1xcnB577LF7MvS5u7vfk3Xnhey+Tjl6wNKrr76qpKSkTOsvX77s8FlKOREYGKjmzZtr5syZunz5ssO2U6dO6aOPPlLnzp2vG8wqVKignTt3OqzbvXu3w/KmTZvUo0cPtW/fXlWrVlVwcLDi4uJuq+5q1app06ZNtzxX3dfXV2FhYfr222+z3L57926lpqZq2rRpqlu3rsqVK3dL7wv+8ccfHV7H7du3y8fHR8WLF1eZMmWUL18+bd682b49JSVFu3fvVsWKFW/pOgAAAHDvmzVrluLj4xUeHq4iRYrYv5YuXWof0759e82ePVvR0dGqWrWq5syZo2XLlqlhw4aSrs74+/bbbxUREaHy5ctryJAhatGihb755hu5ul6dYVewYEHFxMTo0qVLevjhh1WzZk1t3rxZX3zxhcPb2nB/y9Gd1Yz3bf7zvYdJSUkaP368xo0bd1tFvfPOO6pfv74iIiL02muvqWTJkvr55581fPhwFStWzP5woKwMHjxYjRs31ptvvqk2bdpo/fr1Wr16tUO4LVOmjJYvX642bdrIYrFo7Nixt323eNCgQXr77bf15JNPatSoUfL399f27dtVu3ZtlS9f/ob7RkVFqV+/fgoKClKrVq108eJFbdmyRYMHD1bp0qWVmpqqt99+W23atNGWLVs0e/bsbNd15coV9e7dWy+//LJ+//13vfLKKxo0aJBcXFzk7e2t/v37a/jw4SpQoIBCQ0MVHR2tpKQk9e7d+7ZeDwAAANx7svs4m169eqlXr15ZbgsJCXF4MvD11KxZU2vWrLml+nB/ydGd1aymiUpX7+Jd+wTZnCpbtqx2796t0qVLq3PnzipdurSee+45NW3aVNu2bbvhORo0aKDZs2frzTff1AMPPKCYmBg9//zzDg8Cmj59uvLnz6/69eurTZs2ioiI0IMPPnhbNQcGBmr9+vW6dOmSmjRpooceekjvv/9+tm5xd+/eXTNmzNDMmTNVuXJlPfroo/rf//4nSapevbrefPNNTZ06VVWqVNFHH32kyZMnZ7uuRx55RGXLllXjxo3VqVMntWnTRlFRUfbtU6ZMUceOHdWtWzc9+OCDOnTokNasWaP8+fPf8msAAAAAALnllp4GnD9/flksFvtTm64NrGlpabp06ZL69eun//znP3ek2Jzq06ePfvnlF23atCmvS7lvJSQkyN/fX6VfWKpUN++b7wCjWV1tiq6dphE7XY16rw1yjp46F/rpXOin8zG1p3FTWud1CfeklJQUrVq1SpGRkbxnNZsyskGuPg14xowZstls6tWrl8aPHy9/f3/7tnz58iksLEz16tXLedW55I033lDz5s3l7e2t1atXa8GCBQ6fSQoAAAAAMNsthdXu3btLkkqWLKn69esb+5uDnTt3Kjo6WhcvXlSpUqX073//W88++2ye1XPt47j/afXq1WrUqNFdrAYAAAAAzHdL04Czcvny5UxPwL3Rrdz70aFDh667rVixYjn+2Jt7Scat/jNnzigwMDCvy8FtYrqL86GnzoV+Ohf66XzoqXOhn7fujkwDzpCUlKQRI0bok08+sX/20rXS0tJyclinVaZMmbwuAQAAAADuKTl6GvDw4cO1fv16zZw5U1arVXPmzNH48eNVtGhRLVy4MLdrBAAAAADcZ3J0Z/Wrr77SwoULFR4erl69eqlRo0YqU6aMSpQooY8++khdu3bN7ToBAAAAAPeRHN1ZPXfunEqWLCnp6vtTz507J0lq2LChvvvuu9yrDgAAAABwX8pRWC1VqpTi4uIkSZUqVdInn3wi6eod14CAgNyqDQAAAABwn8pRWO3Zs6d+/PFHSdKoUaPs7119/vnnNXz48FwtEAAAAABw/8nRe1aff/55+9+bNm2qX375Rbt371bp0qX1wAMP5FpxAAAAAID7U47C6rX+/vtvhYaGKjQ0NDfqAQAAAAAgZ9OA09LSNGHCBBUrVkw+Pj767bffJEljx47V3Llzc7VAAAAAAMD9J0dhdeLEiZo/f76io6OVL18++/qqVatqzpw5uVYcAAAAAOD+lKOwunDhQr333nvq2rWrXF1d7eurVaumX375JdeKAwAAAADcn3IUVo8fP64yZcpkWp+enq6UlJTbLgoAAAAAcH/LUVitXLmyNm3alGn9p59+qho1atx2UQAAAACA+1uOngb8yiuvqFu3bjp+/LjS09O1fPlyHTx4UAsXLtTKlStzu0YAAAAAwH3mlu6s/vbbb7LZbGrTpo2WLl2qVatWyWKxaNy4cTpw4IC++uorNW/e/E7VCgAAAAC4T9zSndWyZcvq5MmTCgoKUkREhD744AMdOnRIwcHBd6o+AAAAAMB96JburNpsNofl1atXKykpKVcLAgAAAAAgRw9YyvDP8AoAAAAAQG64pbBqsVhksVgyrQMAAAAAIDfd0ntWbTabevToIavVKkn6+++/1a9fP3l7ezuMW758ee5VCAAAAAC479xSWO3evbvD8tNPP52rxQAAAAAAIN1iWJ03b96dqgMAAAAAALvbesASAAAAAAB3AmEVAAAAAGAcwioAAAAAwDiEVQAAAACAcQirAAAAAADjEFYBAAAAAMYhrAIAAAAAjENYBQAAAAAYh7AKAAAAADAOYRUAAAAAYBzCKgAAAADAOIRVAAAAAIBxCKsAAAAAAOMQVgEAAAAAxiGsAgAAAACMQ1gFAAAAABiHsAoAAAAAMA5hFQAAAABgHMIqAAAAAMA4hFUAAAAAgHEIqwAAAAAA4xBWAQAAAADGIawCAAAAAIxDWAUAAAAAGIewCgAAAAAwDmEVAAAAAGAcwioAAAAAwDiEVQAAAACAcQirAAAAAADjEFYBAAAAAMYhrAIAAAAAjENYBQAAAAAYh7AKAAAAADAOYRUAAAAAYBzCKgAAAADAOIRVAAAAAIBxCKsAAAAAAOMQVgEAAAAAxiGsAgAAAACMQ1gFAAAAABiHsAoAAAAAMA5hFQAAAABgHMIqAAAAAMA4hFUAAAAAgHEIqwAAAAAA4xBWAQAAAADGIawCAAAAAIxDWAUAAAAAGIewCgAAAAAwDmEVAAAAAGAcwioAAAAAwDhueV0A7i91Jn+rVDfvvC4Dt8nqalN0balK1Bolp1nyuhzkAnrqXOinc6GfzudGPY2b0jqPqgLMw51VAAAAAIBxCKsAAAAAAOMQVgEAAAAAxiGsOonY2FhZLBZduHDBvm7FihUqU6aMXF1dNXTo0DyrDQAAALdm8uTJqlWrlnx9fRUUFKR27drp4MGDDmN69Oghi8Xi8FW3bl379nPnzmnw4MEqX768vLy8FBoaqiFDhig+Pt4+JuNnyKy+du3addeuF8gKYdUQp0+fVt++fRUaGiqr1arg4GBFRERo27ZtOT5m37599fjjj+vYsWOaMGFCtvYJDw8n2AIAAOSxjRs3auDAgdq+fbvWrVun1NRUtWjRQomJiQ7jWrZsqZMnT9q/Vq1aZd924sQJnThxQm+88Yb27dun+fPnKyYmRr1797aPqV+/vsP+J0+e1LPPPquwsDDVrFnzrl0vkBWeBmyIjh07KiUlRQsWLFCpUqX0559/6ttvv9W5c+dydLxLly7p9OnTioiIUNGiRXO5WgAAANxJMTExDsvz5s1TUFCQ9uzZo8aNG9vXZ9zkyEqVKlW0bNky+3Lp0qU1ceJEPf3000pNTZWbm5vy5cvnsH9KSoq+/PJLDRo0SBYLT59G3uLOqgEuXLigzZs3a+rUqWratKlKlCih2rVra9SoUWrdurXi4uJksVi0d+9eh30sFotiY2MzHS82Nla+vr6SpIcfftg+7uzZs3rqqadUvHhxeXl5qWrVqlqyZIl9vx49emjjxo1666237NM/4uLiJEn79+9XZGSkfHx8VLhwYXXr1k1nzpy5ky8LAAAA/r+MqbsFChRwWB8bG6ugoCCVK1dOffr00enTp296HD8/P7m5ZX3P6ssvv9SZM2fUo0ePXKkbuB3cWTWAj4+PfHx8tGLFCtWtW1dWq/W2jle/fn0dPHhQ5cuX17Jly1S/fn0VKFBAf/31lx566CGNHDlSfn5++vrrr9WtWzeVKlVKderU0VtvvaVff/1VVapU0auvvipJKlSokE6ePKkmTZqoT58+evPNN3X58mWNHDlSnTp10vr167OsITk5WcnJyfblhIQESZLVxSZXV9ttXR/yntXF5vAn7n301LnQT+dCP53PjXqakpKSaZ3NZtPQoUPVoEEDlS9f3j6mefPmat++vUJDQxUXF6eoqCg1bdpUO3bsyPLnybNnz2rChAl69tlnszyPJM2ZM0ctWrRQcHDwdcfAUcbrxOuVfdl9rSw2m43vfAZYtmyZ+vTpo8uXL+vBBx9UkyZN9OSTT6patWqKi4tTyZIl9cMPP6h69eqSrt5ZzZ8/vzZs2KDw8HDFxsaqadOmOn/+vAICAjJtv57WrVurYsWKeuONNyRdfc9q9erVNWPGDPuYcePGaceOHVqzZo193R9//KGQkBAdPHhQ5cqVy3TcqKgojR8/PtP6xYsXy8vLK2cvEgAAwH3o3Xff1e7duzV58mQVLFjwuuPOnTun5557Ti+88ILq1avnsC0pKUlRUVHy8fHR6NGjs7yzeubMGT333HN68cUXVb9+/Vy/DiBDUlKSunTpYr/Tfz3cWTVEx44d1bp1a23atEnbtm1TTEyMoqOjNWfOnBuGzVuRlpamKVOmaOnSpTp+/Lj97qe3t/cN99uzZ482bNggHx+fTNsOHz6cZVgdNWqUhg0bZl9OSEhQSEiIXvvBRanurrd/MchTVhebJtRM19jdLkpO5/0szoCeOhf66Vzop/O5UU//GxXhsDx06FDt27dPmzdvVsmSJW967EmTJsnPz0+RkZH2dRcvXlTr1q1VvHhxrVixQh4eHlnuO3HiRAUGBuqVV16Ru7t7Dq7s/pSSkqJ169apefPmvG7ZlDHr8mYIqwbx8PBQ8+bN1bx5c40bN07PPvusXnnlFW3atEnS1SkgGXIyzWDatGmaPn26ZsyYoapVq8rb21tDhw7VlStXbrhfenq62rRpo6lTp2baVqRIkSz3sVqtWU4/SU63KDWN/9E6i+R0i5Lpp1Ohp86FfjoX+ul8suppRtix2WwaPHiwVqxYodjYWJUtW/amxzt79qyOHTum4sWL24+TkJCg1q1by2q16quvvrruDDebzaaFCxfqmWeeYRZcDrm7uxNWsym7rxNh1WCVKlXSihUrVKhQIUnSyZMnVaNGDUlyeNhSdm3atElt27bV008/LelqCP3f//6nihUr2sfky5dPaWlpDvs9+OCDWrZsmcLCwq77ZnwAAADknoEDB2rx4sX64osv5Ovrq1OnTkmS/P395enpqUuXLikqKkodO3ZUkSJFFBcXp9GjR6tgwYJq3769pKt3VFu0aKGkpCR9+OGHSkhIsN/RKlSokFxd/2+22/r163XkyBGHj7UB8hpPAzbA2bNn9fDDD+vDDz/UTz/9pCNHjujTTz9VdHS02rZtK09PT9WtW1dTpkzR/v379d133+nll1++5fOUKVNG69at09atW3XgwAH17dvX/o0vQ1hYmHbs2KG4uDidOXNG6enpGjhwoM6dO6ennnpKO3fu1G+//aa1a9eqV69emYItAAAAbt+sWbMUHx+v8PBwFSlSxP61dOlSSZKrq6v27duntm3bqly5curevbvKlSunbdu22T8VYs+ePdqxY4f27dunMmXKOBzn2LFjDuebO3eu6tev73ATA8hr3CYzgI+Pj+rUqaPp06fr8OHDSklJUUhIiPr06aPRo0dLkj744AP16tVLNWvWVPny5RUdHa0WLVrc0nnGjh2rI0eOKCIiQl5eXnruuefUrl07+6PQJenFF19U9+7dValSJV2+fFlHjhxRWFiYtmzZopEjRyoiIkLJyckqUaKEWrZsKRcXft8BAACQ2272DFRPT0+Hh19mJTw8/KbHybB48eJs1wbcLYRVA1itVk2ePFmTJ0++7piKFStq27ZtDuuu/ebzz29GAQEBmb45FShQQCtWrLhhLRm/kfunsmXLavny5TfcFwAAAAByC7fFAAAAAADGIawCAAAAAIzDNGDcVTtGPaLAwMC8LgO3KSUlRatWrdJ/oyJ4RLuToKfOhX46F/rpfOgpkD3cWQUAAAAAGIewCgAAAAAwDmEVAAAAAGAcwioAAAAAwDiEVQAAAACAcQirAAAAAADjEFYBAAAAAMYhrAIAAAAAjENYBQAAAAAYh7AKAAAAADAOYRUAAAAAYBzCKgAAAADAOIRVAAAAAIBxCKsAAAAAAOMQVgEAAAAAxiGsAgAAAACMQ1gFAAAAABiHsAoAAAAAMA5hFQAAAABgHMIqAAAAAMA4hFUAAAAAgHEIqwAAAAAA4xBWAQAAAADGIawCAAAAAIxDWAUAAAAAGIewCgAAAAAwDmEVAAAAAGAcwioAAAAAwDiEVQAAAACAcQirAAAAAADjEFYBAAAAAMYhrAIAAAAAjENYBQAAAAAYh7AKAAAAADAOYRUAAAAAYBzCKgAAAADAOIRVAAAAAIBxCKsAAAAAAOMQVgEAAAAAxiGsAgAAAACMQ1gFAAAAABiHsAoAAAAAMA5hFQAAAABgHMIqAAAAAMA4hFUAAAAAgHEIqwAAAAAA4xBWAQAAAADGIawCAAAAAIxDWAUAAAAAGIewCgAAAAAwDmEVAAAAAGAcwioAAAAAwDiEVQAAAACAcQirAAAAAADjEFYBAAAAAMYhrAIAAAAAjENYBQAAAAAYh7AKAAAAADAOYRUAAAAAYBzCKgAAAADAOIRVAAAAAIBxCKsAAAAAAOMQVgEAAAAAxiGsAgAAAACMQ1gFAAAAABiHsAoAAAAAMA5hFQAAAABgHMIqAAAAAMA4hFUAAAAAgHEIqwAAAAAA4xBWAQAAAADGIawCAAAAAIxDWAUAAAAAGMctrwvA/aXO5G+V6uad12XgNlldbYquLVWJWqPkNEtel4NcQE+dC/10LvQze+KmtM7rEgDkMu6sAgAAAACMQ1gFAAAAABiHsAoAAAAAMA5hFQAAAE5h8uTJqlWrlnx9fRUUFKR27drp4MGDDmOioqJUoUIFeXt7K3/+/GrWrJl27NjhMOa9995TeHi4/Pz8ZLFYdOHChUznmjhxourXry8vLy8FBATcwasC7l+E1XtIeHi4hg4desMxYWFhmjFjxg3HWCwWrVixQpIUFxcni8WivXv35kqNAAAAeWXjxo0aOHCgtm/frnXr1ik1NVUtWrRQYmKifUy5cuX0zjvvaN++fdq8ebPCwsLUokUL/fXXX/YxSUlJatmypUaPHn3dc125ckVPPPGE+vfvf0evCbif8TTgO8BiufGT+rp376758+ffkXPv2rVL3t7Zf9puSEiITp48qYIFC0qSYmNj1bRpU50/f57fEgIAgHtKTEyMw/K8efMUFBSkPXv2qHHjxpKkLl26OIx58803NXfuXP3000965JFHJMl+cyA2Nva65xo/frwk3bGf6QAQVu+IkydP2v++dOlSjRs3zmEKiqen5y0dLyUlRe7u7tkaW6hQoVs6tqurq4KDg29pHwAAgHtBfHy8JKlAgQJZbr9y5Yree+89+fv764EHHribpQHIBqYB3wHBwcH2L39/f1ksFvtyTEyMSpQo4TB+xYoVDndjo6KiVL16dX3wwQcqVaqUrFarbDabJCk1NVWDBg1SQECAAgMD9fLLL9u3SZmnAf/vf/9T48aN5eHhoUqVKmndunUO5752GnBcXJyaNm0qScqfP78sFot69OihhQsXKjAwUMnJyQ77duzYUc8880yuvGYAAAC5yWazadiwYWrYsKGqVKnisG3lypXy8fGRh4eHpk+frnXr1tlnmQEwB3dWDXXo0CF98sknWrZsmVxdXe3rFyxYoN69e2vHjh3avXu3nnvuOZUoUUJ9+vTJdIz09HR16NBBBQsW1Pbt25WQkHDD97yGhIRo2bJl6tixow4ePCg/Pz95enoqX758GjJkiL788ks98cQTkqQzZ85o5cqVmabbZEhOTnYItwkJCZIkq4tNrq62LPfBvcPqYnP4E/c+eupc6KdzoZ/Zk5KS4rA8ZMgQ/fTTT9qwYUOmbQ0bNtSuXbt09uxZzZ07V506ddLmzZsVFBTkMC41NdV+7H8eI0NaWlqW589OrbeyD8xFP29ddl8rwqqhrly5okWLFmWa1hsSEqLp06fLYrGofPny2rdvn6ZPn55lWP3mm2904MABxcXFqXjx4pKkSZMmqVWrVlme09XV1T5NJigoyOE9q126dNG8efPsYfWjjz5S8eLFFR4enuWxJk+ebH8vx7VerpEuL6+0m14/7g0TaqbndQnIZfTUudBP50I/b2zVqlX2v7/33nvasWOHJk2apJ9++kk//fTTdfdr166d1qxZo5deekmPP/64w7Z9+/ZJktauXSsfH58s9//xxx+VkpLicP7s+ueMN9zb6Gf2JSUlZWscYdVQJUqUyPL9p3Xr1nWYMlyvXj1NmzZNaWlpDndgJenAgQMKDQ21B9WM8TnRp08f1apVS8ePH1exYsU0b9489ejR47oPkxo1apSGDRtmX05ISFBISIhe+8FFqe6uWe6De4fVxaYJNdM1dreLktNv/EAx3BvoqXOhn86FfmbPf6MiZLPZNHToUO3du1ffffedypYtm619vby8FBYWpsjISIf1GQ+tbNGixXUfPHnmzBm5u7tn2vdGUlJStG7dOjVv3jzbzyWBuejnrcuYdXkzhNW7zMXFxeE9plLWt8Fv5Ym+1/PP80g3f1Lx9dSoUUMPPPCAFi5cqIiICO3bt09fffXVdcdbrVZZrdZM65PTLUpN43+0ziI53aJk+ulU6KlzoZ/OhX7emLu7uwYMGKDFixfriy++UIECBXT27FlJkr+/vzw9PZWYmKiJEyfqscceU5EiRXT27FnNnDlTf/zxh5588kl70Dh16pROnTqluLg4SdIvv/wiX19fhYaG2mehHT16VOfOndPx48eVlpamn3/+WZJUpkyZ696Fzapmwo3zoJ/Zl93XibB6lxUqVEgXL15UYmKiPZDeymecbt++PdNy2bJlM91VlaRKlSrp6NGjOnHihIoWLSpJ2rZt2w2Pny9fPkn/9/6Laz377LOaPn26jh8/rmbNmikkJCTbdQMAANxps2bNkqRMb1PKmBHm6uqqX375RQsWLNCZM2cUGBioWrVqadOmTapcubJ9/OzZsx3ezpTxsTcZx5GkcePGacGCBfYxNWrUkCRt2LDhum+TAnBrCKt3WZ06deTl5aXRo0dr8ODB2rlz5y19PtexY8c0bNgw9e3bV99//73efvttTZs2LcuxzZo1U/ny5fXMM89o2rRpSkhI0JgxY254/BIlSshisWjlypWKjIyUp6en/beDXbt21Ysvvqj3339fCxcuzHbNAAAAd0NWs8qu5eHhoeXLl9/0OFFRUYqKirrhmPnz5/MZq8AdxkfX3GUFChTQhx9+qFWrVqlq1apasmTJTb8ZXuuZZ57R5cuXVbt2bQ0cOFCDBw/Wc889l+VYFxcXff7550pOTlbt2rX17LPPauLEiTc8frFixTR+/Hi99NJLKly4sAYNGmTf5ufnp44dO8rHx0ft2rXLds0AAAAAcKsstpv9Cgq4RvPmzVWxYkX9+9//vqX9EhIS5O/vr9IvLFWq2+2/Hxd5y+pqU3TtNI3Y6cr7p5wEPXUu9NO50M/siZvSOq9LyLaMpwdHRkbyHkcnQD9vXUY2iI+Pl5+f33XHMQ0Y2XLu3DmtXbtW69ev1zvvvJPX5QAAAABwcoRVZMuDDz6o8+fPa+rUqSpfvnxelwMAAADAyRFWkS0Zj26/XTtGPaLAwMBcORbyTsZ0l/9GRTDdxUnQU+dCP50L/QRwv+IBSwAAAAAA4xBWAQAAAADGIawCAAAAAIxDWAUAAAAAGIewCgAAAAAwDmEVAAAAAGAcwioAAAAAwDiEVQAAAACAcQirAAAAAADjEFYBAAAAAMYhrAIAAAAAjENYBQAAAAAYh7AKAAAAADAOYRUAAAAAYBzCKgAAAADAOIRVAAAAAIBxCKsAAAAAAOMQVgEAAAAAxiGsAgAAAACMQ1gFAAAAABiHsAoAAAAAMA5hFQAAAABgHMIqAAAAAMA4hFUAAAAAgHEIqwAAAAAA4xBWAQAAAADGIawCAAAAAIxDWAUAAAAAGIewCgAAAAAwDmEVAAAAAGAcwioAAAAAwDiEVQAAAACAcQirAAAAAADjEFYBAAAAAMYhrAIAAAAAjENYBQAAAAAYh7AKAAAAADAOYRUAAAAAYBzCKgAAAADAOIRVAAAAAIBxCKsAAAAAAOMQVgEAAAAAxiGsAgAAAACMQ1gFAAAAABiHsAoAAAAAMA5hFQAAAABgHMIqAAAAAMA4hFUAAAAAgHEIqwAAAAAA4xBWAQAAAADGIawCAAAAAIxDWAUAAAAAGIewCgAAAAAwDmEVAAAAAGAcwioAAAAAwDiEVQAAAACAcQirAAAAAADjEFYBAAAAAMYhrAIAAAAAjENYBQAAAAAYh7AKAAAAADAOYRUAAAAAYBzCKgAAAADAOIRVAAAAAIBxCKsAAAAAAOMQVgEAAAAAxiGsAgAAAACMQ1gFAAAAABiHsAoAAAAAMA5hFQAAAABgHMIqAAAAAMA4hFUAAAAAgHEIqwAAAAAA47jldQG4v9SZ/K1S3bzzugzcJqurTdG1pSpRa5ScZsnrcpAL6KlzoZ/OhX5mLW5K67wuAcAdxp1VAAAAAIBxCKsAAAAAAOMQVgEAAAAAxrmnwur8+fMVEBBgX46KilL16tVv65hxcXGyWCzau3fvbR3nTomNjZXFYtGFCxfyuhQAAADjTJ48WbVq1ZKvr6+CgoLUrl07HTx40L49JSVFI0eOVNWqVeXt7a2iRYvqmWee0YkTJxyOc/jwYbVv316FChWSn5+fOnXqpD///DPT+b7++mvVqVNHnp6eKliwoDp06HDHrxG4X+VZWLVYLDf86tGjR6Z9OnfurF9//fXuF3uXhIeHa+jQoXldBgAAwD1j48aNGjhwoLZv365169YpNTVVLVq0UGJioiQpKSlJ33//vcaOHavvv/9ey5cv16+//qrHHnvMfozExES1aNFCFotF69ev15YtW3TlyhW1adNG6enp9nHLli1Tt27d1LNnT/3444/asmWLunTpctevGbhf5NnTgE+ePGn/+9KlSzVu3DiH34J5eno6jE9JSZGnp2em9QAAALh/xcTEOCzPmzdPQUFB2rNnjxo3bix/f3+tW7fOYczbb7+t2rVr6+jRowoNDdWWLVsUFxenH374QX5+fvbjFChQQOvXr1ezZs2Umpqqf/3rX3r99dfVu3dv+7HKly9/5y8SuE/l2Z3V4OBg+5e/v78sFot9+e+//1ZAQIA++eQThYeHy8PDQx9++GGmacAZFi1apLCwMPn7++vJJ5/UxYsX7dtiYmLUsGFDBQQEKDAwUI8++qgOHz58w9o2btyo2rVry2q1qkiRInrppZeUmppq3x4eHq7Bgwdr6NChyp8/vwoXLqz33ntPiYmJ6tmzp3x9fVW6dGmtXr3a4bj79+9XZGSkfHx8VLhwYXXr1k1nzpyRJPXo0UMbN27UW2+9Zb+7HBcXZ993z549qlmzpry8vFS/fn2HYH/48GG1bdtWhQsXlo+Pj2rVqqVvvvnG4dxhYWGaNGmSevXqJV9fX4WGhuq9995zGHP8+HF17txZ+fPnV2BgoNq2betQQ2xsrGrXri1vb28FBASoQYMG+v3332/4WgIAANxN8fHxkqQCBQrccIzFYrH/XJmcnCyLxSKr1Wof4+HhIRcXF23evFmS9P333+v48eNycXFRjRo1VKRIEbVq1Uo///zznbsY4D5n9Oesjhw5UtOmTdO8efNktVq1du3aTGMOHz6sFStWaOXKlTp//rw6deqkKVOmaOLEiZKuTusYNmyYqlatqsTERI0bN07t27fX3r175eKSOasfP35ckZGR6tGjhxYuXKhffvlFffr0kYeHh6KiouzjFixYoBEjRmjnzp1aunSp+vfvrxUrVqh9+/YaPXq0pk+frm7duuno0aPy8vLSyZMn1aRJE/Xp00dvvvmmLl++rJEjR6pTp05av3693nrrLf3666+qUqWKXn31VUlSoUKF7GFxzJgxmjZtmgoVKqR+/fqpV69e2rJliyTp0qVLioyM1GuvvSYPDw8tWLBAbdq00cGDBxUaGmqvedq0aZowYYJGjx6tzz77TP3791fjxo1VoUIFJSUlqWnTpmrUqJG+++47ubm56bXXXlPLli31008/ycXFRe3atVOfPn20ZMkSXblyRTt37pTFkvXnvSUnJys5Odm+nJCQIEmyutjk6mq7hX8FMJHVxebwJ+599NS50E/nQj+zlpKSkmmdzWbT0KFD1aBBA5UvXz7LMX///bdGjhypJ598Up6enkpJSdFDDz0kb29vDR8+XBMmTJDNZtPo0aOVnp6u48ePKyUlxf5WtKioKEVHRyssLEzTp09XkyZN9PPPP98wHF+v9qzqw72Hft667L5WFpvNluff+ebPn6+hQ4faHyIUFxenkiVLasaMGfrXv/513XFRUVF6/fXXderUKfn6+kqSRowYoe+++07bt2/P8lx//fWXgoKCtG/fPlWpUsV+rh9++EHVq1fXmDFjtGzZMh04cMAexGbOnKmRI0cqPj5eLi4uCg8PV1pamjZt2iRJSktLk7+/vzp06KCFCxdKkk6dOqUiRYpo27Ztqlu3rsaNG6cdO3ZozZo19lr++OMPhYSE6ODBgypXrpzCw8NVvXp1zZgxwz4mNjZWTZs21TfffKNHHnlEkrRq1Sq1bt1aly9floeHR5bXWblyZfXv31+DBg2SdPXOaqNGjbRo0SJJV7+ZBwcHa/z48erXr58++OADRUdHO1z3lStXFBAQoBUrVqhmzZoKDAxUbGysmjRpctOeRkVFafz48ZnWL168WF5eXjfdHwAA4Fa9++672r17tyZPnqyCBQtm2p6amqro6GidOXNGr732msPPJD/88INmz56t06dPy2KxqFGjRjp27JjKlSunfv36aePGjZo+fbr69++viIgISVd/4O7du7e6du1qXwfg5pKSktSlSxfFx8fbp95nxeg7qzVr1rzpmLCwMHtQlaQiRYro9OnT9uXDhw9r7Nix2r59u86cOWN/k/zRo0dVpUqVTMc7cOCA6tWr53DHsEGDBrp06ZL++OMP+53KatWq2be7uroqMDBQVatWta8rXLiwJNlr2bNnjzZs2CAfH59M5zx8+LDKlSt3w+u89nxFihSxHzs0NFSJiYkaP368Vq5cqRMnTig1NVWXL1/W0aNHr3uMjGnX19Z36NAhh9dSuvrbx8OHD6tFixbq0aOHIiIi1Lx5czVr1kydOnWy1/JPo0aN0rBhw+zLCQkJCgkJ0Ws/uCjV3fWG1wrzWV1smlAzXWN3uyg5Peu767i30FPnQj+dC/3M2n+jHMPh0KFDtW/fPm3evFklS5bMND4lJUVPPfWULl++rC1btigwMNBhe2RkpMaMGaMzZ87Izc1NAQEBCgkJUZMmTRQZGSkvLy9Nnz5dnTp1UoMGDez7RUdHy8/PT5GRkdmuPSUlRevWrVPz5s3l7u5+i1cO09DPW5cx6/JmjA6r3t7eNx3zz38QFovF4altbdq0UUhIiN5//30VLVpU6enpqlKliq5cuZLl8Ww2W6aprRk3n69dn9V5r12XMTajlvT0dLVp00ZTp07NdM7rBb7rXec/jz18+HCtWbNGb7zxhsqUKSNPT089/vjjma7xRq9Venq6HnroIX300UeZzl2oUCFJVx80MGTIEMXExGjp0qV6+eWXtW7dOtWtWzfTPlar1eF9HxmS0y1KTeN/tM4iOd2iZPrpVOipc6GfzoV+Osr4ucZms2nw4MFasWKFYmNjVbZs2UxjU1JS1LVrVx0+fFgbNmyw/2yTlYyfy9avX6/Tp0+rffv2cnd3V506dWS1WnX48GGFh4fbj/v777+rVKlSOQop7u7uhBsnQj+zL7uvk9Fh9XadPXtWBw4c0LvvvqtGjRpJkv1N8tdTqVIlLVu2zCG0bt26Vb6+vipWrFiOa3nwwQe1bNkyhYWFyc0t65c9X758SktLu+Vjb9q0ST169FD79u0lXX0P67UPRspufUuXLlVQUNANb8XXqFFDNWrU0KhRo1SvXj0tXrw4y7AKAABwNwwcOFCLFy/WF198IV9fX506dUqS5O/v///au/f4ms58j+PfHZKQkB2pkNA0oQZBaOtScYv7bajUqboGUzXjuF9HW2NQVYYybZlqR+ckxuXQ1ynaGid1Cx0kCKJUihJFTwxVEoTI5Tl/eNnT3QRJK/ZK8nm/XvvV7LWe/exn7V+fmX73s9baKl++vLKzs/XCCy/o4MGD2rhxo3Jychxt/Pz85OHhIenOl/KhoaHy9/dXfHy8xo0bpwkTJjju9uvj46MRI0ZoxowZCgoKUnBwsBYsWCBJ6tOnjwuOHCj5XHY34Efh7l1t//rXv+qbb77R9u3bnU5Nzc/IkSN17tw5jRkzRl9//bU++eQTzZgxQxMnTsz3hkwFNWrUKP3www/q37+/9u3bp9OnT2vz5s166aWXHAE1JCREe/fu1ZkzZ5xOWX6QWrVqad26dUpKStLhw4c1YMCAAr/2roEDB6py5crq1auX/vnPfyolJUU7d+7UuHHjdP78eaWkpOjVV19VfHy8vv32W23evFknTpxQaGhooT8LAACAh2Xp0qVKS0tT27ZtFRgY6HisXbtW0p17hHz66ac6f/68nnrqKac2e/bscfRz/PhxRUZGKjQ0VK+//rqmTZumt956y+m9FixYoH79+ikqKkpNmzbVt99+q+3bt6tSpUqP9JiB0qJEr6y6ublpzZo1Gjt2rBo0aKA6dero3XffdZy6kZ/q1atr06ZNmjJliho1aiQ/Pz8NGzZMf/jDH37RWKpVq6bdu3dr6tSp6tKlizIzMxUcHKyuXbs6QvDkyZM1ZMgQ1atXTzdv3lRKSkqB+v7zn/+sl156SS1atFDlypU1derUAp8HfpeXl5e++OILTZ06Vb1799a1a9dUvXp1dejQQT4+Prp586a+/vprLV++XJcvX1ZgYKBGjx6t3/3ud4X+LAAAAB6WB90rNCQk5IFtJGnevHmaN2/efdu4u7vrrbfeyhNiARQNS9wNGCVfenq67Ha7npy0VtllH3wtMqzNs4zR/GY5+v2+Mlw/VUJQ05KFepYs1DN/Z+b92tVD+NmysrK0adMmde/enWscSwDqWXh3s8GD7gZcok8DBgAAAAAUT4RVAAAAAIDllOhrVmE9e1/tkOd3zVD83D3d5ejMLpzuUkJQ05KFepYs1BNAacXKKgAAAADAcgirAAAAAADLIawCAAAAACyHsAoAAAAAsBzCKgAAAADAcgirAAAAAADLIawCAAAAACyHsAoAAAAAsBzCKgAAAADAcgirAAAAAADLIawCAAAAACyHsAoAAAAAsBzCKgAAAADAcgirAAAAAADLIawCAAAAACyHsAoAAAAAsBzCKgAAAADAcgirAAAAAADLIawCAAAAACyHsAoAAAAAsBzCKgAAAADAcgirAAAAAADLIawCAAAAACyHsAoAAAAAsBzCKgAAAADAcgirAAAAAADLIawCAAAAACyHsAoAAAAAsBzCKgAAAADAcgirAAAAAADLIawCAAAAACyHsAoAAAAAsBzCKgAAAADAcgirAAAAAADLIawCAAAAACyHsAoAAAAAsBzCKgAAAADAcgirAAAAAADLIawCAAAAACyHsAoAAAAAsBzCKgAAAADAcgirAAAAAADLIawCAAAAACyHsAoAAAAAsBzCKgAAAADAcgirAAAAAADLIawCAAAAACyHsAoAAAAAsBzCKgAAAADAcgirAAAAAADLIawCAAAAACyHsAoAAAAAsBzCKgAAAADAcgirAAAAAADLIawCAAAAACyHsAoAAAAAsBzCKgAAAADAcgirAAAAAADLIawCAAAAACyHsAoAAAAAsBzCKgAAAADAcgirAAAAAADLIawCAAAAACyHsAoAAAAAsBzCKgAAAADAcgirAAAAAADLIawCAAAAACyHsAoAAAAAsBzCKgAAAADAcgirAAAAAADLIawCAAAAACyHsAoAAAAAsBzCKgAAAADAcsq6egAoXZ6du03ZZb1dPQz8Qp5ljOY3kxrM/FyZOTZXDwcPATUtWahnyUI98zoz79euHgKAR4CVVQAAAACA5RBWAQAAAACWQ1gFAAAAAFgOYfURadu2rcaPH1/k72Oz2bRhw4YCtw8JCdHbb79dZOMBAAAoCnPnzlXTpk1VsWJFValSRZGRkTp+/Lhjf1ZWlqZOnaqwsDB5e3urWrVqGjx4sP7v//7PqZ9Tp07p+eefl7+/v3x8fPTiiy/qX//6l1ObK1euKCoqSna7XXa7XVFRUbp69eqjOEygVCt1YfXChQsaM2aMatasKU9PTwUFBalnz57atm2bq4dWKDNnztRTTz2VZ3tqaqq6detW4H7279+v3/72t47nhQ27AAAArrBz506NGjVKCQkJ2rJli7Kzs9W5c2fduHFDkpSRkaGDBw9q+vTpOnjwoNatW6cTJ07oueeec/Rx48YNde7cWTabTdu3b9fu3bt1+/Zt9ezZU7m5uY52AwYMUFJSkmJjYxUbG6ukpCRFRUU98mMGSptSdTfgM2fOqGXLlvL19dX8+fPVsGFDZWVl6fPPP9eoUaP09ddfu3qIv1hAQECh2vv7+xfRSAAAAIpObGys0/Po6GhVqVJFBw4cUJs2bWS327VlyxanNosXL1azZs109uxZPfHEE9q9e7fOnDmjQ4cOycfHx9GPn5+ftm/fro4dOyo5OVmxsbFKSEjQs88+K0latmyZwsPDdfz4cdWpU+fRHDBQCpWqldWRI0fKZrNp3759euGFF1S7dm3Vr19fEydOVEJCgiTp7Nmz6tWrlypUqJDvqSB3VzRXrFihkJAQ2e129evXT9euXXO0uXHjhgYPHqwKFSooMDBQCxcuzDOW/FYwfX19FRMT43h+/vx59evXT35+fvL29laTJk20d+9excTEaNasWTp8+LBsNptsNpvjdT/uNzw8XK+88orTe1y6dEnu7u6Ki4uT5HwacEhIiCTp+eefl81mU0hIiM6cOSM3NzclJiY69bN48WIFBwfLGFOgzx4AAKAopaWlSZL8/Pzu28Zms8nX11eSlJmZKZvNJk9PT0ebcuXKyc3NTbt27ZIkxcfHy263O4KqJDVv3lx2u1179uwpgiMBcFepWVn94YcfFBsbqzlz5sjbO+/vfPr6+soYo8jISHl7e2vnzp3Kzs7WyJEj1bdvX+3YscPR9tSpU9qwYYM2btyoK1eu6MUXX9S8efM0Z84cSdKUKVMUFxen9evXKyAgQK+99poOHDiQ72m793L9+nVFRESoevXq+vTTTxUQEKCDBw8qNzdXffv21dGjRxUbG6utW7dKkux2e54+Bg4cqAULFmju3Lmy2e78LtvatWtVtWpVRURE5Gm/f/9+ValSRdHR0eratavKlCkjf39/dezYUdHR0WrSpImjbXR0tIYOHero96cyMzOVmZnpeJ6eni5J8nQzKlOGgFvceboZp3+i+KOmJQv1LFmoZ15ZWVlOz40xGj9+vFq2bKk6derk2S9Jt27d0tSpU9WvXz+VL19eWVlZaty4sby9vTVlyhTNnj1bxhi99tprys3N1XfffaesrCx999138vf3z9Onv7+/o83PHf/PeS2sh3oWXkE/q1ITVr/55hsZY1S3bt17ttm6dau+/PJLpaSkKCgoSJK0YsUK1a9fX/v371fTpk0lSbm5uYqJiVHFihUlSVFRUdq2bZvmzJmj69ev629/+5v+/ve/q1OnTpKk5cuX6/HHHy/UeFevXq1Lly5p//79jm8Ia9Wq5dhfoUIFlS1b9r6n/fbt21cTJkzQrl271Lp1a0e/AwYMkJtb3kX1u6cE+/r6OvX78ssva8SIEVq0aJE8PT11+PBhJSUlad26dfd877lz52rWrFl5tv/h6Vx5eeU84OhRXMxukvvgRihWqGnJQj1LFur5b5s2bXJ6/sEHHygxMVFz587Ns0+SsrOzNX/+fF29elU9e/Z0ajNhwgS9//77WrJkiWw2m1q3bq2aNWvq/Pnz2rRpk44fP66MjIw8/d64cUMnTpzI9/0K6qenKaN4o54Fl5GRUaB2pSas3j1d9V4rgZKUnJysoKAgR1CVpHr16snX11fJycmOsBoSEuIIqpIUGBioixcvSrqz6nr79m2Fh4c79vv5+RX6eoakpCQ9/fTT9z2V5UH8/f3VqVMnrVq1Sq1bt1ZKSori4+O1dOnSQvUTGRmp0aNHa/369erXr5/+67/+S+3atXOcNpyfV199VRMnTnQ8T09PV1BQkN445KZs9zI/95BgEZ5uRrOb5Gp6opsyc+89p1B8UNOShXqWLNQzr6Mzuzj+Hj9+vI4cOaJdu3apRo0aedpmZWWpf//+unnzpnbv3q3HHnvMaX/37t01bdo0ff/99ypbtqx8fX0VFBSkiIgIde/eXRcvXtTGjRvVvXt3p9dlZGSoTZs2ebYXRFZWlrZs2aJOnTrJ3d290K+HtVDPwrt71uWDlJqw+qtf/Uo2m03JycmKjIzMt40xJt8w+9PtP/2X0GazOe4YV9BrOG02W562P14OL1++fIH6eZCBAwdq3LhxWrx4sVavXq369eurUaNGherDw8NDUVFRio6OVu/evbV69eoH/tyNp6en0/Ufd2Xm2pSdw//RlhSZuTZlUs8ShZqWLNSzZKGe/+bu7i5jjMaMGaMNGzZox44d+tWvfpWnXVZWlgYOHKhTp04pLi7uvjeWDAwMlCRt375dFy9e1PPPPy93d3e1atVKaWlpOnTokJo1ayZJ2rt3r9LS0tS6detfFE7c3d0JNyUI9Sy4gn5OpeYGS35+furSpYv+8pe/OG5p/mNXr15VvXr1dPbsWZ07d86x/dixY0pLS1NoaGiB3qdWrVpyd3d33LBJuvPbXCdOnHBq5+/vr9TUVMfzkydPOi2HN2zYUElJSfrhhx/yfR8PDw/l5Dz4dNrIyEjdunVLsbGxWr16tQYNGnTf9u7u7vn2+/LLL2vr1q167733lJWVpd69ez/wvQEAAIrKqFGjtHLlSq1evVoVK1bUhQsXdOHCBd28eVPSnVN/X3jhBSUmJmrVqlXKyclxtLl9+7ajn+joaCUkJOjUqVNauXKl+vTpowkTJjjOigsNDVXXrl01fPhwJSQkKCEhQcOHD1ePHj24EzBQxEpNWJWk9957Tzk5OWrWrJk+/vhjnTx5UsnJyXr33XcVHh6ujh07qmHDhho4cKAOHjyoffv2afDgwYqIiHC6udD9VKhQQcOGDdOUKVO0bds2HT16VEOHDs1zjWj79u21ZMkSHTx4UImJiRoxYoTTNwz9+/dXQECAIiMjtXv3bp0+fVoff/yx4uPjJd05FTklJUVJSUn6/vvvnW5m9GPe3t7q1auXpk+fruTkZA0YMOC+4w8JCdG2bdt04cIFXblyxbE9NDRUzZs319SpU9W/f/+HtvILAADwcyxdulRpaWlq27atAgMDHY+1a9dKuvOrCp9++qnOnz+vp556yqnNj+/ie/z4cUVGRio0NFSvv/66pk2bprfeesvpvVatWqWwsDB17txZnTt3VsOGDbVixYpHerxAaVSqwmqNGjV08OBBtWvXTpMmTVKDBg3UqVMnbdu2TUuXLnX87EulSpXUpk0bdezYUTVr1nT8j15BLViwQG3atNFzzz2njh07qlWrVmrcuLFTm4ULFyooKEht2rTRgAEDNHnyZHl5eTn2e3h4aPPmzapSpYq6d++usLAwzZs3T2XK3Lne8z/+4z/UtWtXtWvXTv7+/vrv//7ve45n4MCBOnz4sFq3bq0nnnjivmNfuHChtmzZoqCgID399NNO+4YNG6bbt2/rpZdeKtTnAQAA8LAZY/J9DB06VNKdL+Dv1aZt27aOfubNm+dYbT1x4oQmTpyY57IwPz8/rVy5Uunp6UpPT9fKlSsdP38DoOjYDD+UiQKaM2eO1qxZoyNHjhT6tenp6bLb7Xpy0lpll83700EoXjzLGM1vlqPf7yvD9VMlBDUtWahnyUI98zoz79euHsIvkpWVpU2bNql79+5c41gCUM/Cu5sN0tLS5OPjc892pWplFT/P9evXtX//fi1evFhjx4519XAAAAAAlAKEVTzQ6NGj1apVK0VERHAKMAAAAIBHotT8dA1+vpiYGMXExLh6GAAAAABKEcIqHqm9r3bI82PcKH7uXptxdGYXrs0oIahpyUI9SxbqCaC04jRgAAAAAIDlEFYBAAAAAJZDWAUAAAAAWA5hFQAAAABgOYRVAAAAAIDlEFYBAAAAAJZDWAUAAAAAWA5hFQAAAABgOYRVAAAAAIDlEFYBAAAAAJZDWAUAAAAAWA5hFQAAAABgOYRVAAAAAIDlEFYBAAAAAJZDWAUAAAAAWA5hFQAAAABgOYRVAAAAAIDlEFYBAAAAAJZDWAUAAAAAWA5hFQAAAABgOYRVAAAAAIDlEFYBAAAAAJZDWAUAAAAAWA5hFQAAAABgOYRVAAAAAIDlEFYBAAAAAJZDWAUAAAAAWA5hFQAAAABgOYRVAAAAAIDlEFYBAAAAAJZDWAUAAAAAWA5hFQAAAABgOYRVAAAAAIDlEFYBAAAAAJZDWAUAAAAAWA5hFQAAAABgOYRVAAAAAIDlEFYBAAAAAJZDWAUAAAAAWA5hFQAAAABgOYRVAAAAAIDlEFYBAAAAAJZDWAUAAAAAWA5hFQAAAABgOYRVAAAAAIDlEFYBAAAAAJZDWAUAAAAAWA5hFQAAAABgOYRVAAAAAIDlEFYBAAAAAJZDWAUAAAAAWA5hFQAAAABgOYRVAAAAAIDlEFYBAAAAAJZDWAUAAAAAWA5hFQAAAABgOYRVAAAAAIDlEFYBAAAAAJZDWAUAAAAAWA5hFQAAAABgOYRVAAAAAIDlEFYBAAAAAJZDWAUAAAAAWA5hFQAAAABgOYRVAAAAAIDlEFYBAAAAAJZDWAUAAAAAWA5hFQAAAABgOYRVAAAAAIDlEFYBAAAAAJZDWAUAAAAAWA5hFQAAAABgOYRVAAAAAIDlEFYBAAAAAJZDWAUAAAAAWA5hFQAAAABgOYRVAAAAAIDlEFYBAAAAAJZDWAUAAAAAWA5hFQAAAABgOYRVAAAAAIDllHX1AFA6GGMkSdeuXZO7u7uLR4NfKisrSxkZGUpPT6eeJQQ1LVmoZ8lCPUsealqyUM/CS09Pl/TvjHAvhFU8EpcvX5Yk1ahRw8UjAQAAAGAF165dk91uv+d+wioeCT8/P0nS2bNn7/svJIqH9PR0BQUF6dy5c/Lx8XH1cPAQUNOShXqWLNSz5KGmJQv1LDxjjK5du6Zq1ardtx1hFY+Em9udy6PtdjuTuATx8fGhniUMNS1ZqGfJQj1LHmpaslDPwinIAhY3WAIAAAAAWA5hFQAAAABgOYRVPBKenp6aMWOGPD09XT0UPATUs+ShpiUL9SxZqGfJQ01LFupZdGzmQfcLBgAAAADgEWNlFQAAAABgOYRVAAAAAIDlEFYBAAAAAJZDWAUAAAAAWA5hFUXuvffeU40aNVSuXDk1btxY//znP109JORj5syZstlsTo+AgADHfmOMZs6cqWrVqql8+fJq27atvvrqK6c+MjMzNWbMGFWuXFne3t567rnndP78+Ud9KKXSF198oZ49e6patWqy2WzasGGD0/6HVb8rV64oKipKdrtddrtdUVFRunr1ahEfXen0oJoOHTo0z5xt3ry5Uxtqah1z585V06ZNVbFiRVWpUkWRkZE6fvy4UxvmafFRkHoyR4uXpUuXqmHDhvLx8ZGPj4/Cw8P1v//7v479zE/XIKyiSK1du1bjx4/XtGnTdOjQIbVu3VrdunXT2bNnXT005KN+/fpKTU11PI4cOeLYN3/+fC1atEhLlizR/v37FRAQoE6dOunatWuONuPHj9f69eu1Zs0a7dq1S9evX1ePHj2Uk5PjisMpVW7cuKFGjRppyZIl+e5/WPUbMGCAkpKSFBsbq9jYWCUlJSkqKqrIj680elBNJalr165Oc3bTpk1O+6mpdezcuVOjRo1SQkKCtmzZouzsbHXu3Fk3btxwtGGeFh8FqafEHC1OHn/8cc2bN0+JiYlKTExU+/bt1atXL0cgZX66iAGKULNmzcyIESOcttWtW9e88sorLhoR7mXGjBmmUaNG+e7Lzc01AQEBZt68eY5tt27dMna73bz//vvGGGOuXr1q3N3dzZo1axxtvvvuO+Pm5mZiY2OLdOxwJsmsX7/e8fxh1e/YsWNGkklISHC0iY+PN5LM119/XcRHVbr9tKbGGDNkyBDTq1eve76GmlrbxYsXjSSzc+dOYwzztLj7aT2NYY6WBJUqVTIffvgh89OFWFlFkbl9+7YOHDigzp07O23v3Lmz9uzZ46JR4X5OnjypatWqqUaNGurXr59Onz4tSUpJSdGFCxecaunp6amIiAhHLQ8cOKCsrCynNtWqVVODBg2ot4s9rPrFx8fLbrfr2WefdbRp3ry57HY7NXaRHTt2qEqVKqpdu7aGDx+uixcvOvZRU2tLS0uTJPn5+UlinhZ3P63nXczR4iknJ0dr1qzRjRs3FB4ezvx0IcIqisz333+vnJwcVa1a1Wl71apVdeHCBReNCvfy7LPP6u9//7s+//xzLVu2TBcuXFCLFi10+fJlR73uV8sLFy7Iw8NDlSpVumcbuMbDqt+FCxdUpUqVPP1XqVKFGrtAt27dtGrVKm3fvl0LFy7U/v371b59e2VmZkqiplZmjNHEiRPVqlUrNWjQQBLztDjLr54Sc7Q4OnLkiCpUqCBPT0+NGDFC69evV7169ZifLlTW1QNAyWez2ZyeG2PybIPrdevWzfF3WFiYwsPD9eSTT2r58uWOG0L8nFpSb+t4GPXLrz01do2+ffs6/m7QoIGaNGmi4OBg/eMf/1Dv3r3v+Tpq6nqjR4/Wl19+qV27duXZxzwtfu5VT+Zo8VOnTh0lJSXp6tWr+vjjjzVkyBDt3LnTsZ/5+eixsooiU7lyZZUpUybPN0UXL17M880UrMfb21thYWE6efKk467A96tlQECAbt++rStXrtyzDVzjYdUvICBA//rXv/L0f+nSJWpsAYGBgQoODtbJkyclUVOrGjNmjD799FPFxcXp8ccfd2xnnhZP96pnfpij1ufh4aFatWqpSZMmmjt3rho1aqR33nmH+elChFUUGQ8PDzVu3Fhbtmxx2r5lyxa1aNHCRaNCQWVmZio5OVmBgYGqUaOGAgICnGp5+/Zt7dy501HLxo0by93d3alNamqqjh49Sr1d7GHVLzw8XGlpadq3b5+jzd69e5WWlkaNLeDy5cs6d+6cAgMDJVFTqzHGaPTo0Vq3bp22b9+uGjVqOO1nnhYvD6pnfpijxY8xRpmZmcxPV3qkt3NCqbNmzRrj7u5u/va3v5ljx46Z8ePHG29vb3PmzBlXDw0/MWnSJLNjxw5z+vRpk5CQYHr06GEqVqzoqNW8efOM3W4369atM0eOHDH9+/c3gYGBJj093dHHiBEjzOOPP262bt1qDh48aNq3b28aNWpksrOzXXVYpca1a9fMoUOHzKFDh4wks2jRInPo0CHz7bffGmMeXv26du1qGjZsaOLj4018fLwJCwszPXr0eOTHWxrcr6bXrl0zkyZNMnv27DEpKSkmLi7OhIeHm+rVq1NTi/rP//xPY7fbzY4dO0xqaqrjkZGR4WjDPC0+HlRP5mjx8+qrr5ovvvjCpKSkmC+//NK89tprxs3NzWzevNkYw/x0FcIqitxf/vIXExwcbDw8PMwzzzzjdFt3WEffvn1NYGCgcXd3N9WqVTO9e/c2X331lWN/bm6umTFjhgkICDCenp6mTZs25siRI0593Lx504wePdr4+fmZ8uXLmx49epizZ88+6kMpleLi4oykPI8hQ4YYYx5e/S5fvmwGDhxoKlasaCpWrGgGDhxorly58oiOsnS5X00zMjJM586djb+/v3F3dzdPPPGEGTJkSJ56UVPryK+Wkkx0dLSjDfO0+HhQPZmjxc9LL73k+O9Vf39/06FDB0dQNYb56So2Y4x5dOu4AAAAAAA8GNesAgAAAAAsh7AKAAAAALAcwioAAAAAwHIIqwAAAAAAyyGsAgAAAAAsh7AKAAAAALAcwioAAAAAwHIIqwAAAAAAyyGsAgCAX6xt27YaP368q4cBAChBCKsAABSxoUOHymaz5Xl88803D6X/mJgY+fr6PpS+fq5169Zp9uzZLh3D/ezYsUM2m01Xr1519VAAAAVU1tUDAACgNOjatauio6Odtvn7+7toNPeWlZUld3f3Qr/Oz8+vCEbzcGRlZbl6CACAn4GVVQAAHgFPT08FBAQ4PcqUKSNJ+uyzz9S4cWOVK1dONWvW1KxZs5Sdne147aJFixQWFiZvb28FBQVp5MiRun79uqQ7K4a/+c1vlJaW5lixnTlzpiTJZrNpw4YNTuPw9fVVTEyMJOnMmTOy2Wz66KOP1LZtW5UrV04rV66UJEVHRys0NFTlypVT3bp19d577933+H56GnBISIjeeOMNDR48WBUqVFBwcLA++eQTXbp0Sb169VKFChUUFhamxMREx2vurhBv2LBBtWvXVrly5dSpUyedO3fO6b2WLl2qJ598Uh4eHqpTp45WrFjhtN9ms+n9999Xr1695O3trZdfflnt2rWTJFWqVEk2m01Dhw6VJMXGxqpVq1by9fXVY489ph49eujUqVOOvu5+RuvWrVO7du3k5eWlRo0aKT4+3uk9d+/erYiICHl5ealSpUrq0qWLrly5Ikkyxmj+/PmqWbOmypcvr0aNGul//ud/7vt5AgAIqwAAuNTnn3+uQYMGaezYsTp27Jg++OADxcTEaM6cOY42bm5uevfdd3X06FEtX75c27dv1+9//3tJUosWLfT222/Lx8dHqampSk1N1eTJkws1hqlTp2rs2LFKTk5Wly5dtGzZMk2bNk1z5sxRcnKy3nzzTU2fPl3Lly8vVL9//vOf1bJlSx06dEi//vWvFRUVpcGDB2vQoEE6ePCgatWqpcGDB8sY43hNRkaG5syZo+XLl2v37t1KT09Xv379HPvXr1+vcePGadKkSTp69Kh+97vf6Te/+Y3i4uKc3nvGjBnq1auXjhw5otdff10ff/yxJOn48eNKTU3VO++8I0m6ceOGJk6cqP3792vbtm1yc3PT888/r9zcXKf+pk2bpsmTJyspKUm1a9dW//79HV8oJCUlqUOHDqpfv77i4+O1a9cu9ezZUzk5OZKkP/zhD4qOjtbSpUv11VdfacKECRo0aJB27txZqM8TAEodAwAAitSQIUNMmTJljLe3t+PxwgsvGGOMad26tXnzzTed2q9YscIEBgbes7+PPvrIPPbYY47n0dHRxm6352knyaxfv95pm91uN9HR0cYYY1JSUowk8/bbbzu1CQoKMqtXr3baNnv2bBMeHn7PMUVERJhx48Y5ngcHB5tBgwY5nqemphpJZvr06Y5t8fHxRpJJTU11HIckk5CQ4GiTnJxsJJm9e/caY4xp0aKFGT58uNN79+nTx3Tv3t3puMePH+/UJi4uzkgyV65cuecxGGPMxYsXjSRz5MgRY8y/P6MPP/zQ0earr74ykkxycrIxxpj+/fubli1b5tvf9evXTbly5cyePXuctg8bNsz079//vmMBgNKOa1YBAHgE2rVrp6VLlzqee3t7S5IOHDig/fv3O62k5uTk6NatW8rIyJCXl5fi4uL05ptv6tixY0pPT1d2drZu3bqlGzduOPr5JZo0aeL4+9KlSzp37pyGDRum4cOHO7ZnZ2fLbrcXqt+GDRs6/q5ataokKSwsLM+2ixcvKiAgQJJUtmxZp/HUrVtXvr6+Sk5OVrNmzZScnKzf/va3Tu/TsmVLx0ppfsd0P6dOndL06dOVkJCg77//3rGievbsWTVo0CDfYwkMDHSMu27dukpKSlKfPn3y7f/YsWO6deuWOnXq5LT99u3bevrppws0RgAorQirAAA8At7e3qpVq1ae7bm5uZo1a5Z69+6dZ1+5cuX07bffqnv37hoxYoRmz54tPz8/7dq1S8OGDXvgjYNsNpvTKbZS/jcb+nHgvRvWli1bpmeffdap3d1rbAvqxzdqstls99z201Nu726/17af7jfG5NlW0BDfs2dPBQUFadmyZapWrZpyc3PVoEED3b59+4HHcnfc5cuXv2f/d9v84x//UPXq1Z32eXp6FmiMAFBaEVYBAHChZ555RsePH883yEpSYmKisrOztXDhQrm53bnVxEcffeTUxsPDw3F95I/5+/srNTXV8fzkyZPKyMi473iqVq2q6tWr6/Tp0xo4cGBhD+cXy87OVmJiopo1aybpzjWmV69eVd26dSVJoaGh2rVrlwYPHux4zZ49exQaGnrffj08PCTJ6XO6fPmykpOT9cEHH6h169aSpF27dhV6zA0bNtS2bds0a9asPPvq1asnT09PnT17VhEREYXuGwBKM8IqAAAu9Mc//lE9evRQUFCQ+vTpIzc3N3355Zc6cuSI3njjDT355JPKzs7W4sWL1bNnT+3evVvvv/++Ux8hISG6fv26tm3bpkaNGsnLy0teXl5q3769lixZoubNmys3N1dTp04t0M/SzJw5U2PHjpWPj4+6deumzMxMJSYm6sqVK5o4cWJRfRSS7qxgjhkzRu+++67c3d01evRoNW/e3BFep0yZohdffFHPPPOMOnTooM8++0zr1q3T1q1b79tvcHCwbDabNm7cqO7du6t8+fKqVKmSHnvsMf31r39VYGCgzp49q1deeaXQY3711VcVFhamkSNHasSIEfLw8FBcXJz69OmjypUra/LkyZowYYJyc3PVqlUrpaena8+ePapQoYKGDBnysz4nACgNuBswAAAu1KVLF23cuFFbtmxR06ZN1bx5cy1atEjBwcGSpKeeekqLFi3Sn/70JzVo0ECrVq3S3Llznfpo0aKFRowYob59+8rf31/z58+XJC1cuFBBQUFq06aNBgwYoMmTJ8vLy+uBY3r55Zf14YcfKiYmRmFhYYqIiFBMTIxq1Kjx8D+An/Dy8tLUqVM1YMAAhYeHq3z58lqzZo1jf2RkpN555x0tWLBA9evX1wcffKDo6Gi1bdv2vv1Wr15ds2bN0iuvvKKqVatq9OjRcnNz05o1a3TgwAE1aNBAEyZM0IIFCwo95tq1a2vz5s06fPiwmjVrpvDwcH3yyScqW/bOmsDs2bP1xz/+UXPnzlVoaKi6dOmizz777JF8ngBQnNnMTy9mAQAAcIGYmBiNHz9eV69edfVQAAAWwMoqAAAAAMByCKsAAAAAAMvhNGAAAAAAgOWwsgoAAAAAsBzCKgAAAADAcgirAAAAAADLIawCAAAAACyHsAoAAAAAsBzCKgAAAADAcgirAAAAAADLIawCAAAAACzn/wFz6RMlDximkwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x1200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from lightgbm import plot_importance\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10,12))\n",
    "plot_importance(lgbm_wrapper, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "egUn68R9AjSZ"
   },
   "source": [
    "## **3-2. HyperOpt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "YQfqj1GmGiYa"
   },
   "outputs": [],
   "source": [
    "from hyperopt import hp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dt90nZGGAjaO"
   },
   "source": [
    "### **3-2-a. 주어진 정보를 바탕으로 검색 공간을 설정해 주세요.**\n",
    "(힌트: `hp.uniform`)\n",
    "\n",
    "- max_depth: 5에서 20까지, 간격 = 1\n",
    "- min_child_weight: 1에서 2까지, 간격 = 1\n",
    "- colsample_bytree: 0.5, 1\n",
    "- learning_rate: 0.01에서 0.2 사이, 정규 분포된 값으로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "j9hI35hEBenL"
   },
   "outputs": [],
   "source": [
    "search_space ={'max_depth': hp.quniform('max_depth', 5, 20, 1), \n",
    "                'min_child_weight': hp.quniform('min_child_weight', 1,2,1),\n",
    "                'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1),\n",
    "                'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n",
    "               }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3cSRp1UDAji8"
   },
   "source": [
    "### **3-2-b. 검색 공간을 인자로 받아 목적함수를 완성해 주세요.**\n",
    "(n_estimators = 800)  \n",
    "(❓❓❓❓❓로 표시된 빈칸을 채워주세요!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "VIi05vIgHFKQ"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "from hyperopt import STATUS_OK\n",
    "\n",
    "\n",
    "def objective_func(search_space):\n",
    "    xgb_clf = XGBClassifier(n_estimators = 800,\n",
    "                            max_depth = int(search_space['max_depth']),\n",
    "                            min_child_weight = int(search_space['min_child_weight']),\n",
    "                            learning_rate = search_space['learning_rate'],\n",
    "                            colsample_bytree = search_space['colsample_bytree'],\n",
    "                            eval_metric = 'logloss')\n",
    "    accuracy = cross_val_score(xgb_clf, X_train, y_train, scoring = 'accuracy', cv = 3)\n",
    "\n",
    "    return {'loss':-1 * np.mean(accuracy), 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dpFPo2bIBKYA"
   },
   "source": [
    "### **3-2-c. best에 `fmin()` 함수를 이용하여 최적 파라미터 값들을 저장해 주세요.**\n",
    "- fn, 검색공간: 위에서 구한 값\n",
    "- 최대 반복 횟수: 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "oagDclMCKKmS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 50/50 [00:20<00:00,  2.38trial/s, best loss: -0.9142857142857143]\n",
      "best: {'colsample_bytree': 0.8158036761298297, 'learning_rate': 0.012161026844951692, 'max_depth': 12.0, 'min_child_weight': 1.0}\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, Trials\n",
    "\n",
    "trial_val = Trials()\n",
    "best = fmin(fn = objective_func,\n",
    "            space = search_space,\n",
    "            algo = tpe.suggest,\n",
    "            max_evals = 50,\n",
    "            trials = trial_val,\n",
    "            rstate = np.random.default_rng(seed = 9))\n",
    "print('best:', best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X00SYdMqBKf-"
   },
   "source": [
    "### **3-2-d. 아래는 best에 포함된 최적 파라미터들을 할당한 분류기입니다. 해당 분류기의 정확도를 출력해 주세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "YWG7Vx8qLskd"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (121047264.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[46], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    xgb_wrapper.fit(X_tr, y_tr, , eval_metric = 'logloss',\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "xgb_wrapper = XGBClassifier(n_estimators = 400,\n",
    "                            learning_rate = round(best['learning_rate'], 5),\n",
    "                            max_depth = int(best['max_depth']),\n",
    "                            min_child_weight = int(best['min_child_weight']),\n",
    "                            colsample_bytree = round(best['colsample_bytree'], 5)\n",
    "                           )\n",
    "\n",
    "evals = [(X_tr, y_tr), (X_val, y_val)]\n",
    "xgb_wrapper.fit(X_tr, y_tr, , eval_metric = 'logloss',\n",
    "                eval_set = evals, verbose = 0)\n",
    "\n",
    "print('정확도:{0:.4f}'.format(xgb_accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zi7nlAXnaIvx"
   },
   "source": [
    "# **4. 스태킹**\n",
    "- 4번 문제는 3번 문제에서 전처리 된 `water_potability.csv` 데이터를 계속 활용하시면 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zo-EqV9IaOHE"
   },
   "source": [
    "## **4-a. 기본 스태킹 기법을 적용해 봅시다.**\n",
    "- `SVM`, `KNN`, `로지스틱 회귀`, `결정 트리` 모델 객체를 생성해 주세요.\n",
    "- 최종 메타 모델은 `랜덤 포레스트`를 활용해주세요.\n",
    "- 파라미터 설정\n",
    "  - SVM: random_state = 0\n",
    "  - KNN: n_neighbors = 8\n",
    "  - RandomForest: n_estimators = 100, random_state = 0\n",
    "  - 나머지: 기본 파라미터(base model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "A8oVE61iW2rE"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "-g8nzDlXW_hD"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# SVM, KNN, 로지스틱 회귀, 결정 트리 개별 모델들을 생성해 주세요.\n",
    "svm_clf = SVC(random_state = 0)\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=8)\n",
    "lr_clf = LogisticRegression()\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "\n",
    "# 최종 메타 모델로 랜덤 포레스트를 생성해 주세요.\n",
    "rf_final = RandomForestClassifier(n_estimators = 100, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_kiFDVuDZ92_"
   },
   "source": [
    "## **4-b. 개별 모델들을 학습시키고 예측을 수행합니다.**\n",
    "- 아래 코드를 완성시켜 봅시다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "Vda9AE6ga1ne"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf.fit(X_tr, y_tr)\n",
    "knn_clf.fit(X_tr, y_tr)\n",
    "lr_clf.fit(X_tr, y_tr)\n",
    "dt_clf.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bqQEJMSwbXfz"
   },
   "outputs": [],
   "source": [
    "## 학습된 개별 모델들이 반환하는 예측 데이터셋을 생성하세요.\n",
    "# 예측 시 들어가는 테스트 데이터셋 이름은 X_val 입니다.\n",
    "svm_pred = svm_clf.predict(X_val)\n",
    "knn_pred = knn_clf.predict(X_val)\n",
    "lr_pred = lr_clf.predict(X_val)\n",
    "dt_pred = dt_clf.predict(X_val)\n",
    "\n",
    "## 예측 정확도를 반환하세요. 테스트 레이블 데이터셋 이름은 y_val 입니다.\n",
    "# hint : accuracy_score()\n",
    "print('SVM 정확도: {0:.4f}'.format())\n",
    "print('KNN 정확도: {0:.4f}'.format())\n",
    "print('로지스틱 회귀 정확도: {0:.4f}'.format())\n",
    "print('결정 트리 정확도: {0:.4f}'.format())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AmQiW4i4c_9B"
   },
   "source": [
    "## **4-c. 반환된 예측 데이터셋을 행 형태로 묶어 pred 데이터셋에 저장합니다**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Od3yHZ3fc8Uf"
   },
   "outputs": [],
   "source": [
    "pred =\n",
    "print(pred.shape)\n",
    "\n",
    "# 행과 열의 위치를 교환해 원본 데이터 값 하나 당 예측 데이터셋의 값이 1대1 매칭이 되도록 하세요.\n",
    "pred =\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h8rhG78DdzpT"
   },
   "source": [
    "## **4-d. 완성된 최종 데이터셋을 최종 메타 모델에 학습시키고 예측시킵니다.**\n",
    "- 기본 스태킹 모델이므로 학습과 예측 모두 **동일한** 데이터셋을 사용합니다.\n",
    "- **정확도**도 함께 출력해 주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eDf69kCPebqf"
   },
   "outputs": [],
   "source": [
    "rf_final.fit()\n",
    "final =\n",
    "\n",
    "print('최종 메타 모델의 예측 정확도: {0:.4f}'.format(accuracy_score(y_val , final)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bt9i77_NqqJp"
   },
   "source": [
    "# **5. CatBoost**\n",
    "- 책에서 다루지 않는 부분이기 때문에 간단한 실습만 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "bUp-KlCjr7nt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-3.3.0-py3-none-any.whl (404 kB)\n",
      "\u001b[K     |████████████████████████████████| 404 kB 2.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting PyYAML\n",
      "  Downloading PyYAML-6.0.1-cp39-cp39-macosx_10_9_x86_64.whl (197 kB)\n",
      "\u001b[K     |████████████████████████████████| 197 kB 37.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tqdm\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 21.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cmaes>=0.10.0\n",
      "  Downloading cmaes-0.10.0-py3-none-any.whl (29 kB)\n",
      "Collecting colorlog\n",
      "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting sqlalchemy>=1.3.0\n",
      "  Downloading SQLAlchemy-2.0.21-cp39-cp39-macosx_10_9_x86_64.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 49.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting alembic>=1.5.0\n",
      "  Downloading alembic-1.12.0-py3-none-any.whl (226 kB)\n",
      "\u001b[K     |████████████████████████████████| 226 kB 52.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from optuna) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from optuna) (21.3)\n",
      "Collecting typing-extensions>=4\n",
      "  Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
      "Collecting Mako\n",
      "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 35.0 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from packaging>=20.0->optuna) (3.0.9)\n",
      "Collecting greenlet!=0.4.17\n",
      "  Downloading greenlet-2.0.2-cp39-cp39-macosx_11_0_x86_64.whl (241 kB)\n",
      "\u001b[K     |████████████████████████████████| 241 kB 25.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.9.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.1)\n",
      "Installing collected packages: typing-extensions, greenlet, sqlalchemy, Mako, tqdm, PyYAML, colorlog, cmaes, alembic, optuna\n",
      "Successfully installed Mako-1.2.4 PyYAML-6.0.1 alembic-1.12.0 cmaes-0.10.0 colorlog-6.7.0 greenlet-2.0.2 optuna-3.3.0 sqlalchemy-2.0.21 tqdm-4.66.1 typing-extensions-4.8.0\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.9/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting catboost\n",
      "  Downloading catboost-1.2.2-cp39-cp39-macosx_11_0_universal2.whl (25.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 25.8 MB 11.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pandas>=0.24\n",
      "  Downloading pandas-2.1.1-cp39-cp39-macosx_10_9_x86_64.whl (11.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.8 MB 10.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from catboost) (1.16.0)\n",
      "Collecting plotly\n",
      "  Downloading plotly-5.17.0-py2.py3-none-any.whl (15.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 15.6 MB 12.3 MB/s eta 0:00:01     |████████████████████████        | 11.7 MB 12.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from catboost) (1.26.0)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from catboost) (1.11.2)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.8.0-cp39-cp39-macosx_10_12_x86_64.whl (7.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.6 MB 4.7 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: graphviz in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from catboost) (0.20.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pandas>=0.24->catboost) (2022.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pandas>=0.24->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pandas>=0.24->catboost) (2022.2.1)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.43.0-cp39-cp39-macosx_10_9_x86_64.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 8.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.1.1-cp39-cp39-macosx_10_9_x86_64.whl (247 kB)\n",
      "\u001b[K     |████████████████████████████████| 247 kB 9.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cycler>=0.10\n",
      "  Downloading cycler-0.12.0-py3-none-any.whl (8.2 kB)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from matplotlib->catboost) (9.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from matplotlib->catboost) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from matplotlib->catboost) (21.3)\n",
      "Collecting importlib-resources>=3.2.0\n",
      "  Downloading importlib_resources-6.1.0-py3-none-any.whl (33 kB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.4.5-cp39-cp39-macosx_10_9_x86_64.whl (68 kB)\n",
      "\u001b[K     |████████████████████████████████| 68 kB 1.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting zipp>=3.1.0\n",
      "  Downloading zipp-3.17.0-py3-none-any.whl (7.4 kB)\n",
      "Collecting tenacity>=6.2.0\n",
      "  Downloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: zipp, tenacity, kiwisolver, importlib-resources, fonttools, cycler, contourpy, plotly, pandas, matplotlib, catboost\n",
      "Successfully installed catboost-1.2.2 contourpy-1.1.1 cycler-0.12.0 fonttools-4.43.0 importlib-resources-6.1.0 kiwisolver-1.4.5 matplotlib-3.8.0 pandas-2.1.1 plotly-5.17.0 tenacity-8.2.3 zipp-3.17.0\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.9/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# catboost를 사용하기 위해 다음 코드를 실행합니다.\n",
    "\n",
    "!pip install optuna\n",
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "xbcYHmIsqycq"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'catboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datasets\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metrics\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcatboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CatBoostClassifier\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'catboost'"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "cT3d6EKqsJRj"
   },
   "outputs": [],
   "source": [
    "df = datasets.load_iris()\n",
    "X = df.data\n",
    "y = df.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8t-R1-Wfskfm"
   },
   "outputs": [],
   "source": [
    "# CatBoostClassifier 객체를 생성하고 학습시켜 주세요.\n",
    "\n",
    "model_CBC =\n",
    "model_CBC.fit(X_train, y_train, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7yfAnYNXs4LW"
   },
   "outputs": [],
   "source": [
    "# pred에 X_test에 대한 예측 결과를 저장해 주세요.\n",
    "pred =\n",
    "\n",
    "# 아래 코드를 완성해서 정확도를 출력하세요.\n",
    "print('CatBoost의 예측 정확도: {0:.4f}'.format())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
