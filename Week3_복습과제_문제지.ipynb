{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **1. GBM**\n"],"metadata":{"id":"oW4LpW9lRj3n"}},{"cell_type":"markdown","source":["## **1-a. `creditcard.csv`를 다운받은 후 실습을 진행해 주세요.**\n","- 데이터 출처: [Credit Card Fraud Detection](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)"],"metadata":{"id":"s3_1vAdpRxoo"}},{"cell_type":"code","source":["## Colab - 구글 드라이브 마운트\n","# Colab을 사용하시는 분들만 실행시켜 주시면 됩니다.\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"3vR5gQ4HYGAX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df ="],"metadata":{"id":"lkOKaEKZG2Yn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **1-b. GradientBoostingClassifier을 이용하여 훈련 데이터를 fit한 후, GBM 정확도와 수행시간을 구하세요.**\n","(test_size = 0.2, random_state = 42)"],"metadata":{"id":"2_tC0W-5Ryje"}},{"cell_type":"code","source":["from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import train_test_split\n","import time\n","import warnings\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"7zBOFln9ZENb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## 데이터 분할: 훈련 데이터와 테스트 데이터\n","\n","X = df.drop('Class', axis=1)\n","y = df['Class']\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n","\n","## GBM 모델링\n","# 아래에 코드를 작성해 주세요.\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"967Hgk2YZXfa","outputId":"aa8b3623-a718-43f5-d07d-87cd0ec29b85"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["GBM 정확도: 0.9989\n"]}]},{"cell_type":"markdown","source":["## **1-b(2). GBM으로 학습하는 시간이 얼마나 걸리는지 수행 시간을 출력해 주세요.**"],"metadata":{"id":"0_npf7xNR1BZ"}},{"cell_type":"code","source":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FdMUSczWa8_A","outputId":"c47927fd-a125-4cab-a190-761f256d0009"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["GBM 수행 시간: 1587.6 초\n"]}]},{"cell_type":"markdown","source":["## **1-c. ```subsample``` 파라미터를 설정하여 gbm 모델을 학습시키고 학습 시간을 비교해 보세요.**  \n","(subsample = 0.8)"],"metadata":{"id":"xqzN9Hy8TaOk"}},{"cell_type":"code","source":["from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import train_test_split\n","import time\n","import warnings\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"FxWwRW_7TbT0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4HAD9Ebsgte4","outputId":"78b3f503-efbf-44f5-d170-4a05d34651e8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["GBM (subsample=0.8) 정확도: 0.9991\n","GBM (subsample=0.8) 수행 시간: 423.6 초\n"]}]},{"cell_type":"markdown","source":["# **2. XGBoost**"],"metadata":{"id":"D52196vv7JoI"}},{"cell_type":"markdown","source":["- 모델 : Python Wrapper XGBoost\n","- 적용 데이터 : 위스콘신 유방암 데이터"],"metadata":{"id":"koZCKhp8HW4o"}},{"cell_type":"code","source":["import xgboost\n","\n","print(xgboost.__version__)"],"metadata":{"id":"ECMkbXJ-7KT6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- 출력 : 1.7.3"],"metadata":{"id":"5kFl0zeC7tQR"}},{"cell_type":"code","source":["import xgboost as xgb\n","from xgboost import plot_importance\n","\n","import pandas as pd\n","import numpy as np\n","\n","from sklearn.datasets import load_breast_cancer\n","from sklearn.model_selection import train_test_split\n","\n","import warnings\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"fHDjuv_V7vAf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##**2-a. cancer_df의 shape을 프린트하고, 상위 5개 행을 확인해 주세요.**"],"metadata":{"id":"L11sPCSZ74oH"}},{"cell_type":"code","source":["dataset = load_breast_cancer()\n","X_features = dataset.data\n","y_label = dataset.target\n","\n","cancer_df = pd.DataFrame(data = X_features, columns = dataset.feature_names)\n","cancer_df['target'] = y_label"],"metadata":{"id":"4wBOlQxn72Te"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"cMfEC-nZ8HH-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **2-b. 전체 데이터 중 80%는 학습용 데이터, 20%는 테스트용 데이터로 추출하고, 각각의 shape을 print해주세요.**"],"metadata":{"id":"tOKlsQLD8HoD"}},{"cell_type":"code","source":[],"metadata":{"id":"o6k1w2nf8SCm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dtrain = xgb.DMatrix(data = X_train, label = y_train)\n","dtest = xgb.DMatrix(data = X_test, label = y_test)"],"metadata":{"id":"9ZB87ux88a6w"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##**2-c. 주어진 정보를 바탕으로 하이퍼 파라미터 목록을 완성해 주세요.**\n","- 트리의 최대 깊이 : 3\n","- 학습률 : 0.1\n","- 반복 횟수 : 400"],"metadata":{"id":"tzzNfY028f5b"}},{"cell_type":"code","source":["params = {\n","          'objective':'binary:logistic',\n","          'eval_metric':'logloss'\n","         }\n","num_rounds ="],"metadata":{"id":"BZIEP5CS8jSs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["eval_list = [(dtrain,'train'),(dtest,'eval')]"],"metadata":{"id":"UInEOEh98t6z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **2-d. 하이퍼 파라미터를 `train( )` 함수의 파라미터로 전달해 주세요.**"],"metadata":{"id":"Mzl7NufX8utk"}},{"cell_type":"code","source":[],"metadata":{"id":"5vgia5qw8vCa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pred_probs = xgb_model.predict(dtest)\n","print('predict( ) 수행 결과값을 10개만 표시, 예측 확률 값으로 표시됨')\n","print(np.round(pred_probs[:10],3))\n","\n","# 예측 확률이 0.5 보다 크면 1 , 그렇지 않으면 0 으로 예측값 결정하여 List 객체인 preds에 저장\n","preds = [ 1 if x > 0.5 else 0 for x in pred_probs ]\n","print('예측값 10개만 표시:',preds[:10])"],"metadata":{"id":"5UFWSwQp8yA8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##**2-e. `get_eval_clf()` 을 통해 예측 평가를 진행해주세요**"],"metadata":{"id":"Mxk9DN5383sp"}},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix, accuracy_score\n","from sklearn.metrics import precision_score, recall_score\n","from sklearn.metrics import f1_score, roc_auc_score\n","\n","def get_clf_eval(y_test, pred=None, pred_proba=None):\n","    confusion = confusion_matrix( y_test, pred)\n","    accuracy = accuracy_score(y_test , pred)\n","    precision = precision_score(y_test , pred)\n","    recall = recall_score(y_test , pred)\n","    f1 = f1_score(y_test,pred)\n","    # ROC-AUC 추가\n","    roc_auc = roc_auc_score(y_test, pred_proba)\n","    print('오차 행렬')\n","    print(confusion)\n","    # ROC-AUC print 추가\n","    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\\\n","    F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))"],"metadata":{"id":"xS27kc1780cD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"v-foPK_M82hT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **3. LightGBM, HyperOpt**"],"metadata":{"id":"uvg4b6ap9lXg"}},{"cell_type":"markdown","source":["## **3-1. LightGBM**"],"metadata":{"id":"f8SBYxBJ-vhb"}},{"cell_type":"markdown","source":["### **3-1-a. ```water_potability.csv```를 불러와 df에 저장해 주세요.**"],"metadata":{"id":"SnRlTMVaIdU6"}},{"cell_type":"code","source":["# 3.3.2 버전으로 LightGBM을 설치합니다(일부 파라미터가 4.0.0에선 작동하지 않아서 넣었습니다.)\n","\n","!pip install lightgbm==3.3.2\n","print(lightgbm.__version__) # 버전 확인용"],"metadata":{"id":"3cg-dfFE-nOx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import lightgbm\n","from lightgbm import LGBMClassifier\n","\n","import pandas as pd\n","import numpy as np"],"metadata":{"id":"ZcpuDJ8GIoBD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df =\n","\n","# 데이터 확인\n","df.head()"],"metadata":{"id":"z3XVGeXr-_kt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **3-1-b. 이럴수가! 결측값이 있는 것 같네요! 아래의 코드를 실행시켜 어느 변수에 결측값이 있는지 확인하고, 결측값들은 모두 해당하는 변수의 평균으로 바꿔주세요.**"],"metadata":{"id":"cXSVbYeI_DGz"}},{"cell_type":"code","source":["df.isnull().sum()"],"metadata":{"id":"r4nKg2mF_FHE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## 결측값을 해당 칼럼의 평균값으로 대체해 주세요.\n","# 힌트: 파머완 138페이지\n","\n","\n","\n","\n","\n","\n","\n","# 데이터 확인\n","df.head()"],"metadata":{"id":"I3Iq_aHA_XUi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **3-1-c. df를 학습용 데이터와 테스트용 데이터로 분리해 주세요.**  \n","(random_state = 42, 학습용 데이터가 전체의 **80%**를 차지하도록 설정)"],"metadata":{"id":"OyXaOw0X_aXZ"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","X = df.iloc[:, :-1]\n","y = df.iloc[:, -1]\n","\n","X_train, X_test, y_train, y_test ="],"metadata":{"id":"oWbfGB4c_Znx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **3-1-d. 위에서 만든 X_train, y_train을 다시 나누어 90%는 학습용으로, 10%는 검증용 데이터로 분리해 주세요.**  \n","(random_state = 42)"],"metadata":{"id":"hW1x8hQI_krM"}},{"cell_type":"code","source":["X_tr, X_val, y_tr, y_val ="],"metadata":{"id":"QPuPw7bb_qF8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **3-1-e. 다음 조건에 따라 LGBMClassifier을 생성한 후 ```lgbm_wrapper```에 저장해 주세요.**\n","- 반복 수행할 트리 개수: 800개\n","- 학습률: 0.02"],"metadata":{"id":"hEyCPkHZ_tYC"}},{"cell_type":"code","source":["lgbm_wrapper ="],"metadata":{"id":"4gPkmQo3_zlS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **3-1-f. `lgbm_wrapper`가 100번 학습을 반복해도 성능이 향상되지 않으면 수행을 멈추도록 설정해서 학습시키세요.**\n","- 평가 지표: logloss  \n","\n","(❓❓❓❓❓로 표시된 빈칸을 채워주세요!)"],"metadata":{"id":"unGn5aOi_2LG"}},{"cell_type":"code","source":["evals = [(X_tr, y_tr), (X_val, y_val)]\n","lgbm_wrapper.fit(❓❓❓❓❓)"],"metadata":{"id":"89l5qcaB_6QV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **3-1-g. 위에서 학습시킨 `lgbm_wrapper`의 정확도를 출력하세요.**"],"metadata":{"id":"z3YiAxdOAhqh"}},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score\n","\n"],"metadata":{"id":"yrG3MF-JAom3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **3-1-i. 피처 중요도를 중요한 순서대로 시각화 해주세요.**\n","(힌트: 파머완 252 페이지)"],"metadata":{"id":"s5_joSurAjHs"}},{"cell_type":"code","source":["from lightgbm import plot_importance\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","\n"],"metadata":{"id":"5PG_98tJBfB9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **3-2. HyperOpt**"],"metadata":{"id":"egUn68R9AjSZ"}},{"cell_type":"code","source":["from hyperopt import hp"],"metadata":{"id":"YQfqj1GmGiYa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **3-2-a. 주어진 정보를 바탕으로 검색 공간을 설정해 주세요.**\n","(힌트: `hp.uniform`)\n","\n","- max_depth: 5에서 20까지, 간격 = 1\n","- min_child_weight: 1에서 2까지, 간격 = 1\n","- colsample_bytree: 0.5, 1\n","- learning_rate: 0.01에서 0.2 사이, 정규 분포된 값으로"],"metadata":{"id":"Dt90nZGGAjaO"}},{"cell_type":"code","source":["search_space ="],"metadata":{"id":"j9hI35hEBenL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **3-2-b. 검색 공간을 인자로 받아 목적함수를 완성해 주세요.**\n","(n_estimators = 800)  \n","(❓❓❓❓❓로 표시된 빈칸을 채워주세요!)"],"metadata":{"id":"3cSRp1UDAji8"}},{"cell_type":"code","source":["from sklearn.model_selection import cross_val_score\n","from xgboost import XGBClassifier\n","from hyperopt import STATUS_OK\n","\n","\n","def objective_func(search_space):\n","    xgb_clf = XGBClassifier(n_estimators = 800,\n","                            max_depth = ❓❓❓❓❓,\n","                            min_child_weight = ❓❓❓❓❓,\n","                            learning_rate = ❓❓❓❓❓,\n","                            colsample_bytree = ❓❓❓❓❓,\n","                            eval_metric = 'logloss')\n","    accuracy = cross_val_score(xgb_clf, X_train, y_train, scoring = 'accuracy', cv = 3)\n","\n","    return {'loss':-1 * np.mean(accuracy), 'status': STATUS_OK}"],"metadata":{"id":"VIi05vIgHFKQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **3-2-c. best에 `fmin()` 함수를 이용하여 최적 파라미터 값들을 저장해 주세요.**\n","- fn, 검색공간: 위에서 구한 값\n","- 최대 반복 횟수: 50"],"metadata":{"id":"dpFPo2bIBKYA"}},{"cell_type":"code","source":["from hyperopt import fmin, tpe, Trials\n","\n","trial_val = Trials()\n","best = fmin(❓❓❓,\n","            ❓❓❓,\n","            algo = tpe.suggest,\n","            ❓❓❓,\n","            trials = trial_val,\n","            rstate = np.random.default_rng(seed = 9))\n","print('best:', best)"],"metadata":{"id":"oagDclMCKKmS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **3-2-d. 아래는 best에 포함된 최적 파라미터들을 할당한 분류기입니다. 해당 분류기의 정확도를 출력해 주세요.**"],"metadata":{"id":"X00SYdMqBKf-"}},{"cell_type":"code","source":["xgb_wrapper = XGBClassifier(n_estimators = 400,\n","                            learning_rate = round(best['learning_rate'], 5),\n","                            max_depth = int(best['max_depth']),\n","                            min_child_weight = int(best['min_child_weight']),\n","                            colsample_bytree = round(best['colsample_bytree'], 5)\n","                           )\n","\n","evals = [(X_tr, y_tr), (X_val, y_val)]\n","xgb_wrapper.fit(X_tr, y_tr, ❓❓❓, eval_metric = 'logloss',\n","                eval_set = evals, verbose = 0)\n","\n"],"metadata":{"id":"YWG7Vx8qLskd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **4. 스태킹**\n","- 4번 문제는 3번 문제에서 전처리 된 `water_potability.csv` 데이터를 계속 활용하시면 됩니다."],"metadata":{"id":"Zi7nlAXnaIvx"}},{"cell_type":"markdown","source":["## **4-a. 기본 스태킹 기법을 적용해 봅시다.**\n","- `SVM`, `KNN`, `로지스틱 회귀`, `결정 트리` 모델 객체를 생성해 주세요.\n","- 최종 메타 모델은 `랜덤 포레스트`를 활용해주세요.\n","- 파라미터 설정\n","  - SVM: random_state = 0\n","  - KNN: n_neighbors = 8\n","  - RandomForest: n_estimators = 100, random_state = 0\n","  - 나머지: 기본 파라미터(base model)"],"metadata":{"id":"zo-EqV9IaOHE"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","%matplotlib inline"],"metadata":{"id":"A8oVE61iW2rE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# SVM, KNN, 로지스틱 회귀, 결정 트리 개별 모델들을 생성해 주세요.\n","svm_clf =\n","knn_clf =\n","lr_clf =\n","dt_clf =\n","\n","# 최종 메타 모델로 랜덤 포레스트를 생성해 주세요.\n","rf_final ="],"metadata":{"id":"-g8nzDlXW_hD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **4-b. 개별 모델들을 학습시키고 예측을 수행합니다.**\n","- 아래 코드를 완성시켜 봅시다.\n","\n"],"metadata":{"id":"_kiFDVuDZ92_"}},{"cell_type":"code","source":["svm_clf.fit(X_tr, y_tr)\n","knn_clf.fit()\n","lr_clf.fit()\n","dt_clf.fit()"],"metadata":{"id":"Vda9AE6ga1ne"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## 학습된 개별 모델들이 반환하는 예측 데이터셋을 생성하세요.\n","# 예측 시 들어가는 테스트 데이터셋 이름은 X_val 입니다.\n","svm_pred =\n","knn_pred =\n","lr_pred =\n","dt_pred =\n","\n","## 예측 정확도를 반환하세요. 테스트 레이블 데이터셋 이름은 y_val 입니다.\n","# hint : accuracy_score()\n","print('SVM 정확도: {0:.4f}'.format())\n","print('KNN 정확도: {0:.4f}'.format())\n","print('로지스틱 회귀 정확도: {0:.4f}'.format())\n","print('결정 트리 정확도: {0:.4f}'.format())"],"metadata":{"id":"bqQEJMSwbXfz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **4-c. 반환된 예측 데이터셋을 행 형태로 묶어 pred 데이터셋에 저장합니다**"],"metadata":{"id":"AmQiW4i4c_9B"}},{"cell_type":"code","source":["pred =\n","print(pred.shape)\n","\n","# 행과 열의 위치를 교환해 원본 데이터 값 하나 당 예측 데이터셋의 값이 1대1 매칭이 되도록 하세요.\n","pred =\n","print(pred.shape)"],"metadata":{"id":"Od3yHZ3fc8Uf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **4-d. 완성된 최종 데이터셋을 최종 메타 모델에 학습시키고 예측시킵니다.**\n","- 기본 스태킹 모델이므로 학습과 예측 모두 **동일한** 데이터셋을 사용합니다.\n","- **정확도**도 함께 출력해 주세요."],"metadata":{"id":"h8rhG78DdzpT"}},{"cell_type":"code","source":["rf_final.fit()\n","final =\n","\n","print('최종 메타 모델의 예측 정확도: {0:.4f}'.format(accuracy_score(y_val , final)))"],"metadata":{"id":"eDf69kCPebqf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **5. CatBoost**\n","- 책에서 다루지 않는 부분이기 때문에 간단한 실습만 진행합니다."],"metadata":{"id":"Bt9i77_NqqJp"}},{"cell_type":"code","source":["# catboost를 사용하기 위해 다음 코드를 실행합니다.\n","\n","!pip install optuna\n","!pip install catboost"],"metadata":{"id":"bUp-KlCjr7nt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn import datasets\n","from sklearn import metrics\n","from catboost import CatBoostClassifier"],"metadata":{"id":"xbcYHmIsqycq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = datasets.load_iris()\n","X = df.data\n","y = df.target\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"],"metadata":{"id":"cT3d6EKqsJRj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# CatBoostClassifier 객체를 생성하고 학습시켜 주세요.\n","\n","model_CBC =\n","model_CBC.fit(X_train, y_train, verbose = 0)"],"metadata":{"id":"8t-R1-Wfskfm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# pred에 X_test에 대한 예측 결과를 저장해 주세요.\n","pred =\n","\n","# 아래 코드를 완성해서 정확도를 출력하세요.\n","print('CatBoost의 예측 정확도: {0:.4f}'.format())"],"metadata":{"id":"7yfAnYNXs4LW"},"execution_count":null,"outputs":[]}]}