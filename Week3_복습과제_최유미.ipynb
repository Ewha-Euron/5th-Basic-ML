{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oW4LpW9lRj3n"
   },
   "source": [
    "# **1. GBM**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s3_1vAdpRxoo"
   },
   "source": [
    "## **1-a. `creditcard.csv`를 다운받은 후 실습을 진행해 주세요.**\n",
    "- 데이터 출처: [Credit Card Fraud Detection](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "3vR5gQ4HYGAX"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## Colab - 구글 드라이브 마운트\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Colab을 사용하시는 분들만 실행시켜 주시면 됩니다.\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[0;32m      5\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "## Colab - 구글 드라이브 마운트\n",
    "# Colab을 사용하시는 분들만 실행시켜 주시면 됩니다.\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "lkOKaEKZG2Yn"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "df = pd.read_csv(r\"C:\\Users\\jain5\\Desktop\\Euron\\Data_Handling\\creditcard.csv\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2_tC0W-5Ryje"
   },
   "source": [
    "## **1-b. GradientBoostingClassifier을 이용하여 훈련 데이터를 fit한 후, GBM 정확도와 수행시간을 구하세요.**\n",
    "(test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "7zBOFln9ZENb"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "967Hgk2YZXfa",
    "outputId": "aa8b3623-a718-43f5-d07d-87cd0ec29b85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM 정확도: 0.9989\n"
     ]
    }
   ],
   "source": [
    "## 데이터 분할: 훈련 데이터와 테스트 데이터\n",
    "\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "## GBM 모델링\n",
    "# 아래에 코드를 작성해 주세요.\n",
    "start_time = time.time()\n",
    "gb_clf = GradientBoostingClassifier(random_state=0)\n",
    "gb_clf.fit(X_train , y_train)\n",
    "gb_pred = gb_clf.predict(X_test)\n",
    "gb_accuracy = accuracy_score(y_test, gb_pred)\n",
    "\n",
    "print('GBM 정확도: {0:.4f}'.format(gb_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0_npf7xNR1BZ"
   },
   "source": [
    "## **1-b(2). GBM으로 학습하는 시간이 얼마나 걸리는지 수행 시간을 출력해 주세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FdMUSczWa8_A",
    "outputId": "c47927fd-a125-4cab-a190-761f256d0009"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM 수행 시간: 573.7 초 \n"
     ]
    }
   ],
   "source": [
    "print(\"GBM 수행 시간: {0:.1f} 초 \".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xqzN9Hy8TaOk"
   },
   "source": [
    "## **1-c. ```subsample``` 파라미터를 설정하여 gbm 모델을 학습시키고 학습 시간을 비교해 보세요.**  \n",
    "(subsample = 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "subsample : 개별 약한 학습기가 전체 데이터 중 몇 퍼센트를 기반으로 학습할 지 결정하는 파라미터. default=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "FxWwRW_7TbT0"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4HAD9Ebsgte4",
    "outputId": "78b3f503-efbf-44f5-d170-4a05d34651e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM 정확도2: 0.9991\n",
      "GBM 수행 시간2: 426.1 초 \n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "gb_clf2 = GradientBoostingClassifier(subsample=0.8, random_state=0)\n",
    "gb_clf2.fit(X_train , y_train)\n",
    "gb_pred2 = gb_clf2.predict(X_test)\n",
    "gb_accuracy2 = accuracy_score(y_test, gb_pred2)\n",
    "\n",
    "print('GBM 정확도2: {0:.4f}'.format(gb_accuracy2))\n",
    "print(\"GBM 수행 시간2: {0:.1f} 초 \".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D52196vv7JoI"
   },
   "source": [
    "# **2. XGBoost**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "koZCKhp8HW4o"
   },
   "source": [
    "- 모델 : Python Wrapper XGBoost\n",
    "- 적용 데이터 : 위스콘신 유방암 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ECMkbXJ-7KT6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.3\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "\n",
    "print(xgboost.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5kFl0zeC7tQR"
   },
   "source": [
    "- 출력 : 1.7.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "fHDjuv_V7vAf"
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L11sPCSZ74oH"
   },
   "source": [
    "##**2-a. cancer_df의 shape을 프린트하고, 상위 5개 행을 확인해 주세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "4wBOlQxn72Te"
   },
   "outputs": [],
   "source": [
    "dataset = load_breast_cancer()\n",
    "X_features = dataset.data\n",
    "y_label = dataset.target\n",
    "\n",
    "cancer_df = pd.DataFrame(data = X_features, columns = dataset.feature_names)\n",
    "cancer_df['target'] = y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "cMfEC-nZ8HH-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 31)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "3          0.6638                  0.17300       0  \n",
       "4          0.2364                  0.07678       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(cancer_df.shape)\n",
    "cancer_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tOKlsQLD8HoD"
   },
   "source": [
    "## **2-b. 전체 데이터 중 80%는 학습용 데이터, 20%는 테스트용 데이터로 추출하고, 각각의 shape을 print해주세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "o6k1w2nf8SCm"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y_label, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "9ZB87ux88a6w"
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(data = X_train, label = y_train)\n",
    "dtest = xgb.DMatrix(data = X_test, label = y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455, 30) (114, 30)\n",
      "(455,) (114,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape , X_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tzzNfY028f5b"
   },
   "source": [
    "##**2-c. 주어진 정보를 바탕으로 하이퍼 파라미터 목록을 완성해 주세요.**\n",
    "- 트리의 최대 깊이 : 3\n",
    "- 학습률 : 0.1\n",
    "- 반복 횟수 : 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "BZIEP5CS8jSs"
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "          'objective':'binary:logistic',\n",
    "          'eval_metric':'logloss',\n",
    "            'max_depth':3,\n",
    "            'eta': 0.05\n",
    "         }\n",
    "num_rounds = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "UInEOEh98t6z"
   },
   "outputs": [],
   "source": [
    "eval_list = [(dtrain,'train'),(dtest,'eval')] # 데이터 셋 이름"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mzl7NufX8utk"
   },
   "source": [
    "## **2-d. 하이퍼 파라미터를 `train( )` 함수의 파라미터로 전달해 주세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "5vgia5qw8vCa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.65032\teval-logloss:0.65271\n",
      "[1]\ttrain-logloss:0.61155\teval-logloss:0.61483\n",
      "[2]\ttrain-logloss:0.57688\teval-logloss:0.58222\n",
      "[3]\ttrain-logloss:0.54436\teval-logloss:0.55196\n",
      "[4]\ttrain-logloss:0.51449\teval-logloss:0.52274\n",
      "[5]\ttrain-logloss:0.48753\teval-logloss:0.49829\n",
      "[6]\ttrain-logloss:0.46126\teval-logloss:0.47294\n",
      "[7]\ttrain-logloss:0.43709\teval-logloss:0.45091\n",
      "[8]\ttrain-logloss:0.41450\teval-logloss:0.42922\n",
      "[9]\ttrain-logloss:0.39406\teval-logloss:0.41097\n",
      "[10]\ttrain-logloss:0.37459\teval-logloss:0.39286\n",
      "[11]\ttrain-logloss:0.35632\teval-logloss:0.37536\n",
      "[12]\ttrain-logloss:0.33936\teval-logloss:0.35949\n",
      "[13]\ttrain-logloss:0.32339\teval-logloss:0.34431\n",
      "[14]\ttrain-logloss:0.30855\teval-logloss:0.33139\n",
      "[15]\ttrain-logloss:0.29453\teval-logloss:0.31815\n",
      "[16]\ttrain-logloss:0.28170\teval-logloss:0.30790\n",
      "[17]\ttrain-logloss:0.26949\teval-logloss:0.29742\n",
      "[18]\ttrain-logloss:0.25783\teval-logloss:0.28651\n",
      "[19]\ttrain-logloss:0.24690\teval-logloss:0.27632\n",
      "[20]\ttrain-logloss:0.23662\teval-logloss:0.26705\n",
      "[21]\ttrain-logloss:0.22715\teval-logloss:0.25964\n",
      "[22]\ttrain-logloss:0.21800\teval-logloss:0.25188\n",
      "[23]\ttrain-logloss:0.20935\teval-logloss:0.24395\n",
      "[24]\ttrain-logloss:0.20119\teval-logloss:0.23549\n",
      "[25]\ttrain-logloss:0.19359\teval-logloss:0.23001\n",
      "[26]\ttrain-logloss:0.18625\teval-logloss:0.22294\n",
      "[27]\ttrain-logloss:0.17932\teval-logloss:0.21563\n",
      "[28]\ttrain-logloss:0.17287\teval-logloss:0.21097\n",
      "[29]\ttrain-logloss:0.16659\teval-logloss:0.20533\n",
      "[30]\ttrain-logloss:0.16068\teval-logloss:0.19897\n",
      "[31]\ttrain-logloss:0.15507\teval-logloss:0.19515\n",
      "[32]\ttrain-logloss:0.14932\teval-logloss:0.18825\n",
      "[33]\ttrain-logloss:0.14436\teval-logloss:0.18499\n",
      "[34]\ttrain-logloss:0.13912\teval-logloss:0.18165\n",
      "[35]\ttrain-logloss:0.13417\teval-logloss:0.17554\n",
      "[36]\ttrain-logloss:0.12945\teval-logloss:0.17181\n",
      "[37]\ttrain-logloss:0.12532\teval-logloss:0.16723\n",
      "[38]\ttrain-logloss:0.12147\teval-logloss:0.16486\n",
      "[39]\ttrain-logloss:0.11741\teval-logloss:0.15966\n",
      "[40]\ttrain-logloss:0.11355\teval-logloss:0.15771\n",
      "[41]\ttrain-logloss:0.10982\teval-logloss:0.15382\n",
      "[42]\ttrain-logloss:0.10629\teval-logloss:0.15188\n",
      "[43]\ttrain-logloss:0.10293\teval-logloss:0.14836\n",
      "[44]\ttrain-logloss:0.09992\teval-logloss:0.14699\n",
      "[45]\ttrain-logloss:0.09693\teval-logloss:0.14328\n",
      "[46]\ttrain-logloss:0.09422\teval-logloss:0.14212\n",
      "[47]\ttrain-logloss:0.09141\teval-logloss:0.14023\n",
      "[48]\ttrain-logloss:0.08881\teval-logloss:0.13766\n",
      "[49]\ttrain-logloss:0.08646\teval-logloss:0.13682\n",
      "[50]\ttrain-logloss:0.08410\teval-logloss:0.13448\n",
      "[51]\ttrain-logloss:0.08180\teval-logloss:0.13198\n",
      "[52]\ttrain-logloss:0.07959\teval-logloss:0.13080\n",
      "[53]\ttrain-logloss:0.07762\teval-logloss:0.13023\n",
      "[54]\ttrain-logloss:0.07561\teval-logloss:0.12819\n",
      "[55]\ttrain-logloss:0.07369\teval-logloss:0.12707\n",
      "[56]\ttrain-logloss:0.07164\teval-logloss:0.12539\n",
      "[57]\ttrain-logloss:0.06960\teval-logloss:0.12497\n",
      "[58]\ttrain-logloss:0.06792\teval-logloss:0.12303\n",
      "[59]\ttrain-logloss:0.06640\teval-logloss:0.12287\n",
      "[60]\ttrain-logloss:0.06465\teval-logloss:0.12147\n",
      "[61]\ttrain-logloss:0.06309\teval-logloss:0.12091\n",
      "[62]\ttrain-logloss:0.06149\teval-logloss:0.11965\n",
      "[63]\ttrain-logloss:0.06008\teval-logloss:0.11921\n",
      "[64]\ttrain-logloss:0.05875\teval-logloss:0.11764\n",
      "[65]\ttrain-logloss:0.05749\teval-logloss:0.11616\n",
      "[66]\ttrain-logloss:0.05617\teval-logloss:0.11659\n",
      "[67]\ttrain-logloss:0.05486\teval-logloss:0.11559\n",
      "[68]\ttrain-logloss:0.05370\teval-logloss:0.11537\n",
      "[69]\ttrain-logloss:0.05250\teval-logloss:0.11447\n",
      "[70]\ttrain-logloss:0.05145\teval-logloss:0.11434\n",
      "[71]\ttrain-logloss:0.05015\teval-logloss:0.11409\n",
      "[72]\ttrain-logloss:0.04908\teval-logloss:0.11331\n",
      "[73]\ttrain-logloss:0.04791\teval-logloss:0.11377\n",
      "[74]\ttrain-logloss:0.04691\teval-logloss:0.11327\n",
      "[75]\ttrain-logloss:0.04604\teval-logloss:0.11312\n",
      "[76]\ttrain-logloss:0.04512\teval-logloss:0.11268\n",
      "[77]\ttrain-logloss:0.04404\teval-logloss:0.11262\n",
      "[78]\ttrain-logloss:0.04327\teval-logloss:0.11173\n",
      "[79]\ttrain-logloss:0.04246\teval-logloss:0.11243\n",
      "[80]\ttrain-logloss:0.04165\teval-logloss:0.11188\n",
      "[81]\ttrain-logloss:0.04077\teval-logloss:0.11241\n",
      "[82]\ttrain-logloss:0.04011\teval-logloss:0.11158\n",
      "[83]\ttrain-logloss:0.03938\teval-logloss:0.11112\n",
      "[84]\ttrain-logloss:0.03851\teval-logloss:0.11117\n",
      "[85]\ttrain-logloss:0.03792\teval-logloss:0.11043\n",
      "[86]\ttrain-logloss:0.03719\teval-logloss:0.11103\n",
      "[87]\ttrain-logloss:0.03654\teval-logloss:0.11050\n",
      "[88]\ttrain-logloss:0.03578\teval-logloss:0.11070\n",
      "[89]\ttrain-logloss:0.03517\teval-logloss:0.11056\n",
      "[90]\ttrain-logloss:0.03447\teval-logloss:0.11011\n",
      "[91]\ttrain-logloss:0.03399\teval-logloss:0.10949\n",
      "[92]\ttrain-logloss:0.03335\teval-logloss:0.10950\n",
      "[93]\ttrain-logloss:0.03273\teval-logloss:0.10965\n",
      "[94]\ttrain-logloss:0.03222\teval-logloss:0.10954\n",
      "[95]\ttrain-logloss:0.03171\teval-logloss:0.10945\n",
      "[96]\ttrain-logloss:0.03115\teval-logloss:0.10963\n",
      "[97]\ttrain-logloss:0.03068\teval-logloss:0.10899\n",
      "[98]\ttrain-logloss:0.03017\teval-logloss:0.10901\n",
      "[99]\ttrain-logloss:0.02977\teval-logloss:0.10849\n",
      "[100]\ttrain-logloss:0.02926\teval-logloss:0.10738\n",
      "[101]\ttrain-logloss:0.02878\teval-logloss:0.10745\n",
      "[102]\ttrain-logloss:0.02829\teval-logloss:0.10742\n",
      "[103]\ttrain-logloss:0.02788\teval-logloss:0.10797\n",
      "[104]\ttrain-logloss:0.02749\teval-logloss:0.10767\n",
      "[105]\ttrain-logloss:0.02704\teval-logloss:0.10766\n",
      "[106]\ttrain-logloss:0.02671\teval-logloss:0.10729\n",
      "[107]\ttrain-logloss:0.02630\teval-logloss:0.10753\n",
      "[108]\ttrain-logloss:0.02596\teval-logloss:0.10727\n",
      "[109]\ttrain-logloss:0.02554\teval-logloss:0.10716\n",
      "[110]\ttrain-logloss:0.02515\teval-logloss:0.10738\n",
      "[111]\ttrain-logloss:0.02482\teval-logloss:0.10738\n",
      "[112]\ttrain-logloss:0.02445\teval-logloss:0.10618\n",
      "[113]\ttrain-logloss:0.02412\teval-logloss:0.10602\n",
      "[114]\ttrain-logloss:0.02380\teval-logloss:0.10578\n",
      "[115]\ttrain-logloss:0.02354\teval-logloss:0.10606\n",
      "[116]\ttrain-logloss:0.02328\teval-logloss:0.10564\n",
      "[117]\ttrain-logloss:0.02294\teval-logloss:0.10558\n",
      "[118]\ttrain-logloss:0.02268\teval-logloss:0.10528\n",
      "[119]\ttrain-logloss:0.02241\teval-logloss:0.10567\n",
      "[120]\ttrain-logloss:0.02209\teval-logloss:0.10562\n",
      "[121]\ttrain-logloss:0.02180\teval-logloss:0.10551\n",
      "[122]\ttrain-logloss:0.02154\teval-logloss:0.10577\n",
      "[123]\ttrain-logloss:0.02130\teval-logloss:0.10494\n",
      "[124]\ttrain-logloss:0.02103\teval-logloss:0.10481\n",
      "[125]\ttrain-logloss:0.02076\teval-logloss:0.10406\n",
      "[126]\ttrain-logloss:0.02050\teval-logloss:0.10364\n",
      "[127]\ttrain-logloss:0.02023\teval-logloss:0.10367\n",
      "[128]\ttrain-logloss:0.02000\teval-logloss:0.10378\n",
      "[129]\ttrain-logloss:0.01980\teval-logloss:0.10307\n",
      "[130]\ttrain-logloss:0.01955\teval-logloss:0.10311\n",
      "[131]\ttrain-logloss:0.01936\teval-logloss:0.10301\n",
      "[132]\ttrain-logloss:0.01918\teval-logloss:0.10330\n",
      "[133]\ttrain-logloss:0.01896\teval-logloss:0.10364\n",
      "[134]\ttrain-logloss:0.01877\teval-logloss:0.10296\n",
      "[135]\ttrain-logloss:0.01854\teval-logloss:0.10302\n",
      "[136]\ttrain-logloss:0.01837\teval-logloss:0.10331\n",
      "[137]\ttrain-logloss:0.01820\teval-logloss:0.10322\n",
      "[138]\ttrain-logloss:0.01804\teval-logloss:0.10267\n",
      "[139]\ttrain-logloss:0.01779\teval-logloss:0.10304\n",
      "[140]\ttrain-logloss:0.01764\teval-logloss:0.10333\n",
      "[141]\ttrain-logloss:0.01741\teval-logloss:0.10363\n",
      "[142]\ttrain-logloss:0.01725\teval-logloss:0.10342\n",
      "[143]\ttrain-logloss:0.01711\teval-logloss:0.10303\n",
      "[144]\ttrain-logloss:0.01696\teval-logloss:0.10241\n",
      "[145]\ttrain-logloss:0.01677\teval-logloss:0.10228\n",
      "[146]\ttrain-logloss:0.01663\teval-logloss:0.10208\n",
      "[147]\ttrain-logloss:0.01649\teval-logloss:0.10237\n",
      "[148]\ttrain-logloss:0.01632\teval-logloss:0.10247\n",
      "[149]\ttrain-logloss:0.01613\teval-logloss:0.10254\n",
      "[150]\ttrain-logloss:0.01600\teval-logloss:0.10282\n",
      "[151]\ttrain-logloss:0.01585\teval-logloss:0.10269\n",
      "[152]\ttrain-logloss:0.01567\teval-logloss:0.10276\n",
      "[153]\ttrain-logloss:0.01556\teval-logloss:0.10237\n",
      "[154]\ttrain-logloss:0.01543\teval-logloss:0.10206\n",
      "[155]\ttrain-logloss:0.01529\teval-logloss:0.10185\n",
      "[156]\ttrain-logloss:0.01518\teval-logloss:0.10140\n",
      "[157]\ttrain-logloss:0.01504\teval-logloss:0.10181\n",
      "[158]\ttrain-logloss:0.01488\teval-logloss:0.10215\n",
      "[159]\ttrain-logloss:0.01478\teval-logloss:0.10216\n",
      "[160]\ttrain-logloss:0.01461\teval-logloss:0.10267\n",
      "[161]\ttrain-logloss:0.01453\teval-logloss:0.10272\n",
      "[162]\ttrain-logloss:0.01445\teval-logloss:0.10251\n",
      "[163]\ttrain-logloss:0.01430\teval-logloss:0.10285\n",
      "[164]\ttrain-logloss:0.01421\teval-logloss:0.10259\n",
      "[165]\ttrain-logloss:0.01408\teval-logloss:0.10213\n",
      "[166]\ttrain-logloss:0.01397\teval-logloss:0.10239\n",
      "[167]\ttrain-logloss:0.01383\teval-logloss:0.10273\n",
      "[168]\ttrain-logloss:0.01375\teval-logloss:0.10248\n",
      "[169]\ttrain-logloss:0.01366\teval-logloss:0.10249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[170]\ttrain-logloss:0.01351\teval-logloss:0.10317\n",
      "[171]\ttrain-logloss:0.01344\teval-logloss:0.10285\n",
      "[172]\ttrain-logloss:0.01331\teval-logloss:0.10260\n",
      "[173]\ttrain-logloss:0.01318\teval-logloss:0.10327\n",
      "[174]\ttrain-logloss:0.01310\teval-logloss:0.10346\n",
      "[175]\ttrain-logloss:0.01304\teval-logloss:0.10308\n",
      "[176]\ttrain-logloss:0.01295\teval-logloss:0.10340\n",
      "[177]\ttrain-logloss:0.01288\teval-logloss:0.10308\n",
      "[178]\ttrain-logloss:0.01280\teval-logloss:0.10310\n",
      "[179]\ttrain-logloss:0.01269\teval-logloss:0.10364\n",
      "[180]\ttrain-logloss:0.01263\teval-logloss:0.10383\n",
      "[181]\ttrain-logloss:0.01257\teval-logloss:0.10346\n",
      "[182]\ttrain-logloss:0.01251\teval-logloss:0.10315\n",
      "[183]\ttrain-logloss:0.01242\teval-logloss:0.10330\n",
      "[184]\ttrain-logloss:0.01234\teval-logloss:0.10333\n",
      "[185]\ttrain-logloss:0.01225\teval-logloss:0.10311\n",
      "[186]\ttrain-logloss:0.01217\teval-logloss:0.10320\n",
      "[187]\ttrain-logloss:0.01211\teval-logloss:0.10332\n",
      "[188]\ttrain-logloss:0.01206\teval-logloss:0.10307\n",
      "[189]\ttrain-logloss:0.01200\teval-logloss:0.10277\n",
      "[190]\ttrain-logloss:0.01190\teval-logloss:0.10258\n",
      "[191]\ttrain-logloss:0.01182\teval-logloss:0.10261\n",
      "[192]\ttrain-logloss:0.01174\teval-logloss:0.10271\n",
      "[193]\ttrain-logloss:0.01167\teval-logloss:0.10289\n",
      "[194]\ttrain-logloss:0.01161\teval-logloss:0.10261\n",
      "[195]\ttrain-logloss:0.01154\teval-logloss:0.10264\n",
      "[196]\ttrain-logloss:0.01147\teval-logloss:0.10273\n",
      "[197]\ttrain-logloss:0.01141\teval-logloss:0.10286\n",
      "[198]\ttrain-logloss:0.01136\teval-logloss:0.10251\n",
      "[199]\ttrain-logloss:0.01132\teval-logloss:0.10227\n",
      "[200]\ttrain-logloss:0.01125\teval-logloss:0.10245\n",
      "[201]\ttrain-logloss:0.01119\teval-logloss:0.10257\n",
      "[202]\ttrain-logloss:0.01115\teval-logloss:0.10246\n",
      "[203]\ttrain-logloss:0.01108\teval-logloss:0.10249\n",
      "[204]\ttrain-logloss:0.01101\teval-logloss:0.10259\n",
      "[205]\ttrain-logloss:0.01097\teval-logloss:0.10235\n",
      "[206]\ttrain-logloss:0.01092\teval-logloss:0.10248\n"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.train(params = params , dtrain=dtrain , num_boost_round=num_rounds , \\\n",
    "                      early_stopping_rounds=50, evals=eval_list )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "5UFWSwQp8yA8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict( ) 수행 결과값을 10개만 표시, 예측 확률 값으로 표시됨\n",
      "[0.988 0.001 0.001 0.998 0.999 0.001 0.001 0.088 0.2   0.998]\n",
      "예측값 10개만 표시: [1, 0, 0, 1, 1, 0, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "pred_probs = xgb_model.predict(dtest)\n",
    "print('predict( ) 수행 결과값을 10개만 표시, 예측 확률 값으로 표시됨')\n",
    "print(np.round(pred_probs[:10],3))\n",
    "\n",
    "# 예측 확률이 0.5 보다 크면 1 , 그렇지 않으면 0 으로 예측값 결정하여 List 객체인 preds에 저장\n",
    "preds = [ 1 if x > 0.5 else 0 for x in pred_probs ]\n",
    "print('예측값 10개만 표시:',preds[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mxk9DN5383sp"
   },
   "source": [
    "##**2-e. `get_eval_clf()` 을 통해 예측 평가를 진행해주세요**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "xS27kc1780cD"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "def get_clf_eval(y_test, pred=None, pred_proba=None):\n",
    "    confusion = confusion_matrix( y_test, pred)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    precision = precision_score(y_test , pred)\n",
    "    recall = recall_score(y_test , pred)\n",
    "    f1 = f1_score(y_test,pred)\n",
    "    # ROC-AUC 추가\n",
    "    roc_auc = roc_auc_score(y_test, pred_proba)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    # ROC-AUC print 추가\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\\\n",
    "    F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "v-foPK_M82hT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[40  3]\n",
      " [ 1 70]]\n",
      "정확도: 0.9649, 정밀도: 0.9589, 재현율: 0.9859,    F1: 0.9722, AUC:0.9938\n"
     ]
    }
   ],
   "source": [
    "get_clf_eval(y_test, preds, pred_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uvg4b6ap9lXg"
   },
   "source": [
    "# **3. LightGBM, HyperOpt**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f8SBYxBJ-vhb"
   },
   "source": [
    "## **3-1. LightGBM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SnRlTMVaIdU6"
   },
   "source": [
    "### **3-1-a. ```water_potability.csv```를 불러와 df에 저장해 주세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "3cg-dfFE-nOx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3.2\n"
     ]
    }
   ],
   "source": [
    "# 3.3.2 버전으로 LightGBM을 설치합니다(일부 파라미터가 4.0.0에선 작동하지 않아서 넣었습니다.)\n",
    "\n",
    "#!pip install lightgbm==3.3.2\n",
    "print(lightgbm.__version__) # 버전 확인용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "ZcpuDJ8GIoBD"
   },
   "outputs": [],
   "source": [
    "import lightgbm\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "z3XVGeXr-_kt"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ph</th>\n",
       "      <th>Hardness</th>\n",
       "      <th>Solids</th>\n",
       "      <th>Chloramines</th>\n",
       "      <th>Sulfate</th>\n",
       "      <th>Conductivity</th>\n",
       "      <th>Organic_carbon</th>\n",
       "      <th>Trihalomethanes</th>\n",
       "      <th>Turbidity</th>\n",
       "      <th>Potability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>204.890455</td>\n",
       "      <td>20791.318981</td>\n",
       "      <td>7.300212</td>\n",
       "      <td>368.516441</td>\n",
       "      <td>564.308654</td>\n",
       "      <td>10.379783</td>\n",
       "      <td>86.990970</td>\n",
       "      <td>2.963135</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.716080</td>\n",
       "      <td>129.422921</td>\n",
       "      <td>18630.057858</td>\n",
       "      <td>6.635246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>592.885359</td>\n",
       "      <td>15.180013</td>\n",
       "      <td>56.329076</td>\n",
       "      <td>4.500656</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.099124</td>\n",
       "      <td>224.236259</td>\n",
       "      <td>19909.541732</td>\n",
       "      <td>9.275884</td>\n",
       "      <td>NaN</td>\n",
       "      <td>418.606213</td>\n",
       "      <td>16.868637</td>\n",
       "      <td>66.420093</td>\n",
       "      <td>3.055934</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.316766</td>\n",
       "      <td>214.373394</td>\n",
       "      <td>22018.417441</td>\n",
       "      <td>8.059332</td>\n",
       "      <td>356.886136</td>\n",
       "      <td>363.266516</td>\n",
       "      <td>18.436524</td>\n",
       "      <td>100.341674</td>\n",
       "      <td>4.628771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.092223</td>\n",
       "      <td>181.101509</td>\n",
       "      <td>17978.986339</td>\n",
       "      <td>6.546600</td>\n",
       "      <td>310.135738</td>\n",
       "      <td>398.410813</td>\n",
       "      <td>11.558279</td>\n",
       "      <td>31.997993</td>\n",
       "      <td>4.075075</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ph    Hardness        Solids  Chloramines     Sulfate  Conductivity  \\\n",
       "0       NaN  204.890455  20791.318981     7.300212  368.516441    564.308654   \n",
       "1  3.716080  129.422921  18630.057858     6.635246         NaN    592.885359   \n",
       "2  8.099124  224.236259  19909.541732     9.275884         NaN    418.606213   \n",
       "3  8.316766  214.373394  22018.417441     8.059332  356.886136    363.266516   \n",
       "4  9.092223  181.101509  17978.986339     6.546600  310.135738    398.410813   \n",
       "\n",
       "   Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
       "0       10.379783        86.990970   2.963135           0  \n",
       "1       15.180013        56.329076   4.500656           0  \n",
       "2       16.868637        66.420093   3.055934           0  \n",
       "3       18.436524       100.341674   4.628771           0  \n",
       "4       11.558279        31.997993   4.075075           0  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\jain5\\Desktop\\Euron\\Data_Handling\\water_potability.csv\")\n",
    "\n",
    "# 데이터 확인\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cXSVbYeI_DGz"
   },
   "source": [
    "### **3-1-b. 이럴수가! 결측값이 있는 것 같네요! 아래의 코드를 실행시켜 어느 변수에 결측값이 있는지 확인하고, 결측값들은 모두 해당하는 변수의 평균으로 바꿔주세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "r4nKg2mF_FHE"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ph                 491\n",
       "Hardness             0\n",
       "Solids               0\n",
       "Chloramines          0\n",
       "Sulfate            781\n",
       "Conductivity         0\n",
       "Organic_carbon       0\n",
       "Trihalomethanes    162\n",
       "Turbidity            0\n",
       "Potability           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()\n",
    "# ph, Sulface, Tri... 결측값!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "I3Iq_aHA_XUi"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ph</th>\n",
       "      <th>Hardness</th>\n",
       "      <th>Solids</th>\n",
       "      <th>Chloramines</th>\n",
       "      <th>Sulfate</th>\n",
       "      <th>Conductivity</th>\n",
       "      <th>Organic_carbon</th>\n",
       "      <th>Trihalomethanes</th>\n",
       "      <th>Turbidity</th>\n",
       "      <th>Potability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.080795</td>\n",
       "      <td>204.890455</td>\n",
       "      <td>20791.318981</td>\n",
       "      <td>7.300212</td>\n",
       "      <td>368.516441</td>\n",
       "      <td>564.308654</td>\n",
       "      <td>10.379783</td>\n",
       "      <td>86.990970</td>\n",
       "      <td>2.963135</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.716080</td>\n",
       "      <td>129.422921</td>\n",
       "      <td>18630.057858</td>\n",
       "      <td>6.635246</td>\n",
       "      <td>333.775777</td>\n",
       "      <td>592.885359</td>\n",
       "      <td>15.180013</td>\n",
       "      <td>56.329076</td>\n",
       "      <td>4.500656</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.099124</td>\n",
       "      <td>224.236259</td>\n",
       "      <td>19909.541732</td>\n",
       "      <td>9.275884</td>\n",
       "      <td>333.775777</td>\n",
       "      <td>418.606213</td>\n",
       "      <td>16.868637</td>\n",
       "      <td>66.420093</td>\n",
       "      <td>3.055934</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.316766</td>\n",
       "      <td>214.373394</td>\n",
       "      <td>22018.417441</td>\n",
       "      <td>8.059332</td>\n",
       "      <td>356.886136</td>\n",
       "      <td>363.266516</td>\n",
       "      <td>18.436524</td>\n",
       "      <td>100.341674</td>\n",
       "      <td>4.628771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.092223</td>\n",
       "      <td>181.101509</td>\n",
       "      <td>17978.986339</td>\n",
       "      <td>6.546600</td>\n",
       "      <td>310.135738</td>\n",
       "      <td>398.410813</td>\n",
       "      <td>11.558279</td>\n",
       "      <td>31.997993</td>\n",
       "      <td>4.075075</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ph    Hardness        Solids  Chloramines     Sulfate  Conductivity  \\\n",
       "0  7.080795  204.890455  20791.318981     7.300212  368.516441    564.308654   \n",
       "1  3.716080  129.422921  18630.057858     6.635246  333.775777    592.885359   \n",
       "2  8.099124  224.236259  19909.541732     9.275884  333.775777    418.606213   \n",
       "3  8.316766  214.373394  22018.417441     8.059332  356.886136    363.266516   \n",
       "4  9.092223  181.101509  17978.986339     6.546600  310.135738    398.410813   \n",
       "\n",
       "   Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
       "0       10.379783        86.990970   2.963135           0  \n",
       "1       15.180013        56.329076   4.500656           0  \n",
       "2       16.868637        66.420093   3.055934           0  \n",
       "3       18.436524       100.341674   4.628771           0  \n",
       "4       11.558279        31.997993   4.075075           0  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 결측값을 해당 칼럼의 평균값으로 대체해 주세요.\n",
    "# 힌트: 파머완 138페이지\n",
    "\n",
    "\n",
    "df['ph'].fillna(df['ph'].mean(), inplace=True)\n",
    "df['Sulfate'].fillna(df['Sulfate'].mean(), inplace=True)\n",
    "df['Trihalomethanes'].fillna(df['Trihalomethanes'].mean(), inplace=True)\n",
    "\n",
    "# 데이터 확인\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OyXaOw0X_aXZ"
   },
   "source": [
    "### **3-1-c. df를 학습용 데이터와 테스트용 데이터로 분리해 주세요.**  \n",
    "(random_state = 42, 학습용 데이터가 전체의 **80%**를 차지하도록 설정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "oWbfGB4c_Znx"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hW1x8hQI_krM"
   },
   "source": [
    "### **3-1-d. 위에서 만든 X_train, y_train을 다시 나누어 90%는 학습용으로, 10%는 검증용 데이터로 분리해 주세요.**  \n",
    "(random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "QPuPw7bb_qF8"
   },
   "outputs": [],
   "source": [
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hEyCPkHZ_tYC"
   },
   "source": [
    "### **3-1-e. 다음 조건에 따라 LGBMClassifier을 생성한 후 ```lgbm_wrapper```에 저장해 주세요.**\n",
    "- 반복 수행할 트리 개수: 800개\n",
    "- 학습률: 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "4gPkmQo3_zlS"
   },
   "outputs": [],
   "source": [
    "lgbm_wrapper = LGBMClassifier(n_estimators=800, learning_rate=0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "unGn5aOi_2LG"
   },
   "source": [
    "### **3-1-f. `lgbm_wrapper`가 100번 학습을 반복해도 성능이 향상되지 않으면 수행을 멈추도록 설정해서 학습시키세요.**\n",
    "- 평가 지표: logloss  \n",
    "\n",
    "(❓❓❓❓❓로 표시된 빈칸을 채워주세요!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "89l5qcaB_6QV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.667547\tvalid_1's binary_logloss: 0.664685\n",
      "[2]\ttraining's binary_logloss: 0.664047\tvalid_1's binary_logloss: 0.662495\n",
      "[3]\ttraining's binary_logloss: 0.660692\tvalid_1's binary_logloss: 0.660532\n",
      "[4]\ttraining's binary_logloss: 0.657277\tvalid_1's binary_logloss: 0.658939\n",
      "[5]\ttraining's binary_logloss: 0.65419\tvalid_1's binary_logloss: 0.657061\n",
      "[6]\ttraining's binary_logloss: 0.651193\tvalid_1's binary_logloss: 0.65562\n",
      "[7]\ttraining's binary_logloss: 0.648042\tvalid_1's binary_logloss: 0.65442\n",
      "[8]\ttraining's binary_logloss: 0.645251\tvalid_1's binary_logloss: 0.65276\n",
      "[9]\ttraining's binary_logloss: 0.642221\tvalid_1's binary_logloss: 0.651453\n",
      "[10]\ttraining's binary_logloss: 0.63971\tvalid_1's binary_logloss: 0.649738\n",
      "[11]\ttraining's binary_logloss: 0.637098\tvalid_1's binary_logloss: 0.648505\n",
      "[12]\ttraining's binary_logloss: 0.634355\tvalid_1's binary_logloss: 0.647447\n",
      "[13]\ttraining's binary_logloss: 0.631831\tvalid_1's binary_logloss: 0.6465\n",
      "[14]\ttraining's binary_logloss: 0.629512\tvalid_1's binary_logloss: 0.645076\n",
      "[15]\ttraining's binary_logloss: 0.627136\tvalid_1's binary_logloss: 0.644241\n",
      "[16]\ttraining's binary_logloss: 0.624549\tvalid_1's binary_logloss: 0.642928\n",
      "[17]\ttraining's binary_logloss: 0.622566\tvalid_1's binary_logloss: 0.641793\n",
      "[18]\ttraining's binary_logloss: 0.620011\tvalid_1's binary_logloss: 0.640239\n",
      "[19]\ttraining's binary_logloss: 0.617778\tvalid_1's binary_logloss: 0.639463\n",
      "[20]\ttraining's binary_logloss: 0.615404\tvalid_1's binary_logloss: 0.638609\n",
      "[21]\ttraining's binary_logloss: 0.613173\tvalid_1's binary_logloss: 0.637227\n",
      "[22]\ttraining's binary_logloss: 0.611319\tvalid_1's binary_logloss: 0.63608\n",
      "[23]\ttraining's binary_logloss: 0.609269\tvalid_1's binary_logloss: 0.635334\n",
      "[24]\ttraining's binary_logloss: 0.607131\tvalid_1's binary_logloss: 0.634674\n",
      "[25]\ttraining's binary_logloss: 0.604981\tvalid_1's binary_logloss: 0.633856\n",
      "[26]\ttraining's binary_logloss: 0.602973\tvalid_1's binary_logloss: 0.633035\n",
      "[27]\ttraining's binary_logloss: 0.600891\tvalid_1's binary_logloss: 0.632326\n",
      "[28]\ttraining's binary_logloss: 0.598837\tvalid_1's binary_logloss: 0.631523\n",
      "[29]\ttraining's binary_logloss: 0.597021\tvalid_1's binary_logloss: 0.630514\n",
      "[30]\ttraining's binary_logloss: 0.595074\tvalid_1's binary_logloss: 0.629968\n",
      "[31]\ttraining's binary_logloss: 0.593365\tvalid_1's binary_logloss: 0.629077\n",
      "[32]\ttraining's binary_logloss: 0.591409\tvalid_1's binary_logloss: 0.628504\n",
      "[33]\ttraining's binary_logloss: 0.589704\tvalid_1's binary_logloss: 0.627899\n",
      "[34]\ttraining's binary_logloss: 0.587997\tvalid_1's binary_logloss: 0.627062\n",
      "[35]\ttraining's binary_logloss: 0.586386\tvalid_1's binary_logloss: 0.626465\n",
      "[36]\ttraining's binary_logloss: 0.584785\tvalid_1's binary_logloss: 0.625355\n",
      "[37]\ttraining's binary_logloss: 0.582981\tvalid_1's binary_logloss: 0.624617\n",
      "[38]\ttraining's binary_logloss: 0.581404\tvalid_1's binary_logloss: 0.624309\n",
      "[39]\ttraining's binary_logloss: 0.579584\tvalid_1's binary_logloss: 0.623495\n",
      "[40]\ttraining's binary_logloss: 0.57818\tvalid_1's binary_logloss: 0.623059\n",
      "[41]\ttraining's binary_logloss: 0.576512\tvalid_1's binary_logloss: 0.622334\n",
      "[42]\ttraining's binary_logloss: 0.574888\tvalid_1's binary_logloss: 0.621196\n",
      "[43]\ttraining's binary_logloss: 0.573249\tvalid_1's binary_logloss: 0.619868\n",
      "[44]\ttraining's binary_logloss: 0.57189\tvalid_1's binary_logloss: 0.619827\n",
      "[45]\ttraining's binary_logloss: 0.570241\tvalid_1's binary_logloss: 0.619596\n",
      "[46]\ttraining's binary_logloss: 0.568716\tvalid_1's binary_logloss: 0.619083\n",
      "[47]\ttraining's binary_logloss: 0.5673\tvalid_1's binary_logloss: 0.619142\n",
      "[48]\ttraining's binary_logloss: 0.565919\tvalid_1's binary_logloss: 0.618903\n",
      "[49]\ttraining's binary_logloss: 0.564496\tvalid_1's binary_logloss: 0.618536\n",
      "[50]\ttraining's binary_logloss: 0.562884\tvalid_1's binary_logloss: 0.618233\n",
      "[51]\ttraining's binary_logloss: 0.561515\tvalid_1's binary_logloss: 0.618077\n",
      "[52]\ttraining's binary_logloss: 0.560285\tvalid_1's binary_logloss: 0.618009\n",
      "[53]\ttraining's binary_logloss: 0.558754\tvalid_1's binary_logloss: 0.617756\n",
      "[54]\ttraining's binary_logloss: 0.557339\tvalid_1's binary_logloss: 0.617285\n",
      "[55]\ttraining's binary_logloss: 0.556088\tvalid_1's binary_logloss: 0.61718\n",
      "[56]\ttraining's binary_logloss: 0.554629\tvalid_1's binary_logloss: 0.616633\n",
      "[57]\ttraining's binary_logloss: 0.553365\tvalid_1's binary_logloss: 0.616256\n",
      "[58]\ttraining's binary_logloss: 0.552168\tvalid_1's binary_logloss: 0.615741\n",
      "[59]\ttraining's binary_logloss: 0.550464\tvalid_1's binary_logloss: 0.61504\n",
      "[60]\ttraining's binary_logloss: 0.549265\tvalid_1's binary_logloss: 0.615171\n",
      "[61]\ttraining's binary_logloss: 0.548038\tvalid_1's binary_logloss: 0.614906\n",
      "[62]\ttraining's binary_logloss: 0.546864\tvalid_1's binary_logloss: 0.615046\n",
      "[63]\ttraining's binary_logloss: 0.545476\tvalid_1's binary_logloss: 0.615044\n",
      "[64]\ttraining's binary_logloss: 0.544288\tvalid_1's binary_logloss: 0.615147\n",
      "[65]\ttraining's binary_logloss: 0.542654\tvalid_1's binary_logloss: 0.614795\n",
      "[66]\ttraining's binary_logloss: 0.54164\tvalid_1's binary_logloss: 0.614296\n",
      "[67]\ttraining's binary_logloss: 0.540516\tvalid_1's binary_logloss: 0.614464\n",
      "[68]\ttraining's binary_logloss: 0.538924\tvalid_1's binary_logloss: 0.614556\n",
      "[69]\ttraining's binary_logloss: 0.537522\tvalid_1's binary_logloss: 0.614134\n",
      "[70]\ttraining's binary_logloss: 0.536069\tvalid_1's binary_logloss: 0.613612\n",
      "[71]\ttraining's binary_logloss: 0.534842\tvalid_1's binary_logloss: 0.613207\n",
      "[72]\ttraining's binary_logloss: 0.533493\tvalid_1's binary_logloss: 0.612727\n",
      "[73]\ttraining's binary_logloss: 0.532093\tvalid_1's binary_logloss: 0.61206\n",
      "[74]\ttraining's binary_logloss: 0.530997\tvalid_1's binary_logloss: 0.611842\n",
      "[75]\ttraining's binary_logloss: 0.529792\tvalid_1's binary_logloss: 0.611458\n",
      "[76]\ttraining's binary_logloss: 0.528547\tvalid_1's binary_logloss: 0.611183\n",
      "[77]\ttraining's binary_logloss: 0.52721\tvalid_1's binary_logloss: 0.610372\n",
      "[78]\ttraining's binary_logloss: 0.526187\tvalid_1's binary_logloss: 0.610703\n",
      "[79]\ttraining's binary_logloss: 0.524654\tvalid_1's binary_logloss: 0.610464\n",
      "[80]\ttraining's binary_logloss: 0.523712\tvalid_1's binary_logloss: 0.610687\n",
      "[81]\ttraining's binary_logloss: 0.522468\tvalid_1's binary_logloss: 0.610206\n",
      "[82]\ttraining's binary_logloss: 0.521323\tvalid_1's binary_logloss: 0.60944\n",
      "[83]\ttraining's binary_logloss: 0.520141\tvalid_1's binary_logloss: 0.609356\n",
      "[84]\ttraining's binary_logloss: 0.519102\tvalid_1's binary_logloss: 0.608809\n",
      "[85]\ttraining's binary_logloss: 0.517993\tvalid_1's binary_logloss: 0.608626\n",
      "[86]\ttraining's binary_logloss: 0.516937\tvalid_1's binary_logloss: 0.608656\n",
      "[87]\ttraining's binary_logloss: 0.515772\tvalid_1's binary_logloss: 0.608443\n",
      "[88]\ttraining's binary_logloss: 0.514632\tvalid_1's binary_logloss: 0.608518\n",
      "[89]\ttraining's binary_logloss: 0.513572\tvalid_1's binary_logloss: 0.608283\n",
      "[90]\ttraining's binary_logloss: 0.51251\tvalid_1's binary_logloss: 0.608352\n",
      "[91]\ttraining's binary_logloss: 0.511467\tvalid_1's binary_logloss: 0.608149\n",
      "[92]\ttraining's binary_logloss: 0.510382\tvalid_1's binary_logloss: 0.607771\n",
      "[93]\ttraining's binary_logloss: 0.508859\tvalid_1's binary_logloss: 0.607334\n",
      "[94]\ttraining's binary_logloss: 0.507781\tvalid_1's binary_logloss: 0.607239\n",
      "[95]\ttraining's binary_logloss: 0.506705\tvalid_1's binary_logloss: 0.606651\n",
      "[96]\ttraining's binary_logloss: 0.505648\tvalid_1's binary_logloss: 0.606788\n",
      "[97]\ttraining's binary_logloss: 0.504399\tvalid_1's binary_logloss: 0.607109\n",
      "[98]\ttraining's binary_logloss: 0.503404\tvalid_1's binary_logloss: 0.607263\n",
      "[99]\ttraining's binary_logloss: 0.501983\tvalid_1's binary_logloss: 0.607194\n",
      "[100]\ttraining's binary_logloss: 0.50099\tvalid_1's binary_logloss: 0.607282\n",
      "[101]\ttraining's binary_logloss: 0.499824\tvalid_1's binary_logloss: 0.607247\n",
      "[102]\ttraining's binary_logloss: 0.498856\tvalid_1's binary_logloss: 0.60742\n",
      "[103]\ttraining's binary_logloss: 0.497442\tvalid_1's binary_logloss: 0.607316\n",
      "[104]\ttraining's binary_logloss: 0.496373\tvalid_1's binary_logloss: 0.60732\n",
      "[105]\ttraining's binary_logloss: 0.495097\tvalid_1's binary_logloss: 0.607256\n",
      "[106]\ttraining's binary_logloss: 0.493956\tvalid_1's binary_logloss: 0.606972\n",
      "[107]\ttraining's binary_logloss: 0.492786\tvalid_1's binary_logloss: 0.607018\n",
      "[108]\ttraining's binary_logloss: 0.49182\tvalid_1's binary_logloss: 0.606827\n",
      "[109]\ttraining's binary_logloss: 0.490963\tvalid_1's binary_logloss: 0.606737\n",
      "[110]\ttraining's binary_logloss: 0.489966\tvalid_1's binary_logloss: 0.606608\n",
      "[111]\ttraining's binary_logloss: 0.489148\tvalid_1's binary_logloss: 0.606561\n",
      "[112]\ttraining's binary_logloss: 0.488277\tvalid_1's binary_logloss: 0.606796\n",
      "[113]\ttraining's binary_logloss: 0.487368\tvalid_1's binary_logloss: 0.606787\n",
      "[114]\ttraining's binary_logloss: 0.486279\tvalid_1's binary_logloss: 0.606649\n",
      "[115]\ttraining's binary_logloss: 0.485349\tvalid_1's binary_logloss: 0.606573\n",
      "[116]\ttraining's binary_logloss: 0.484404\tvalid_1's binary_logloss: 0.606804\n",
      "[117]\ttraining's binary_logloss: 0.483562\tvalid_1's binary_logloss: 0.606487\n",
      "[118]\ttraining's binary_logloss: 0.482428\tvalid_1's binary_logloss: 0.606461\n",
      "[119]\ttraining's binary_logloss: 0.481512\tvalid_1's binary_logloss: 0.606384\n",
      "[120]\ttraining's binary_logloss: 0.480715\tvalid_1's binary_logloss: 0.60617\n",
      "[121]\ttraining's binary_logloss: 0.479965\tvalid_1's binary_logloss: 0.606376\n",
      "[122]\ttraining's binary_logloss: 0.479068\tvalid_1's binary_logloss: 0.606733\n",
      "[123]\ttraining's binary_logloss: 0.477955\tvalid_1's binary_logloss: 0.606621\n",
      "[124]\ttraining's binary_logloss: 0.476929\tvalid_1's binary_logloss: 0.605802\n",
      "[125]\ttraining's binary_logloss: 0.475845\tvalid_1's binary_logloss: 0.605189\n",
      "[126]\ttraining's binary_logloss: 0.474794\tvalid_1's binary_logloss: 0.60524\n",
      "[127]\ttraining's binary_logloss: 0.473823\tvalid_1's binary_logloss: 0.604651\n",
      "[128]\ttraining's binary_logloss: 0.473117\tvalid_1's binary_logloss: 0.604408\n",
      "[129]\ttraining's binary_logloss: 0.472245\tvalid_1's binary_logloss: 0.60428\n",
      "[130]\ttraining's binary_logloss: 0.471411\tvalid_1's binary_logloss: 0.604563\n",
      "[131]\ttraining's binary_logloss: 0.470444\tvalid_1's binary_logloss: 0.604498\n",
      "[132]\ttraining's binary_logloss: 0.4696\tvalid_1's binary_logloss: 0.60433\n",
      "[133]\ttraining's binary_logloss: 0.468737\tvalid_1's binary_logloss: 0.604457\n",
      "[134]\ttraining's binary_logloss: 0.467882\tvalid_1's binary_logloss: 0.604643\n",
      "[135]\ttraining's binary_logloss: 0.467074\tvalid_1's binary_logloss: 0.60459\n",
      "[136]\ttraining's binary_logloss: 0.465983\tvalid_1's binary_logloss: 0.6041\n",
      "[137]\ttraining's binary_logloss: 0.465135\tvalid_1's binary_logloss: 0.603884\n",
      "[138]\ttraining's binary_logloss: 0.464335\tvalid_1's binary_logloss: 0.603975\n",
      "[139]\ttraining's binary_logloss: 0.463289\tvalid_1's binary_logloss: 0.603518\n",
      "[140]\ttraining's binary_logloss: 0.462394\tvalid_1's binary_logloss: 0.603927\n",
      "[141]\ttraining's binary_logloss: 0.461579\tvalid_1's binary_logloss: 0.603516\n",
      "[142]\ttraining's binary_logloss: 0.460654\tvalid_1's binary_logloss: 0.603582\n",
      "[143]\ttraining's binary_logloss: 0.45975\tvalid_1's binary_logloss: 0.603672\n",
      "[144]\ttraining's binary_logloss: 0.458865\tvalid_1's binary_logloss: 0.603851\n",
      "[145]\ttraining's binary_logloss: 0.457908\tvalid_1's binary_logloss: 0.603774\n",
      "[146]\ttraining's binary_logloss: 0.45706\tvalid_1's binary_logloss: 0.603484\n",
      "[147]\ttraining's binary_logloss: 0.456221\tvalid_1's binary_logloss: 0.60365\n",
      "[148]\ttraining's binary_logloss: 0.455435\tvalid_1's binary_logloss: 0.603882\n",
      "[149]\ttraining's binary_logloss: 0.454648\tvalid_1's binary_logloss: 0.60381\n",
      "[150]\ttraining's binary_logloss: 0.453867\tvalid_1's binary_logloss: 0.603974\n",
      "[151]\ttraining's binary_logloss: 0.45304\tvalid_1's binary_logloss: 0.603606\n",
      "[152]\ttraining's binary_logloss: 0.452142\tvalid_1's binary_logloss: 0.603745\n",
      "[153]\ttraining's binary_logloss: 0.451329\tvalid_1's binary_logloss: 0.603914\n",
      "[154]\ttraining's binary_logloss: 0.450524\tvalid_1's binary_logloss: 0.603933\n",
      "[155]\ttraining's binary_logloss: 0.449743\tvalid_1's binary_logloss: 0.604349\n",
      "[156]\ttraining's binary_logloss: 0.448834\tvalid_1's binary_logloss: 0.604694\n",
      "[157]\ttraining's binary_logloss: 0.448032\tvalid_1's binary_logloss: 0.60476\n",
      "[158]\ttraining's binary_logloss: 0.447105\tvalid_1's binary_logloss: 0.604317\n",
      "[159]\ttraining's binary_logloss: 0.446176\tvalid_1's binary_logloss: 0.604407\n",
      "[160]\ttraining's binary_logloss: 0.445418\tvalid_1's binary_logloss: 0.604685\n",
      "[161]\ttraining's binary_logloss: 0.444712\tvalid_1's binary_logloss: 0.604758\n",
      "[162]\ttraining's binary_logloss: 0.443915\tvalid_1's binary_logloss: 0.604907\n",
      "[163]\ttraining's binary_logloss: 0.443093\tvalid_1's binary_logloss: 0.605203\n",
      "[164]\ttraining's binary_logloss: 0.442318\tvalid_1's binary_logloss: 0.605045\n",
      "[165]\ttraining's binary_logloss: 0.441326\tvalid_1's binary_logloss: 0.605121\n",
      "[166]\ttraining's binary_logloss: 0.440627\tvalid_1's binary_logloss: 0.604886\n",
      "[167]\ttraining's binary_logloss: 0.43984\tvalid_1's binary_logloss: 0.604574\n",
      "[168]\ttraining's binary_logloss: 0.439218\tvalid_1's binary_logloss: 0.604623\n",
      "[169]\ttraining's binary_logloss: 0.43844\tvalid_1's binary_logloss: 0.604389\n",
      "[170]\ttraining's binary_logloss: 0.437732\tvalid_1's binary_logloss: 0.604601\n",
      "[171]\ttraining's binary_logloss: 0.436889\tvalid_1's binary_logloss: 0.604902\n",
      "[172]\ttraining's binary_logloss: 0.436101\tvalid_1's binary_logloss: 0.605497\n",
      "[173]\ttraining's binary_logloss: 0.435415\tvalid_1's binary_logloss: 0.605354\n",
      "[174]\ttraining's binary_logloss: 0.434636\tvalid_1's binary_logloss: 0.605431\n",
      "[175]\ttraining's binary_logloss: 0.433818\tvalid_1's binary_logloss: 0.605277\n",
      "[176]\ttraining's binary_logloss: 0.433069\tvalid_1's binary_logloss: 0.605222\n",
      "[177]\ttraining's binary_logloss: 0.432374\tvalid_1's binary_logloss: 0.605233\n",
      "[178]\ttraining's binary_logloss: 0.43162\tvalid_1's binary_logloss: 0.605042\n",
      "[179]\ttraining's binary_logloss: 0.43085\tvalid_1's binary_logloss: 0.605577\n",
      "[180]\ttraining's binary_logloss: 0.430095\tvalid_1's binary_logloss: 0.605771\n",
      "[181]\ttraining's binary_logloss: 0.429368\tvalid_1's binary_logloss: 0.606193\n",
      "[182]\ttraining's binary_logloss: 0.42862\tvalid_1's binary_logloss: 0.606251\n",
      "[183]\ttraining's binary_logloss: 0.427908\tvalid_1's binary_logloss: 0.606214\n",
      "[184]\ttraining's binary_logloss: 0.427279\tvalid_1's binary_logloss: 0.606474\n",
      "[185]\ttraining's binary_logloss: 0.42653\tvalid_1's binary_logloss: 0.6069\n",
      "[186]\ttraining's binary_logloss: 0.425813\tvalid_1's binary_logloss: 0.607007\n",
      "[187]\ttraining's binary_logloss: 0.425155\tvalid_1's binary_logloss: 0.607044\n",
      "[188]\ttraining's binary_logloss: 0.42445\tvalid_1's binary_logloss: 0.60725\n",
      "[189]\ttraining's binary_logloss: 0.423672\tvalid_1's binary_logloss: 0.607054\n",
      "[190]\ttraining's binary_logloss: 0.422997\tvalid_1's binary_logloss: 0.607556\n",
      "[191]\ttraining's binary_logloss: 0.422177\tvalid_1's binary_logloss: 0.607929\n",
      "[192]\ttraining's binary_logloss: 0.421462\tvalid_1's binary_logloss: 0.60826\n",
      "[193]\ttraining's binary_logloss: 0.420824\tvalid_1's binary_logloss: 0.608331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[194]\ttraining's binary_logloss: 0.420159\tvalid_1's binary_logloss: 0.608811\n",
      "[195]\ttraining's binary_logloss: 0.419371\tvalid_1's binary_logloss: 0.60826\n",
      "[196]\ttraining's binary_logloss: 0.418572\tvalid_1's binary_logloss: 0.608784\n",
      "[197]\ttraining's binary_logloss: 0.417891\tvalid_1's binary_logloss: 0.608964\n",
      "[198]\ttraining's binary_logloss: 0.41717\tvalid_1's binary_logloss: 0.60936\n",
      "[199]\ttraining's binary_logloss: 0.416526\tvalid_1's binary_logloss: 0.609618\n",
      "[200]\ttraining's binary_logloss: 0.415756\tvalid_1's binary_logloss: 0.609881\n",
      "[201]\ttraining's binary_logloss: 0.415058\tvalid_1's binary_logloss: 0.609832\n",
      "[202]\ttraining's binary_logloss: 0.414324\tvalid_1's binary_logloss: 0.610014\n",
      "[203]\ttraining's binary_logloss: 0.413585\tvalid_1's binary_logloss: 0.610107\n",
      "[204]\ttraining's binary_logloss: 0.412798\tvalid_1's binary_logloss: 0.610432\n",
      "[205]\ttraining's binary_logloss: 0.41209\tvalid_1's binary_logloss: 0.610616\n",
      "[206]\ttraining's binary_logloss: 0.411336\tvalid_1's binary_logloss: 0.610971\n",
      "[207]\ttraining's binary_logloss: 0.410626\tvalid_1's binary_logloss: 0.611248\n",
      "[208]\ttraining's binary_logloss: 0.410003\tvalid_1's binary_logloss: 0.611792\n",
      "[209]\ttraining's binary_logloss: 0.409252\tvalid_1's binary_logloss: 0.612032\n",
      "[210]\ttraining's binary_logloss: 0.408566\tvalid_1's binary_logloss: 0.61221\n",
      "[211]\ttraining's binary_logloss: 0.407803\tvalid_1's binary_logloss: 0.612316\n",
      "[212]\ttraining's binary_logloss: 0.407127\tvalid_1's binary_logloss: 0.612495\n",
      "[213]\ttraining's binary_logloss: 0.4064\tvalid_1's binary_logloss: 0.611917\n",
      "[214]\ttraining's binary_logloss: 0.405728\tvalid_1's binary_logloss: 0.612519\n",
      "[215]\ttraining's binary_logloss: 0.405077\tvalid_1's binary_logloss: 0.612765\n",
      "[216]\ttraining's binary_logloss: 0.404356\tvalid_1's binary_logloss: 0.612383\n",
      "[217]\ttraining's binary_logloss: 0.403719\tvalid_1's binary_logloss: 0.61238\n",
      "[218]\ttraining's binary_logloss: 0.403095\tvalid_1's binary_logloss: 0.612218\n",
      "[219]\ttraining's binary_logloss: 0.402518\tvalid_1's binary_logloss: 0.61242\n",
      "[220]\ttraining's binary_logloss: 0.401921\tvalid_1's binary_logloss: 0.612454\n",
      "[221]\ttraining's binary_logloss: 0.401269\tvalid_1's binary_logloss: 0.612367\n",
      "[222]\ttraining's binary_logloss: 0.400617\tvalid_1's binary_logloss: 0.61241\n",
      "[223]\ttraining's binary_logloss: 0.399992\tvalid_1's binary_logloss: 0.612486\n",
      "[224]\ttraining's binary_logloss: 0.399321\tvalid_1's binary_logloss: 0.612776\n",
      "[225]\ttraining's binary_logloss: 0.398735\tvalid_1's binary_logloss: 0.613451\n",
      "[226]\ttraining's binary_logloss: 0.398141\tvalid_1's binary_logloss: 0.613401\n",
      "[227]\ttraining's binary_logloss: 0.397515\tvalid_1's binary_logloss: 0.613395\n",
      "[228]\ttraining's binary_logloss: 0.396858\tvalid_1's binary_logloss: 0.613893\n",
      "[229]\ttraining's binary_logloss: 0.396122\tvalid_1's binary_logloss: 0.613888\n",
      "[230]\ttraining's binary_logloss: 0.395476\tvalid_1's binary_logloss: 0.613876\n",
      "[231]\ttraining's binary_logloss: 0.394899\tvalid_1's binary_logloss: 0.613959\n",
      "[232]\ttraining's binary_logloss: 0.394239\tvalid_1's binary_logloss: 0.61386\n",
      "[233]\ttraining's binary_logloss: 0.393536\tvalid_1's binary_logloss: 0.613255\n",
      "[234]\ttraining's binary_logloss: 0.392961\tvalid_1's binary_logloss: 0.613403\n",
      "[235]\ttraining's binary_logloss: 0.39242\tvalid_1's binary_logloss: 0.613293\n",
      "[236]\ttraining's binary_logloss: 0.391727\tvalid_1's binary_logloss: 0.613704\n",
      "[237]\ttraining's binary_logloss: 0.391167\tvalid_1's binary_logloss: 0.613996\n",
      "[238]\ttraining's binary_logloss: 0.390586\tvalid_1's binary_logloss: 0.614283\n",
      "[239]\ttraining's binary_logloss: 0.389876\tvalid_1's binary_logloss: 0.614068\n",
      "[240]\ttraining's binary_logloss: 0.389311\tvalid_1's binary_logloss: 0.614001\n",
      "[241]\ttraining's binary_logloss: 0.38874\tvalid_1's binary_logloss: 0.613854\n",
      "[242]\ttraining's binary_logloss: 0.388173\tvalid_1's binary_logloss: 0.613195\n",
      "[243]\ttraining's binary_logloss: 0.38763\tvalid_1's binary_logloss: 0.613166\n",
      "[244]\ttraining's binary_logloss: 0.387089\tvalid_1's binary_logloss: 0.613315\n",
      "[245]\ttraining's binary_logloss: 0.386465\tvalid_1's binary_logloss: 0.613558\n",
      "[246]\ttraining's binary_logloss: 0.385861\tvalid_1's binary_logloss: 0.613781\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(learning_rate=0.02, n_estimators=800)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(learning_rate=0.02, n_estimators=800)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(learning_rate=0.02, n_estimators=800)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evals = [(X_tr, y_tr), (X_val, y_val)]\n",
    "lgbm_wrapper.fit(X_tr, y_tr, early_stopping_rounds=100, eval_metric=\"logloss\", eval_set=evals, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z3YiAxdOAhqh"
   },
   "source": [
    "### **3-1-g. 위에서 학습시킨 `lgbm_wrapper`의 정확도를 출력하세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "yrG3MF-JAom3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 : 0.6768\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "preds = lgbm_wrapper.predict(X_test)\n",
    "pred_proba = lgbm_wrapper.predict_proba(X_test)[:, 1]\n",
    "accuracy = accuracy_score(y_test , preds)\n",
    "\n",
    "print(\"정확도 : {0:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s5_joSurAjHs"
   },
   "source": [
    "### **3-1-i. 피처 중요도를 중요한 순서대로 시각화 해주세요.**\n",
    "(힌트: 파머완 252 페이지)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "5PG_98tJBfB9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Feature importance'}, xlabel='Feature importance', ylabel='Features'>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from lightgbm import plot_importance\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,12))\n",
    "plot_importance(lgbm_wrapper, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "egUn68R9AjSZ"
   },
   "source": [
    "## **3-2. HyperOpt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "YQfqj1GmGiYa"
   },
   "outputs": [],
   "source": [
    "from hyperopt import hp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dt90nZGGAjaO"
   },
   "source": [
    "### **3-2-a. 주어진 정보를 바탕으로 검색 공간을 설정해 주세요.**\n",
    "(힌트: `hp.uniform`)\n",
    "\n",
    "- max_depth: 5에서 20까지, 간격 = 1\n",
    "- min_child_weight: 1에서 2까지, 간격 = 1\n",
    "- colsample_bytree: 0.5, 1\n",
    "- learning_rate: 0.01에서 0.2 사이, 정규 분포된 값으로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "j9hI35hEBenL"
   },
   "outputs": [],
   "source": [
    "search_space = {'max_depth': hp.quniform('max_depth', 5, 20, 1), \n",
    "                'min_child_weight': hp.quniform('min_child_weight', 1, 2, 1),\n",
    "                'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 0.95),\n",
    "                'learning_rate': hp.uniform('learning_rate', 0.01, 0.2)\n",
    "               }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3cSRp1UDAji8"
   },
   "source": [
    "### **3-2-b. 검색 공간을 인자로 받아 목적함수를 완성해 주세요.**\n",
    "(n_estimators = 800)  \n",
    "(❓❓❓❓❓로 표시된 빈칸을 채워주세요!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "VIi05vIgHFKQ"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "from hyperopt import STATUS_OK\n",
    "\n",
    "\n",
    "def objective_func(search_space):\n",
    "    xgb_clf = XGBClassifier(n_estimators = 800,\n",
    "                            max_depth = int(search_space['max_depth']),\n",
    "                            min_child_weight = int(search_space['min_child_weight']),\n",
    "                            learning_rate = search_space['learning_rate'],\n",
    "                            colsample_bytree = search_space['colsample_bytree'],\n",
    "                            eval_metric = 'logloss')\n",
    "    accuracy = cross_val_score(xgb_clf, X_train, y_train, scoring = 'accuracy', cv = 3)\n",
    "\n",
    "    return {'loss':-1 * np.mean(accuracy), 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dpFPo2bIBKYA"
   },
   "source": [
    "### **3-2-c. best에 `fmin()` 함수를 이용하여 최적 파라미터 값들을 저장해 주세요.**\n",
    "- fn, 검색공간: 위에서 구한 값\n",
    "- 최대 반복 횟수: 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "oagDclMCKKmS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 50/50 [06:45<00:00,  8.11s/trial, best loss: -0.6629772923268877]\n",
      "best: {'colsample_bytree': 0.9416056675880711, 'learning_rate': 0.010085626080481525, 'max_depth': 14.0, 'min_child_weight': 1.0}\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, Trials\n",
    "\n",
    "trial_val = Trials()\n",
    "best = fmin(fn=objective_func,\n",
    "            space=search_space,\n",
    "            algo = tpe.suggest,\n",
    "            max_evals=50,\n",
    "            trials = trial_val,\n",
    "            rstate = np.random.default_rng(seed = 9))\n",
    "print('best:', best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X00SYdMqBKf-"
   },
   "source": [
    "### **3-2-d. 아래는 best에 포함된 최적 파라미터들을 할당한 분류기입니다. 해당 분류기의 정확도를 출력해 주세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "YWG7Vx8qLskd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 : 0.6784\n"
     ]
    }
   ],
   "source": [
    "xgb_wrapper = XGBClassifier(n_estimators = 400,\n",
    "                            learning_rate = round(best['learning_rate'], 5),\n",
    "                            max_depth = int(best['max_depth']),\n",
    "                            min_child_weight = int(best['min_child_weight']),\n",
    "                            colsample_bytree = round(best['colsample_bytree'], 5)\n",
    "                           )\n",
    "\n",
    "evals = [(X_tr, y_tr), (X_val, y_val)]\n",
    "xgb_wrapper.fit(X_tr, y_tr, early_stopping_rounds=100, eval_metric = 'logloss',\n",
    "                eval_set = evals, verbose = 0)\n",
    "\n",
    "accuracy = accuracy_score(y_test , xgb_wrapper.predict(X_test))\n",
    "\n",
    "print(\"정확도 : {0:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zi7nlAXnaIvx"
   },
   "source": [
    "# **4. 스태킹**\n",
    "- 4번 문제는 3번 문제에서 전처리 된 `water_potability.csv` 데이터를 계속 활용하시면 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zo-EqV9IaOHE"
   },
   "source": [
    "## **4-a. 기본 스태킹 기법을 적용해 봅시다.**\n",
    "- `SVM`, `KNN`, `로지스틱 회귀`, `결정 트리` 모델 객체를 생성해 주세요.\n",
    "- 최종 메타 모델은 `랜덤 포레스트`를 활용해주세요.\n",
    "- 파라미터 설정\n",
    "  - SVM: random_state = 0\n",
    "  - KNN: n_neighbors = 8\n",
    "  - RandomForest: n_estimators = 100, random_state = 0\n",
    "  - 나머지: 기본 파라미터(base model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "A8oVE61iW2rE"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "-g8nzDlXW_hD"
   },
   "outputs": [],
   "source": [
    "# SVM, KNN, 로지스틱 회귀, 결정 트리 개별 모델들을 생성해 주세요.\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "svm_clf = SVC(kernel='linear')\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=4)\n",
    "lr_clf = LogisticRegression()\n",
    "dt_clf =DecisionTreeClassifier()\n",
    "\n",
    "# 최종 메타 모델로 랜덤 포레스트를 생성해 주세요.\n",
    "rf_final = RandomForestClassifier(n_estimators=100, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_kiFDVuDZ92_"
   },
   "source": [
    "## **4-b. 개별 모델들을 학습시키고 예측을 수행합니다.**\n",
    "- 아래 코드를 완성시켜 봅시다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "Vda9AE6ga1ne"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf.fit(X_tr, y_tr)\n",
    "knn_clf.fit(X_tr, y_tr)\n",
    "lr_clf.fit(X_tr, y_tr)\n",
    "dt_clf.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "bqQEJMSwbXfz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM 정확도: 0.6107\n",
      "KNN 정확도: 0.5840\n",
      "로지스틱 회귀 정확도: 0.6145\n",
      "결정 트리 정확도: 0.5992\n"
     ]
    }
   ],
   "source": [
    "## 학습된 개별 모델들이 반환하는 예측 데이터셋을 생성하세요.\n",
    "# 예측 시 들어가는 테스트 데이터셋 이름은 X_val 입니다.\n",
    "svm_pred = svm_clf.predict(X_val)\n",
    "knn_pred = knn_clf.predict(X_val)\n",
    "lr_pred = lr_clf.predict(X_val)\n",
    "dt_pred = dt_clf.predict(X_val)\n",
    "\n",
    "## 예측 정확도를 반환하세요. 테스트 레이블 데이터셋 이름은 y_val 입니다.\n",
    "# hint : accuracy_score()\n",
    "print('SVM 정확도: {0:.4f}'.format(accuracy_score(y_val, svm_pred)))\n",
    "print('KNN 정확도: {0:.4f}'.format(accuracy_score(y_val, knn_pred)))\n",
    "print('로지스틱 회귀 정확도: {0:.4f}'.format(accuracy_score(y_val,lr_pred)))\n",
    "print('결정 트리 정확도: {0:.4f}'.format(accuracy_score(y_val, dt_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AmQiW4i4c_9B"
   },
   "source": [
    "## **4-c. 반환된 예측 데이터셋을 행 형태로 묶어 pred 데이터셋에 저장합니다**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "Od3yHZ3fc8Uf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 262)\n",
      "(262, 4)\n"
     ]
    }
   ],
   "source": [
    "pred = np.array([knn_pred, svm_pred, dt_pred, lr_pred])\n",
    "print(pred.shape)\n",
    "\n",
    "# 행과 열의 위치를 교환해 원본 데이터 값 하나 당 예측 데이터셋의 값이 1대1 매칭이 되도록 하세요.\n",
    "pred = np.transpose(pred)\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h8rhG78DdzpT"
   },
   "source": [
    "## **4-d. 완성된 최종 데이터셋을 최종 메타 모델에 학습시키고 예측시킵니다.**\n",
    "- 기본 스태킹 모델이므로 학습과 예측 모두 **동일한** 데이터셋을 사용합니다.\n",
    "- **정확도**도 함께 출력해 주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "eDf69kCPebqf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 메타 모델의 예측 정확도: 0.6145\n"
     ]
    }
   ],
   "source": [
    "rf_final.fit(pred, y_val)\n",
    "final = rf_final.predict(pred)\n",
    "\n",
    "print('최종 메타 모델의 예측 정확도: {0:.4f}'.format(accuracy_score(y_val , final)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bt9i77_NqqJp"
   },
   "source": [
    "# **5. CatBoost**\n",
    "- 책에서 다루지 않는 부분이기 때문에 간단한 실습만 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "bUp-KlCjr7nt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-3.3.0-py3-none-any.whl (404 kB)\n",
      "                                              0.0/404.2 kB ? eta -:--:--\n",
      "     ---------------------------------      358.4/404.2 kB 7.4 MB/s eta 0:00:01\n",
      "     -------------------------------------- 404.2/404.2 kB 6.3 MB/s eta 0:00:00\n",
      "Collecting alembic>=1.5.0 (from optuna)\n",
      "  Downloading alembic-1.12.0-py3-none-any.whl (226 kB)\n",
      "                                              0.0/226.0 kB ? eta -:--:--\n",
      "     -------------------------------------- 226.0/226.0 kB 7.0 MB/s eta 0:00:00\n",
      "Collecting cmaes>=0.10.0 (from optuna)\n",
      "  Downloading cmaes-0.10.0-py3-none-any.whl (29 kB)\n",
      "Collecting colorlog (from optuna)\n",
      "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\jain5\\anaconda3\\lib\\site-packages (from optuna) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jain5\\anaconda3\\lib\\site-packages (from optuna) (23.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in c:\\users\\jain5\\anaconda3\\lib\\site-packages (from optuna) (1.4.39)\n",
      "Requirement already satisfied: tqdm in c:\\users\\jain5\\anaconda3\\lib\\site-packages (from optuna) (4.65.0)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\jain5\\anaconda3\\lib\\site-packages (from optuna) (6.0)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna)\n",
      "  Using cached Mako-1.2.4-py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\users\\jain5\\anaconda3\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.6.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\jain5\\anaconda3\\lib\\site-packages (from sqlalchemy>=1.3.0->optuna) (2.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\jain5\\anaconda3\\lib\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\jain5\\anaconda3\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.1)\n",
      "Installing collected packages: Mako, colorlog, cmaes, alembic, optuna\n",
      "Successfully installed Mako-1.2.4 alembic-1.12.0 cmaes-0.10.0 colorlog-6.7.0 optuna-3.3.0\n",
      "Collecting catboost\n",
      "  Downloading catboost-1.2.2-cp311-cp311-win_amd64.whl (101.0 MB)\n",
      "                                              0.0/101.0 MB ? eta -:--:--\n",
      "                                              0.3/101.0 MB 8.6 MB/s eta 0:00:12\n",
      "                                              0.6/101.0 MB 7.7 MB/s eta 0:00:13\n",
      "                                              1.0/101.0 MB 7.9 MB/s eta 0:00:13\n",
      "                                              1.3/101.0 MB 7.7 MB/s eta 0:00:14\n",
      "                                              1.8/101.0 MB 8.0 MB/s eta 0:00:13\n",
      "                                              2.3/101.0 MB 8.7 MB/s eta 0:00:12\n",
      "     -                                        2.9/101.0 MB 9.2 MB/s eta 0:00:11\n",
      "     -                                        3.5/101.0 MB 9.6 MB/s eta 0:00:11\n",
      "     -                                        3.9/101.0 MB 9.7 MB/s eta 0:00:11\n",
      "     -                                       4.6/101.0 MB 10.1 MB/s eta 0:00:10\n",
      "     -                                       5.1/101.0 MB 10.5 MB/s eta 0:00:10\n",
      "     --                                      5.5/101.0 MB 10.4 MB/s eta 0:00:10\n",
      "     --                                      6.1/101.0 MB 10.3 MB/s eta 0:00:10\n",
      "     --                                      6.7/101.0 MB 10.5 MB/s eta 0:00:09\n",
      "     --                                      7.4/101.0 MB 10.9 MB/s eta 0:00:09\n",
      "     ---                                     7.9/101.0 MB 11.0 MB/s eta 0:00:09\n",
      "     ---                                     8.4/101.0 MB 11.0 MB/s eta 0:00:09\n",
      "     ---                                     8.8/101.0 MB 10.7 MB/s eta 0:00:09\n",
      "     ---                                     9.4/101.0 MB 10.9 MB/s eta 0:00:09\n",
      "     ---                                     9.8/101.0 MB 10.8 MB/s eta 0:00:09\n",
      "     ---                                    10.4/101.0 MB 10.9 MB/s eta 0:00:09\n",
      "     ----                                   11.0/101.0 MB 11.3 MB/s eta 0:00:08\n",
      "     ----                                   11.5/101.0 MB 11.5 MB/s eta 0:00:08\n",
      "     ----                                   12.1/101.0 MB 11.9 MB/s eta 0:00:08\n",
      "     ----                                   12.5/101.0 MB 11.5 MB/s eta 0:00:08\n",
      "     ----                                   13.0/101.0 MB 11.5 MB/s eta 0:00:08\n",
      "     -----                                  13.5/101.0 MB 11.5 MB/s eta 0:00:08\n",
      "     -----                                  14.1/101.0 MB 11.7 MB/s eta 0:00:08\n",
      "     -----                                  14.6/101.0 MB 11.5 MB/s eta 0:00:08\n",
      "     -----                                  15.1/101.0 MB 11.3 MB/s eta 0:00:08\n",
      "     -----                                  15.6/101.0 MB 11.5 MB/s eta 0:00:08\n",
      "     ------                                 16.2/101.0 MB 11.5 MB/s eta 0:00:08\n",
      "     ------                                 16.7/101.0 MB 11.3 MB/s eta 0:00:08\n",
      "     ------                                 17.3/101.0 MB 11.3 MB/s eta 0:00:08\n",
      "     ------                                 17.8/101.0 MB 11.3 MB/s eta 0:00:08\n",
      "     ------                                 18.3/101.0 MB 11.1 MB/s eta 0:00:08\n",
      "     -------                                19.0/101.0 MB 11.5 MB/s eta 0:00:08\n",
      "     -------                                19.6/101.0 MB 11.5 MB/s eta 0:00:08\n",
      "     -------                                20.2/101.0 MB 11.9 MB/s eta 0:00:07\n",
      "     -------                                20.7/101.0 MB 11.7 MB/s eta 0:00:07\n",
      "     --------                               21.4/101.0 MB 11.9 MB/s eta 0:00:07\n",
      "     --------                               22.0/101.0 MB 11.7 MB/s eta 0:00:07\n",
      "     --------                               22.6/101.0 MB 12.1 MB/s eta 0:00:07\n",
      "     --------                               23.1/101.0 MB 12.1 MB/s eta 0:00:07\n",
      "     --------                               23.8/101.0 MB 12.4 MB/s eta 0:00:07\n",
      "     ---------                              24.2/101.0 MB 12.1 MB/s eta 0:00:07\n",
      "     ---------                              24.9/101.0 MB 12.4 MB/s eta 0:00:07\n",
      "     ---------                              25.4/101.0 MB 12.4 MB/s eta 0:00:07\n",
      "     ---------                              26.0/101.0 MB 12.4 MB/s eta 0:00:07\n",
      "     ----------                             26.7/101.0 MB 12.6 MB/s eta 0:00:06\n",
      "     ----------                             27.3/101.0 MB 12.6 MB/s eta 0:00:06\n",
      "     ----------                             28.0/101.0 MB 12.8 MB/s eta 0:00:06\n",
      "     ----------                             28.5/101.0 MB 12.8 MB/s eta 0:00:06\n",
      "     ----------                             29.2/101.0 MB 13.1 MB/s eta 0:00:06\n",
      "     -----------                            29.8/101.0 MB 12.9 MB/s eta 0:00:06\n",
      "     -----------                            30.5/101.0 MB 13.1 MB/s eta 0:00:06\n",
      "     -----------                            31.1/101.0 MB 13.4 MB/s eta 0:00:06\n",
      "     -----------                            31.5/101.0 MB 13.1 MB/s eta 0:00:06\n",
      "     -----------                            31.5/101.0 MB 13.1 MB/s eta 0:00:06\n",
      "     ------------                           32.0/101.0 MB 11.9 MB/s eta 0:00:06\n",
      "     ------------                           32.6/101.0 MB 11.9 MB/s eta 0:00:06\n",
      "     ------------                           33.0/101.0 MB 11.7 MB/s eta 0:00:06\n",
      "     ------------                           33.5/101.0 MB 11.7 MB/s eta 0:00:06\n",
      "     ------------                           34.2/101.0 MB 11.7 MB/s eta 0:00:06\n",
      "     -------------                          34.8/101.0 MB 11.9 MB/s eta 0:00:06\n",
      "     -------------                          35.4/101.0 MB 11.7 MB/s eta 0:00:06\n",
      "     -------------                          36.0/101.0 MB 11.9 MB/s eta 0:00:06\n",
      "     -------------                          36.5/101.0 MB 11.7 MB/s eta 0:00:06\n",
      "     -------------                          37.1/101.0 MB 11.7 MB/s eta 0:00:06\n",
      "     --------------                         37.7/101.0 MB 11.7 MB/s eta 0:00:06\n",
      "     --------------                         38.2/101.0 MB 11.7 MB/s eta 0:00:06\n",
      "     --------------                         38.9/101.0 MB 11.5 MB/s eta 0:00:06\n",
      "     --------------                         39.3/101.0 MB 11.5 MB/s eta 0:00:06\n",
      "     ---------------                        39.9/101.0 MB 11.5 MB/s eta 0:00:06\n",
      "     ---------------                        40.5/101.0 MB 11.5 MB/s eta 0:00:06\n",
      "     ---------------                        41.2/101.0 MB 11.5 MB/s eta 0:00:06\n",
      "     ---------------                        41.7/101.0 MB 12.6 MB/s eta 0:00:05\n",
      "     ---------------                        42.4/101.0 MB 12.6 MB/s eta 0:00:05\n",
      "     ----------------                       43.0/101.0 MB 12.8 MB/s eta 0:00:05\n",
      "     ----------------                       43.6/101.0 MB 12.8 MB/s eta 0:00:05\n",
      "     ----------------                       44.1/101.0 MB 12.8 MB/s eta 0:00:05\n",
      "     ----------------                       44.6/101.0 MB 12.6 MB/s eta 0:00:05\n",
      "     -----------------                      45.2/101.0 MB 12.6 MB/s eta 0:00:05\n",
      "     -----------------                      45.8/101.0 MB 12.6 MB/s eta 0:00:05\n",
      "     -----------------                      46.5/101.0 MB 12.8 MB/s eta 0:00:05\n",
      "     -----------------                      46.9/101.0 MB 12.6 MB/s eta 0:00:05\n",
      "     -----------------                      47.6/101.0 MB 12.6 MB/s eta 0:00:05\n",
      "     ------------------                     48.2/101.0 MB 12.6 MB/s eta 0:00:05\n",
      "     ------------------                     48.7/101.0 MB 12.6 MB/s eta 0:00:05\n",
      "     ------------------                     49.4/101.0 MB 12.9 MB/s eta 0:00:05\n",
      "     ------------------                     50.0/101.0 MB 12.8 MB/s eta 0:00:04\n",
      "     -------------------                    50.7/101.0 MB 12.8 MB/s eta 0:00:04\n",
      "     -------------------                    51.1/101.0 MB 12.6 MB/s eta 0:00:04\n",
      "     -------------------                    51.7/101.0 MB 12.6 MB/s eta 0:00:04\n",
      "     -------------------                    52.2/101.0 MB 12.6 MB/s eta 0:00:04\n",
      "     -------------------                    52.8/101.0 MB 12.4 MB/s eta 0:00:04\n",
      "     --------------------                   53.4/101.0 MB 12.3 MB/s eta 0:00:04\n",
      "     --------------------                   53.9/101.0 MB 12.6 MB/s eta 0:00:04\n",
      "     --------------------                   54.4/101.0 MB 12.6 MB/s eta 0:00:04\n",
      "     --------------------                   54.9/101.0 MB 12.1 MB/s eta 0:00:04\n",
      "     --------------------                   55.4/101.0 MB 12.1 MB/s eta 0:00:04\n",
      "     ---------------------                  55.8/101.0 MB 11.9 MB/s eta 0:00:04\n",
      "     ---------------------                  56.4/101.0 MB 12.1 MB/s eta 0:00:04\n",
      "     ---------------------                  56.9/101.0 MB 12.1 MB/s eta 0:00:04\n",
      "     ---------------------                  57.5/101.0 MB 12.1 MB/s eta 0:00:04\n",
      "     ---------------------                  58.1/101.0 MB 11.9 MB/s eta 0:00:04\n",
      "     ----------------------                 58.7/101.0 MB 12.1 MB/s eta 0:00:04\n",
      "     ----------------------                 59.3/101.0 MB 12.1 MB/s eta 0:00:04\n",
      "     ----------------------                 59.9/101.0 MB 12.1 MB/s eta 0:00:04\n",
      "     ----------------------                 60.6/101.0 MB 11.9 MB/s eta 0:00:04\n",
      "     -----------------------                61.2/101.0 MB 12.1 MB/s eta 0:00:04\n",
      "     -----------------------                61.8/101.0 MB 12.1 MB/s eta 0:00:04\n",
      "     -----------------------                62.3/101.0 MB 12.1 MB/s eta 0:00:04\n",
      "     -----------------------                63.0/101.0 MB 12.4 MB/s eta 0:00:04\n",
      "     -----------------------                63.5/101.0 MB 12.1 MB/s eta 0:00:04\n",
      "     ------------------------               64.0/101.0 MB 12.1 MB/s eta 0:00:04\n",
      "     ------------------------               64.5/101.0 MB 12.1 MB/s eta 0:00:04\n",
      "     ------------------------               65.1/101.0 MB 12.4 MB/s eta 0:00:03\n",
      "     ------------------------               65.7/101.0 MB 12.4 MB/s eta 0:00:03\n",
      "     ------------------------               66.2/101.0 MB 12.6 MB/s eta 0:00:03\n",
      "     -------------------------              66.9/101.0 MB 12.6 MB/s eta 0:00:03\n",
      "     -------------------------              67.5/101.0 MB 12.6 MB/s eta 0:00:03\n",
      "     -------------------------              68.2/101.0 MB 12.8 MB/s eta 0:00:03\n",
      "     -------------------------              68.7/101.0 MB 12.8 MB/s eta 0:00:03\n",
      "     --------------------------             69.3/101.0 MB 12.6 MB/s eta 0:00:03\n",
      "     --------------------------             69.9/101.0 MB 12.6 MB/s eta 0:00:03\n",
      "     --------------------------             70.3/101.0 MB 12.4 MB/s eta 0:00:03\n",
      "     --------------------------             70.9/101.0 MB 12.4 MB/s eta 0:00:03\n",
      "     --------------------------             71.5/101.0 MB 12.4 MB/s eta 0:00:03\n",
      "     ---------------------------            71.8/101.0 MB 12.1 MB/s eta 0:00:03\n",
      "     ---------------------------            72.3/101.0 MB 11.9 MB/s eta 0:00:03\n",
      "     ---------------------------            72.6/101.0 MB 11.7 MB/s eta 0:00:03\n",
      "     ---------------------------            73.1/101.0 MB 11.5 MB/s eta 0:00:03\n",
      "     ---------------------------            73.5/101.0 MB 11.3 MB/s eta 0:00:03\n",
      "     ---------------------------            74.1/101.0 MB 11.5 MB/s eta 0:00:03\n",
      "     ----------------------------           74.7/101.0 MB 11.5 MB/s eta 0:00:03\n",
      "     ----------------------------           75.1/101.0 MB 11.3 MB/s eta 0:00:03\n",
      "     ----------------------------           75.5/101.0 MB 11.1 MB/s eta 0:00:03\n",
      "     ----------------------------           76.0/101.0 MB 11.1 MB/s eta 0:00:03\n",
      "     ----------------------------           76.6/101.0 MB 11.1 MB/s eta 0:00:03\n",
      "     -----------------------------          77.2/101.0 MB 11.1 MB/s eta 0:00:03\n",
      "     -----------------------------          77.7/101.0 MB 10.9 MB/s eta 0:00:03\n",
      "     -----------------------------          78.1/101.0 MB 10.7 MB/s eta 0:00:03\n",
      "     -----------------------------          78.6/101.0 MB 10.6 MB/s eta 0:00:03\n",
      "     -----------------------------          79.0/101.0 MB 10.6 MB/s eta 0:00:03\n",
      "     -----------------------------          79.4/101.0 MB 10.6 MB/s eta 0:00:03\n",
      "     -----------------------------          79.7/101.0 MB 10.4 MB/s eta 0:00:03\n",
      "     ------------------------------         80.3/101.0 MB 10.2 MB/s eta 0:00:03\n",
      "     ------------------------------         80.7/101.0 MB 10.2 MB/s eta 0:00:02\n",
      "     ------------------------------         81.1/101.0 MB 10.1 MB/s eta 0:00:02\n",
      "     -------------------------------         81.6/101.0 MB 9.9 MB/s eta 0:00:02\n",
      "     ------------------------------         82.0/101.0 MB 10.1 MB/s eta 0:00:02\n",
      "     -------------------------------        82.5/101.0 MB 10.1 MB/s eta 0:00:02\n",
      "     -------------------------------        83.0/101.0 MB 10.2 MB/s eta 0:00:02\n",
      "     -------------------------------        83.4/101.0 MB 10.1 MB/s eta 0:00:02\n",
      "     -------------------------------        83.8/101.0 MB 10.1 MB/s eta 0:00:02\n",
      "     --------------------------------        84.1/101.0 MB 9.9 MB/s eta 0:00:02\n",
      "     --------------------------------        84.6/101.0 MB 9.9 MB/s eta 0:00:02\n",
      "     --------------------------------        85.1/101.0 MB 9.8 MB/s eta 0:00:02\n",
      "     --------------------------------        85.5/101.0 MB 9.8 MB/s eta 0:00:02\n",
      "     ---------------------------------       86.0/101.0 MB 9.8 MB/s eta 0:00:02\n",
      "     ---------------------------------       86.4/101.0 MB 9.8 MB/s eta 0:00:02\n",
      "     ---------------------------------       86.9/101.0 MB 9.6 MB/s eta 0:00:02\n",
      "     ---------------------------------       87.4/101.0 MB 9.6 MB/s eta 0:00:02\n",
      "     ---------------------------------       87.8/101.0 MB 9.6 MB/s eta 0:00:02\n",
      "     ----------------------------------      88.2/101.0 MB 9.5 MB/s eta 0:00:02\n",
      "     ----------------------------------      88.8/101.0 MB 9.6 MB/s eta 0:00:02\n",
      "     ----------------------------------      89.4/101.0 MB 9.8 MB/s eta 0:00:02\n",
      "     ----------------------------------      89.9/101.0 MB 9.9 MB/s eta 0:00:02\n",
      "     ----------------------------------     90.6/101.0 MB 10.1 MB/s eta 0:00:02\n",
      "     ----------------------------------     91.2/101.0 MB 10.2 MB/s eta 0:00:01\n",
      "     ----------------------------------     91.8/101.0 MB 10.4 MB/s eta 0:00:01\n",
      "     ----------------------------------     92.4/101.0 MB 10.7 MB/s eta 0:00:01\n",
      "     ----------------------------------     93.0/101.0 MB 10.9 MB/s eta 0:00:01\n",
      "     -----------------------------------    93.7/101.0 MB 11.1 MB/s eta 0:00:01\n",
      "     -----------------------------------    94.3/101.0 MB 11.7 MB/s eta 0:00:01\n",
      "     -----------------------------------    94.9/101.0 MB 11.9 MB/s eta 0:00:01\n",
      "     -----------------------------------    95.6/101.0 MB 12.1 MB/s eta 0:00:01\n",
      "     ------------------------------------   96.2/101.0 MB 12.1 MB/s eta 0:00:01\n",
      "     ------------------------------------   96.8/101.0 MB 12.6 MB/s eta 0:00:01\n",
      "     ------------------------------------   97.3/101.0 MB 12.6 MB/s eta 0:00:01\n",
      "     ------------------------------------   97.9/101.0 MB 12.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  98.4/101.0 MB 13.1 MB/s eta 0:00:01\n",
      "     -------------------------------------  99.1/101.0 MB 13.1 MB/s eta 0:00:01\n",
      "     -------------------------------------  99.6/101.0 MB 13.1 MB/s eta 0:00:01\n",
      "     ------------------------------------  100.2/101.0 MB 13.1 MB/s eta 0:00:01\n",
      "     ------------------------------------  100.9/101.0 MB 13.1 MB/s eta 0:00:01\n",
      "     ------------------------------------  101.0/101.0 MB 13.1 MB/s eta 0:00:01\n",
      "     ------------------------------------  101.0/101.0 MB 13.1 MB/s eta 0:00:01\n",
      "     ------------------------------------  101.0/101.0 MB 13.1 MB/s eta 0:00:01\n",
      "     ------------------------------------  101.0/101.0 MB 13.1 MB/s eta 0:00:01\n",
      "     ------------------------------------  101.0/101.0 MB 13.1 MB/s eta 0:00:01\n",
      "     ------------------------------------  101.0/101.0 MB 13.1 MB/s eta 0:00:01\n",
      "     ------------------------------------  101.0/101.0 MB 13.1 MB/s eta 0:00:01\n",
      "     ------------------------------------  101.0/101.0 MB 13.1 MB/s eta 0:00:01\n",
      "     ------------------------------------  101.0/101.0 MB 13.1 MB/s eta 0:00:01\n",
      "     ------------------------------------  101.0/101.0 MB 13.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- 101.0/101.0 MB 7.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: graphviz in c:\\users\\jain5\\anaconda3\\lib\\site-packages (from catboost) (0.20.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\jain5\\anaconda3\\lib\\site-packages (from catboost) (3.7.1)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\jain5\\anaconda3\\lib\\site-packages (from catboost) (1.24.3)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\jain5\\anaconda3\\lib\\site-packages (from catboost) (1.5.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\jain5\\anaconda3\\lib\\site-packages (from catboost) (1.10.1)\n",
      "Requirement already satisfied: plotly in c:\\users\\jain5\\anaconda3\\lib\\site-packages (from catboost) (5.9.0)\n",
      "Requirement already satisfied: six in c:\\users\\jain5\\anaconda3\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\jain5\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jain5\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2022.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\jain5\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\jain5\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\jain5\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\jain5\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jain5\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (23.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\jain5\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\jain5\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (3.0.9)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\jain5\\anaconda3\\lib\\site-packages (from plotly->catboost) (8.2.2)\n",
      "Installing collected packages: catboost\n",
      "Successfully installed catboost-1.2.2\n"
     ]
    }
   ],
   "source": [
    "# catboost를 사용하기 위해 다음 코드를 실행합니다.\n",
    "\n",
    "!pip install optuna\n",
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "xbcYHmIsqycq"
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "cT3d6EKqsJRj"
   },
   "outputs": [],
   "source": [
    "df = datasets.load_iris()\n",
    "X = df.data\n",
    "y = df.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "8t-R1-Wfskfm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x18c3f728f10>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CatBoostClassifier 객체를 생성하고 학습시켜 주세요.\n",
    "\n",
    "model_CBC = CatBoostClassifier()\n",
    "model_CBC.fit(X_train, y_train, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "7yfAnYNXs4LW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost의 예측 정확도: 0.9333\n"
     ]
    }
   ],
   "source": [
    "# pred에 X_test에 대한 예측 결과를 저장해 주세요.\n",
    "pred = model_CBC.predict(X_test)\n",
    "\n",
    "# 아래 코드를 완성해서 정확도를 출력하세요.\n",
    "print('CatBoost의 예측 정확도: {0:.4f}'.format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
