{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPiHR/cF/agjZVh7baRIAUf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["데이터 전처리 - 데이터 인코딩"],"metadata":{"id":"QDTzqhGuAkq5"}},{"cell_type":"markdown","source":["레이 인코딩"],"metadata":{"id":"CTN8LX-5AmEY"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z6CDjQ_UAaXn"},"outputs":[],"source":["from sklearn.preprocessing import LabelEncoder\n","\n","items=['TV','냉장고','전자레인지','컴퓨터','선풍기','선풍기','믹서','믹서']\n","\n","# LabelEncoder를 객체로 생성한 후 , fit( ) 과 transform( ) 으로 label 인코딩 수행.\n","encoder = LabelEncoder()\n","encoder.fit(items)\n","labels = encoder.transform(items)\n","print('인코딩 변환값:',labels)"]},{"cell_type":"code","source":["print('인코딩 클래스:',encoder.classes_)"],"metadata":{"id":"ItTWdmtrBMA6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('디코딩 원본 값:',encoder.inverse_transform([4, 5, 2, 0, 1, 1, 3, 3]))"],"metadata":{"id":"fVmkp8IuBNCm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["원-핫 인코딩"],"metadata":{"id":"uhHzzkiCBPDA"}},{"cell_type":"code","source":["from sklearn.preprocessing import OneHotEncoder\n","import numpy as np\n","\n","items=['TV','냉장고','전자레인지','컴퓨터','선풍기','선풍기','믹서','믹서']\n","\n","# 2차원 ndarray로 변환합니다.\n","items = np.array(items).reshape(-1, 1)\n","\n","# 원-핫 인코딩을 적용합니다.\n","oh_encoder = OneHotEncoder()\n","oh_encoder.fit(items)\n","oh_labels = oh_encoder.transform(items)\n","\n","# OneHotEncoder로 변환한 결과는 희소행렬이므로 toarray()를 이용해 밀집 행렬로 변환.\n","print('원-핫 인코딩 데이터')\n","print(oh_labels.toarray())\n","print('원-핫 인코딩 데이터 차원')\n","print(oh_labels.shape)"],"metadata":{"id":"wXNDcbHoBQZg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","df = pd.DataFrame({'item':['TV','냉장고','전자레인지','컴퓨터','선풍기','선풍기','믹서','믹서'] })\n","pd.get_dummies(df)"],"metadata":{"id":"GB9CZASMBVj9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["피처 스케일링과 정규화"],"metadata":{"id":"FB_PY0KXBXyG"}},{"cell_type":"code","source":["from sklearn.datasets import load_iris\n","import pandas as pd\n","# 붓꽃 데이터 셋을 로딩하고 DataFrame으로 변환합니다.\n","iris = load_iris()\n","iris_data = iris.data\n","iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)\n","\n","print('feature 들의 평균 값')\n","print(iris_df.mean())\n","print('\\nfeature 들의 분산 값')\n","print(iris_df.var())"],"metadata":{"id":"QBSpdexmBZGJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","# StandardScaler객체 생성\n","scaler = StandardScaler()\n","# StandardScaler 로 데이터 셋 변환. fit( ) 과 transform( ) 호출.\n","scaler.fit(iris_df)\n","iris_scaled = scaler.transform(iris_df)\n","\n","#transform( )시 scale 변환된 데이터 셋이 numpy ndarry로 반환되어 이를 DataFrame으로 변환\n","iris_df_scaled = pd.DataFrame(data=iris_scaled, columns=iris.feature_names)\n","print('feature 들의 평균 값')\n","print(iris_df_scaled.mean())\n","print('\\nfeature 들의 분산 값')\n","print(iris_df_scaled.var())"],"metadata":{"id":"_-EhIWZmBc_6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["MinMaxScaler"],"metadata":{"id":"0NHj8ypHBdp-"}},{"cell_type":"code","source":["from sklearn.preprocessing import MinMaxScaler\n","\n","# MinMaxScaler객체 생성\n","scaler = MinMaxScaler()\n","# MinMaxScaler 로 데이터 셋 변환. fit() 과 transform() 호출.\n","scaler.fit(iris_df)\n","iris_scaled = scaler.transform(iris_df)\n","\n","# transform()시 scale 변환된 데이터 셋이 numpy ndarry로 반환되어 이를 DataFrame으로 변환\n","iris_df_scaled = pd.DataFrame(data=iris_scaled, columns=iris.feature_names)\n","print('feature들의 최솟값')\n","print(iris_df_scaled.min())\n","print('\\nfeature들의 최댓값')\n","print(iris_df_scaled.max())"],"metadata":{"id":"uWejokaNBhA5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["학습 데이터와 테스트 데이터의 스케일링 변환 시 유의점"],"metadata":{"id":"q0Gekg4nBi3Y"}},{"cell_type":"code","source":["from sklearn.preprocessing import MinMaxScaler\n","import numpy as np\n","\n","# 학습 데이터는 0 부터 10까지, 테스트 데이터는 0 부터 5까지 값을 가지는 데이터 세트로 생성\n","# Scaler클래스의 fit(), transform()은 2차원 이상 데이터만 가능하므로 reshape(-1, 1)로 차원 변경\n","train_array = np.arange(0, 11).reshape(-1, 1)\n","test_array =  np.arange(0, 6).reshape(-1, 1)"],"metadata":{"id":"zVH-_40zBp39"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# MinMaxScaler 객체에 별도의 feature_range 파라미터 값을 지정하지 않으면 0~1 값으로 변환\n","scaler = MinMaxScaler()\n","\n","# fit()하게 되면 train_array 데이터의 최솟값이 0, 최댓값이 10으로 설정.\n","scaler.fit(train_array)\n","\n","# 1/10 scale로 train_array 데이터 변환함. 원본 10-> 1로 변환됨.\n","train_scaled = scaler.transform(train_array)\n","\n","print('원본 train_array 데이터:', np.round(train_array.reshape(-1), 2))\n","print('Scale된 train_array 데이터:', np.round(train_scaled.reshape(-1), 2))"],"metadata":{"id":"1xiaXYYUBvOI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# MinMaxScaler에 test_array를 fit()하게 되면 원본 데이터의 최솟값이 0, 최댓값이 5로 설정됨\n","scaler.fit(test_array)\n","\n","# 1/5 scale로 test_array 데이터 변환함. 원본 5->1로 변환.\n","test_scaled = scaler.transform(test_array)\n","\n","# test_array의 scale 변환 출력.\n","print('원본 test_array 데이터:', np.round(test_array.reshape(-1), 2))\n","print('Scale된 test_array 데이터:', np.round(test_scaled.reshape(-1), 2))"],"metadata":{"id":"tC7jYWZEBxzU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["scaler = MinMaxScaler()\n","scaler.fit(train_array)\n","train_scaled = scaler.transform(train_array)\n","print('원본 train_array 데이터:', np.round(train_array.reshape(-1), 2))\n","print('Scale된 train_array 데이터:', np.round(train_scaled.reshape(-1), 2))\n","\n","# test_array에 Scale 변환을 할 때는 반드시 fit()을 호출하지 않고 transform() 만으로 변환해야 함.\n","test_scaled = scaler.transform(test_array)\n","print('\\n원본 test_array 데이터:', np.round(test_array.reshape(-1), 2))\n","print('Scale된 test_array 데이터:', np.round(test_scaled.reshape(-1), 2))"],"metadata":{"id":"bl_5OBoBB0A0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["사이킷런으로 수행하는 타이타닉 생존자 예측"],"metadata":{"id":"hQ9Kt72iB3b8"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","%matplotlib inline\n","\n","titanic_df = pd.read_csv('./titanic_train.csv')\n","titanic_df.head(3)"],"metadata":{"id":"LReyoljRB58z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('\\n ### train 데이터 정보 ###  \\n')\n","print(titanic_df.info())"],"metadata":{"id":"4fUqut3tCbcE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["titanic_df['Age'].fillna(titanic_df['Age'].mean(),inplace=True)\n","titanic_df['Cabin'].fillna('N',inplace=True)\n","titanic_df['Embarked'].fillna('N',inplace=True)\n","print('데이터 세트 Null 값 갯수 ',titanic_df.isnull().sum().sum())"],"metadata":{"id":"GBUkJbtID7MW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(' Sex 값 분포 :\\n',titanic_df['Sex'].value_counts())\n","print('\\n Cabin 값 분포 :\\n',titanic_df['Cabin'].value_counts())\n","print('\\n Embarked 값 분포 :\\n',titanic_df['Embarked'].value_counts())"],"metadata":{"id":"AfFa0QyND8cx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["titanic_df['Cabin'] = titanic_df['Cabin'].str[:1]\n","print(titanic_df['Cabin'].head(3))"],"metadata":{"id":"dgWUJ4cND-R3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["titanic_df.groupby(['Sex','Survived'])['Survived'].count()"],"metadata":{"id":"3wfvduW7D_SV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sns.barplot(x='Sex', y = 'Survived', data=titanic_df)"],"metadata":{"id":"ooEfSxxGEATK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sns.barplot(x='Pclass', y='Survived', hue='Sex', data=titanic_df)"],"metadata":{"id":"z-svaExwEBed"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 입력 age에 따라 구분값을 반환하는 함수 설정. DataFrame의 apply lambda식에 사용.\n","def get_category(age):\n","    cat = ''\n","    if age <= -1: cat = 'Unknown'\n","    elif age <= 5: cat = 'Baby'\n","    elif age <= 12: cat = 'Child'\n","    elif age <= 18: cat = 'Teenager'\n","    elif age <= 25: cat = 'Student'\n","    elif age <= 35: cat = 'Young Adult'\n","    elif age <= 60: cat = 'Adult'\n","    else : cat = 'Elderly'\n","\n","    return cat\n","\n","# 막대그래프의 크기 figure를 더 크게 설정\n","plt.figure(figsize=(10,6))\n","\n","#X축의 값을 순차적으로 표시하기 위한 설정\n","group_names = ['Unknown', 'Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Elderly']\n","\n","# lambda 식에 위에서 생성한 get_category( ) 함수를 반환값으로 지정.\n","# get_category(X)는 입력값으로 'Age' 컬럼값을 받아서 해당하는 cat 반환\n","titanic_df['Age_cat'] = titanic_df['Age'].apply(lambda x : get_category(x))\n","sns.barplot(x='Age_cat', y = 'Survived', hue='Sex', data=titanic_df, order=group_names)\n","titanic_df.drop('Age_cat', axis=1, inplace=True)"],"metadata":{"id":"FNvCRjVUEDJz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn import preprocessing\n","\n","def encode_features(dataDF):\n","    features = ['Cabin', 'Sex', 'Embarked']\n","    for feature in features:\n","        le = preprocessing.LabelEncoder()\n","        le = le.fit(dataDF[feature])\n","        dataDF[feature] = le.transform(dataDF[feature])\n","\n","    return dataDF\n","\n","titanic_df = encode_features(titanic_df)\n","titanic_df.head()"],"metadata":{"id":"x-46VUE3EEYA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import LabelEncoder\n","\n","# Null 처리 함수\n","def fillna(df):\n","    df['Age'].fillna(df['Age'].mean(), inplace=True)\n","    df['Cabin'].fillna('N', inplace=True)\n","    df['Embarked'].fillna('N', inplace=True)\n","    df['Fare'].fillna(0, inplace=True)\n","    return df\n","\n","# 머신러닝 알고리즘에 불필요한 피처 제거\n","def drop_features(df):\n","    df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)\n","    return df\n","\n","# 레이블 인코딩 수행.\n","def format_features(df):\n","    df['Cabin'] = df['Cabin'].str[:1]\n","    features = ['Cabin', 'Sex', 'Embarked']\n","    for feature in features:\n","        le = LabelEncoder()\n","        le = le.fit(df[feature])\n","        df[feature] = le.transform(df[feature])\n","    return df\n","\n","# 앞에서 설정한 데이터 전처리 함수 호출\n","def transform_features(df):\n","    df = fillna(df)\n","    df = drop_features(df)\n","    df = format_features(df)\n","    return df"],"metadata":{"id":"zVqrFXoyEHX6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 원본 데이터를 재로딩 하고, feature데이터 셋과 Label 데이터 셋 추출.\n","titanic_df = pd.read_csv('./titanic_train.csv')\n","y_titanic_df = titanic_df['Survived']\n","X_titanic_df= titanic_df.drop('Survived',axis=1)\n","\n","X_titanic_df = transform_features(X_titanic_df)"],"metadata":{"id":"B9Pmd9LeEI2e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test=train_test_split(X_titanic_df, y_titanic_df, \\\n","                                                  test_size=0.2, random_state=11)"],"metadata":{"id":"szcFy4UYEJ43"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n","\n","# 결정트리, Random Forest, 로지스틱 회귀를 위한 사이킷런 Classifier 클래스 생성\n","dt_clf = DecisionTreeClassifier(random_state=11)\n","rf_clf = RandomForestClassifier(random_state=11)\n","lr_clf = LogisticRegression(solver='liblinear')\n","\n","# DecisionTreeClassifier 학습/예측/평가\n","dt_clf.fit(X_train , y_train)\n","dt_pred = dt_clf.predict(X_test)\n","print('DecisionTreeClassifier 정확도: {0:.4f}'.format(accuracy_score(y_test, dt_pred)))\n","\n","# RandomForestClassifier 학습/예측/평가\n","rf_clf.fit(X_train , y_train)\n","rf_pred = rf_clf.predict(X_test)\n","print('RandomForestClassifier 정확도:{0:.4f}'.format(accuracy_score(y_test, rf_pred)))\n","\n","# LogisticRegression 학습/예측/평가\n","lr_clf.fit(X_train , y_train)\n","lr_pred = lr_clf.predict(X_test)\n","print('LogisticRegression 정확도: {0:.4f}'.format(accuracy_score(y_test, lr_pred)))"],"metadata":{"id":"-UEFz19YELKX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import KFold\n","\n","def exec_kfold(clf, folds=5):\n","    # 폴드 세트를 5개인 KFold객체를 생성, 폴드 수만큼 예측결과 저장을 위한  리스트 객체 생성.\n","    kfold = KFold(n_splits=folds)\n","    scores = []\n","\n","    # KFold 교차 검증 수행.\n","    for iter_count , (train_index, test_index) in enumerate(kfold.split(X_titanic_df)):\n","        # X_titanic_df 데이터에서 교차 검증별로 학습과 검증 데이터를 가리키는 index 생성\n","        X_train, X_test = X_titanic_df.values[train_index], X_titanic_df.values[test_index]\n","        y_train, y_test = y_titanic_df.values[train_index], y_titanic_df.values[test_index]\n","\n","        # Classifier 학습, 예측, 정확도 계산\n","        clf.fit(X_train, y_train)\n","        predictions = clf.predict(X_test)\n","        accuracy = accuracy_score(y_test, predictions)\n","        scores.append(accuracy)\n","        print(\"교차 검증 {0} 정확도: {1:.4f}\".format(iter_count, accuracy))\n","\n","    # 5개 fold에서의 평균 정확도 계산.\n","    mean_score = np.mean(scores)\n","    print(\"평균 정확도: {0:.4f}\".format(mean_score))\n","# exec_kfold 호출\n","exec_kfold(dt_clf , folds=5)"],"metadata":{"id":"wqF47KJuEMyN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import GridSearchCV\n","\n","parameters = {'max_depth':[2,3,5,10],\n","             'min_samples_split':[2,3,5], 'min_samples_leaf':[1,5,8]}\n","\n","grid_dclf = GridSearchCV(dt_clf , param_grid=parameters , scoring='accuracy' , cv=5)\n","grid_dclf.fit(X_train , y_train)\n","\n","print('GridSearchCV 최적 하이퍼 파라미터 :',grid_dclf.best_params_)\n","print('GridSearchCV 최고 정확도: {0:.4f}'.format(grid_dclf.best_score_))\n","best_dclf = grid_dclf.best_estimator_\n","\n","# GridSearchCV의 최적 하이퍼 파라미터로 학습된 Estimator로 예측 및 평가 수행.\n","dpredictions = best_dclf.predict(X_test)\n","accuracy = accuracy_score(y_test , dpredictions)\n","print('테스트 세트에서의 DecisionTreeClassifier 정확도 : {0:.4f}'.format(accuracy))"],"metadata":{"id":"z3jBjHiuEOMV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["정확도 (Accuracy)"],"metadata":{"id":"3Ku_mhvMEOx-"}},{"cell_type":"code","source":["from sklearn.base import BaseEstimator\n","\n","class MyDummyClassifier(BaseEstimator):\n","    # fit( ) 메소드는 아무것도 학습하지 않음.\n","    def fit(self, X , y=None):\n","        pass\n","\n","    # predict( ) 메소드는 단순히 Sex feature가 1 이면 0 , 그렇지 않으면 1 로 예측함.\n","    def predict(self, X):\n","        pred = np.zeros( ( X.shape[0], 1 ))\n","        for i in range (X.shape[0]) :\n","            if X['Sex'].iloc[i] == 1:\n","                pred[i] = 0\n","            else :\n","                pred[i] = 1\n","\n","        return pred"],"metadata":{"id":"JvgyEcfcEg6l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","# 원본 데이터를 재로딩, 데이터 가공, 학습 데이터/테스트 데이터 분할.\n","titanic_df = pd.read_csv('./titanic_train.csv')\n","y_titanic_df = titanic_df['Survived']\n","X_titanic_df= titanic_df.drop('Survived', axis=1)\n","X_titanic_df = transform_features(X_titanic_df)\n","X_train, X_test, y_train, y_test=train_test_split(X_titanic_df, y_titanic_df,\n","                                                  test_size=0.2, random_state=0)\n","\n","# 위에서 생성한 Dummy Classifier를 이용해 학습/예측/평가 수행.\n","myclf = MyDummyClassifier()\n","myclf.fit(X_train, y_train)\n","\n","mypredictions = myclf.predict(X_test)\n","print('Dummy Classifier의 정확도는: {0:.4f}'.format(accuracy_score(y_test, mypredictions)))"],"metadata":{"id":"hQohMoP2EqNj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.datasets import load_digits\n","from sklearn.model_selection import train_test_split\n","from sklearn.base import BaseEstimator\n","from sklearn.metrics import accuracy_score\n","import numpy as np\n","import pandas as pd\n","\n","class MyFakeClassifier(BaseEstimator):\n","    def fit(self,X,y):\n","        pass\n","\n","    # 입력값으로 들어오는 X 데이터 세트의 크기만큼 모두 0값으로 만들어서 반환\n","    def predict(self,X):\n","        return np.zeros( (len(X), 1) , dtype=bool)\n","\n","# 사이킷런의 내장 데이터 세트인 load_digits( )를 이용하여 MNIST 데이터 로딩\n","digits = load_digits()\n","\n","# digits 번호가 7번이면 True이고 이를 astype(int)로 1로 변환, 7번이 아니면 False이고 0으로 변환.\n","y= (digits.target = 7).astype(int)\n","X_train, X_test, X_train, y_test = train_test_split(digits.data, y, random_state = 11)"],"metadata":{"id":"aXCp8DFbE0LY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 불균형한 레이블 데이터 분포도 확인.\n","print('레이블 테스트 세트 크기 :', y_test.shape)\n","print('테스트 세트 레이블 0 과 1의 분포도')\n","print(pd.Series(y_test).value_counts())\n","\n","# Dummy Classifier로 학습/예측/정확도 평가\n","fakeclf = MyFakeClassifier()\n","fakeclf.fit(X_train , y_train)\n","fakepred = fakeclf.predict(X_test)\n","print('모든 예측을 0으로 하여도 정확도는:{:.3f}'.format(accuracy_score(y_test , fakepred)))"],"metadata":{"id":"TnYO56bKFibi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["오차 행렬"],"metadata":{"id":"h6gJs9rYFkz1"}},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix\n","\n","confusion_matrix(y_test , fakepred)"],"metadata":{"id":"q86VlfiUFqer"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["정밀도와 재현율"],"metadata":{"id":"akC4or7rFuGS"}},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score, precision_score , recall_score , confusion_matrix\n","\n","def get_clf_eval(y_test , pred):\n","    confusion = confusion_matrix( y_test, pred)\n","    accuracy = accuracy_score(y_test , pred)\n","    precision = precision_score(y_test , pred)\n","    recall = recall_score(y_test , pred)\n","    print('오차 행렬')\n","    print(confusion)\n","    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}'.format(accuracy , precision ,recall)"],"metadata":{"id":"yz-aWxenFvqp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","\n","# 원본 데이터를 재로딩, 데이터 가공, 학습데이터/테스트 데이터 분할.\n","titanic_df = pd.read_csv('./titanic_train.csv')\n","y_titanic_df = titanic_df['Survived']\n","X_titanic_df= titanic_df.drop('Survived', axis=1)\n","X_titanic_df = transform_features(X_titanic_df)\n","\n","X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, \\\n","                                                    test_size=0.20, random_state=11)\n","\n","lr_clf = LogisticRegression(solver='liblinear')\n","\n","lr_clf.fit(X_train , y_train)\n","pred = lr_clf.predict(X_test)\n","get_clf_eval(y_test , pred)"],"metadata":{"id":"wsPmR1fgFsA3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["정밀도/재현율 트레이드오프"],"metadata":{"id":"77zfgmDDGFT7"}},{"cell_type":"code","source":["pred_proba = lr_clf.predict_proba(X_test)\n","pred  = lr_clf.predict(X_test)\n","print('pred_proba()결과 Shape : {0}'.format(pred_proba.shape))\n","print('pred_proba array에서 앞 3개만 샘플로 추출 \\n:', pred_proba[:3])\n","\n","# 예측 확률 array 와 예측 결과값 array 를 concatenate 하여 예측 확률과 결과값을 한눈에 확인\n","pred_proba_result = np.concatenate([pred_proba , pred.reshape(-1,1)],axis=1)\n","print('두개의 class 중에서 더 큰 확률을 클래스 값으로 예측 \\n',pred_proba_result[:3])"],"metadata":{"id":"T4_Vun48GH9g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import Binarizer\n","\n","X = [[ 1, -1,  2],\n","     [ 2,  0,  0],\n","     [ 0,  1.1, 1.2]]\n","\n","# X의 개별 원소들 threshold 기준값보다 같거나 작으면 0을, 크면 1을 반환\n","binarizer = Binarizer(threshold=1.1)\n","print(binarizer.fit_transform(X))"],"metadata":{"id":"wvrEGSjCGQeY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import Binarizer\n","\n","#Binarizer의 threshold 설정값. 분류 결정 임곗값임.\n","custom_threshold = 0.5\n","\n","# predict_proba( ) 반환값의 두번째 컬럼 , 즉 Positive 클래스 컬럼 하나만 추출하여 Binarizer를 적용\n","pred_proba_1 = pred_proba[:,1].reshape(-1,1)\n","\n","binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_1)\n","custom_predict = binarizer.transform(pred_proba_1)\n","\n","get_clf_eval(y_test, custom_predict)"],"metadata":{"id":"uaWaARx0GWrM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Binarizer의 threshold 설정값을 0.4로 설정. 즉 분류 결정 임곗값을 0.5에서 0.4로 낮춤\n","custom_threshold = 0.4\n","pred_proba_1 = pred_proba[:,1].reshape(-1,1)\n","binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_1)\n","custom_predict = binarizer.transform(pred_proba_1)\n","\n","get_clf_eval(y_test , custom_predict)"],"metadata":{"id":"2Pn4IFTWGehh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 테스트를 수행할 모든 임곗값을 리스트 객체로 저장.\n","thresholds = [0.4, 0.45, 0.50, 0.55, 0.60]\n","\n","def get_eval_by_threshold(y_test , pred_proba_c1, thresholds):\n","    # thresholds list객체내의 값을 차례로 iteration하면서 Evaluation 수행.\n","    for custom_threshold in thresholds:\n","        binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_c1)\n","        custom_predict = binarizer.transform(pred_proba_c1)\n","        print('임곗값:',custom_threshold)\n","        get_clf_eval(y_test , custom_predict)\n","\n","get_eval_by_threshold(y_test ,pred_proba[:,1].reshape(-1,1), thresholds )"],"metadata":{"id":"3h8Wc5kpGjUl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import precision_recall_curve\n","\n","# 레이블 값이 1일때의 예측 확률을 추출\n","pred_proba_class1 = lr_clf.predict_proba(X_test)[:, 1]\n","\n","# 실제값 데이터 셋과 레이블 값이 1일 때의 예측 확률을 precision_recall_curve 인자로 입력\n","precisions, recalls, thresholds = precision_recall_curve(y_test, pred_proba_class1 )\n","print('반환된 분류 결정 임곗값 배열의 Shape:', thresholds.shape)\n","print('반환된 precisions 배열의 Shape:', precisions.shape)\n","print('반환된 recalls 배열의 Shape:', recalls.shape)\n","\n","print(\"thresholds 5 sample:\", thresholds[:5])\n","print(\"precisions 5 sample:\", precisions[:5])\n","print(\"recalls 5 sample:\", recalls[:5])\n","\n","#반환된 임계값 배열 로우가 147건이므로 샘플로 10건만 추출하되, 임곗값을 15 Step으로 추출.\n","thr_index = np.arange(0, thresholds.shape[0], 15)\n","print('샘플 추출을 위한 임계값 배열의 index 10개:', thr_index)\n","print('샘플용 10개의 임곗값: ', np.round(thresholds[thr_index], 2))\n","\n","# 15 step 단위로 추출된 임계값에 따른 정밀도와 재현율 값\n","print('샘플 임계값별 정밀도: ', np.round(precisions[thr_index], 3))\n","print('샘플 임계값별 재현율: ', np.round(recalls[thr_index], 3))"],"metadata":{"id":"-JZJgR-9GmeH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import matplotlib.ticker as ticker\n","%matplotlib inline\n","\n","def precision_recall_curve_plot(y_test , pred_proba_c1):\n","    # threshold ndarray와 이 threshold에 따른 정밀도, 재현율 ndarray 추출.\n","    precisions, recalls, thresholds = precision_recall_curve( y_test, pred_proba_c1)\n","\n","    # X축을 threshold값으로, Y축은 정밀도, 재현율 값으로 각각 Plot 수행. 정밀도는 점선으로 표시\n","    plt.figure(figsize=(8,6))\n","    threshold_boundary = thresholds.shape[0]\n","    plt.plot(thresholds, precisions[0:threshold_boundary], linestyle='--', label='precision')\n","    plt.plot(thresholds, recalls[0:threshold_boundary],label='recall')\n","\n","    # threshold 값 X 축의 Scale을 0.1 단위로 변경\n","    start, end = plt.xlim()\n","    plt.xticks(np.round(np.arange(start, end, 0.1),2))\n","\n","    # x축, y축 label과 legend, 그리고 grid 설정\n","    plt.xlabel('Threshold value'); plt.ylabel('Precision and Recall value')\n","    plt.legend(); plt.grid()\n","    plt.show()\n","\n","precision_recall_curve_plot( y_test, lr_clf.predict_proba(X_test)[:, 1] )"],"metadata":{"id":"QhYyMZNzGrE_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["F1 스코어"],"metadata":{"id":"DUAPJeVJGtLj"}},{"cell_type":"markdown","source":["의미) 정밀도와 재현율을 결합한 지표\n","\n","-> 정밀도와 재현율이 어느 한 쪽으로 치우치지 않은 수치를 나타낼 때 상대적으로 높은 값을 가짐."],"metadata":{"id":"N_kgBav9Gwoo"}},{"cell_type":"code","source":["from sklearn.metrics import f1_score\n","f1 = f1_score(y_test , pred)\n","print('F1 스코어: {0:.4f}'.format(f1))"],"metadata":{"id":"-qH-58u-G8uq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_clf_eval(y_test , pred):\n","    confusion = confusion_matrix( y_test, pred)\n","    accuracy = accuracy_score(y_test , pred)\n","    precision = precision_score(y_test , pred)\n","    recall = recall_score(y_test , pred)\n","    # F1 스코어 추가\n","    f1 = f1_score(y_test,pred)\n","    print('오차 행렬')\n","    print(confusion)\n","    # f1 score print 추가\n","    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}, F1:{3:.4f}'.format(accuracy, precision, recall, f1))\n","\n","thresholds = [0.4 , 0.45 , 0.50 , 0.55 , 0.60]\n","pred_proba = lr_clf.predict_proba(X_test)\n","get_eval_by_threshold(y_test, pred_proba[:,1].reshape(-1,1), thresholds)"],"metadata":{"id":"JpbTCeZ1HBfO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["ROC 곡선과 AUC"],"metadata":{"id":"tcZRgSdyHExl"}},{"cell_type":"code","source":["from sklearn.metrics import roc_curve\n","\n","# 레이블 값이 1일때의 예측 확률을 추출\n","pred_proba_class1 = lr_clf.predict_proba(X_test)[:, 1]\n","\n","fprs , tprs , thresholds = roc_curve(y_test, pred_proba_class1)\n","# 반환된 임곗값 배열에서 샘플로 데이터를 추출하되, 임곗값을 5 Step으로 추출.\n","# thresholds[0]은 max(예측확률)+1로 임의 설정됨. 이를 제외하기 위해 np.arange는 1부터 시작\n","thr_index = np.arange(1, thresholds.shape[0], 5)\n","print('샘플 추출을 위한 임곗값 배열의 index:', thr_index)\n","print('샘플 index로 추출한 임곗값: ', np.round(thresholds[thr_index], 2))\n","\n","# 5 step 단위로 추출된 임계값에 따른 FPR, TPR 값\n","print('샘플 임곗값별 FPR: ', np.round(fprs[thr_index], 3))\n","print('샘플 임곗값별 TPR: ', np.round(tprs[thr_index], 3))"],"metadata":{"id":"wmt15ag_HJdQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def roc_curve_plot(y_test , pred_proba_c1):\n","    # 임곗값에 따른 FPR, TPR 값을 반환 받음.\n","    fprs , tprs , thresholds = roc_curve(y_test ,pred_proba_c1)\n","\n","    # ROC Curve를 plot 곡선으로 그림.\n","    plt.plot(fprs , tprs, label='ROC')\n","    # 가운데 대각선 직선을 그림.\n","    plt.plot([0, 1], [0, 1], 'k--', label='Random')\n","\n","    # FPR X 축의 Scale을 0.1 단위로 변경, X,Y 축명 설정등\n","    start, end = plt.xlim()\n","    plt.xticks(np.round(np.arange(start, end, 0.1),2))\n","    plt.xlim(0,1); plt.ylim(0,1)\n","    plt.xlabel('FPR( 1 - Specificity )'); plt.ylabel('TPR( Recall )')\n","    plt.legend()\n","    plt.show()\n","\n","roc_curve_plot(y_test, lr_clf.predict_proba(X_test)[:, 1] )"],"metadata":{"id":"kqNUu464HNvJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import roc_auc_score\n","\n","pred_proba = lr_clf.predict_proba(X_test)[:, 1]\n","roc_score = roc_auc_score(y_test, pred_proba)\n","print('ROC AUC 값: {0:.4f}'.format(roc_score))"],"metadata":{"id":"cKLZPXI_HQpr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_clf_eval(y_test, pred=None, pred_proba=None):\n","    confusion = confusion_matrix( y_test, pred)\n","    accuracy = accuracy_score(y_test , pred)\n","    precision = precision_score(y_test , pred)\n","    recall = recall_score(y_test , pred)\n","    f1 = f1_score(y_test,pred)\n","    # ROC-AUC 추가\n","    roc_auc = roc_auc_score(y_test, pred_proba)\n","    print('오차 행렬')\n","    print(confusion)\n","    # ROC-AUC print 추가\n","    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\\\n","          F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))"],"metadata":{"id":"oZIMefpmHS5M"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["피마 인디언 당뇨병 예측"],"metadata":{"id":"qKjD8gWOHUSg"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n","from sklearn.metrics import f1_score, confusion_matrix, precision_recall_curve, roc_curve\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.linear_model import LogisticRegression\n","\n","diabetes_data = pd.read_csv('diabetes.csv')\n","print(diabetes_data['Outcome'].value_counts())\n","diabetes_data.head(3)"],"metadata":{"id":"SyfDrTwrHWeg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["diabetes_data.info( )"],"metadata":{"id":"6t5lHytuHdLQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 피처 데이터 세트 X, 레이블 데이터 세트 y를 추출.\n","# 맨 끝이 Outcome 컬럼으로 레이블 값임. 컬럼 위치 -1을 이용해 추출\n","X = diabetes_data.iloc[:, :-1]\n","y = diabetes_data.iloc[:, -1]\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 156, stratify=y)\n","\n","# 로지스틱 회귀로 학습,예측 및 평가 수행.\n","lr_clf = LogisticRegression(solver='liblinear')\n","lr_clf.fit(X_train , y_train)\n","pred = lr_clf.predict(X_test)\n","pred_proba = lr_clf.predict_proba(X_test)[:, 1]\n","\n","get_clf_eval(y_test , pred, pred_proba)"],"metadata":{"id":"Vbjjbb8oHi7M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pred_proba_c1 = lr_clf.predict_proba(X_test)[:, 1]\n","precision_recall_curve_plot(y_test, pred_proba_c1)"],"metadata":{"id":"6wxJB_eiHnY-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["diabetes_data.describe()"],"metadata":{"id":"BtEtvezVHqMg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.hist(diabetes_data['Glucose'], bins=100)\n","plt.show()"],"metadata":{"id":"nWia58IVHrFm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 0값을 검사할 피처명 리스트\n","zero_features = ['Glucose', 'BloodPressure','SkinThickness','Insulin','BMI']\n","\n","# 전체 데이터 건수\n","total_count = diabetes_data['Glucose'].count()\n","\n","# 피처별로 반복 하면서 데이터 값이 0 인 데이터 건수 추출하고, 퍼센트 계산\n","for feature in zero_features:\n","    zero_count = diabetes_data[diabetes_data[feature] == 0][feature].count()\n","    print('{0} 0 건수는 {1}, 퍼센트는 {2:.2f} %'.format(feature, zero_count, 100*zero_count/total_count))"],"metadata":{"id":"QAa7pj1PHwr8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# zero_features 리스트 내부에 저장된 개별 피처들에 대해서 0값을 평균 값으로 대체\n","mean_zero_features = diabetes_data[zero_features].mean()\n","diabetes_data[zero_features]=diabetes_data[zero_features].replace(0, mean_zero_features)"],"metadata":{"id":"0lNBlZm0H5mh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X = diabetes_data.iloc[:, :-1]\n","y = diabetes_data.iloc[:, -1]\n","\n","# StandardScaler 클래스를 이용해 피처 데이터 세트에 일괄적으로 스케일링 적용\n","scaler = StandardScaler( )\n","X_scaled = scaler.fit_transform(X)\n","\n","X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size = 0.2, random_state = 156, stratify=y)\n","\n","# 로지스틱 회귀로 학습, 예측 및 평가 수행.\n","lr_clf = LogisticRegression()\n","lr_clf.fit(X_train , y_train)\n","pred = lr_clf.predict(X_test)\n","pred_proba = lr_clf.predict_proba(X_test)[:, 1]\n","\n","get_clf_eval(y_test , pred, pred_proba)"],"metadata":{"id":"MpxcizIIH70H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["thresholds = [0.3 , 0.33 ,0.36,0.39, 0.42 , 0.45 ,0.48, 0.50]\n","pred_proba = lr_clf.predict_proba(X_test)\n","get_eval_by_threshold(y_test, pred_proba[:,1].reshape(-1,1), thresholds )"],"metadata":{"id":"8a4Ws16RH-lO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 임곗값를 0.48로 설정한 Binarizer 생성\n","binarizer = Binarizer(threshold=0.48)\n","\n","# 위에서 구한 lr_clf의 predict_proba() 예측 확률 array에서 1에 해당하는 컬럼값을 Binarizer변환.\n","pred_th_048 = binarizer.fit_transform(pred_proba[:, 1].reshape(-1,1))\n","\n","get_clf_eval(y_test , pred_th_048, pred_proba[:, 1])"],"metadata":{"id":"mrF_A706IBDk"},"execution_count":null,"outputs":[]}]}